
@article{glozman_image-guided_2007,
	title = {Image-{Guided} {Robotic} {Flexible} {Needle} {Steering}},
	volume = {23},
	issn = {1552-3098},
	doi = {10.1109/TRO.2007.898972},
	abstract = {This paper presents a robotic system for steering under real-time fluoroscopic guidance a flexible needle in soft tissue. Given a target and possible obstacle locations, the computer calculates the flexible needle-tip trajectory that avoids the obstacle and hits the target. Using an inverse kinematics algorithm, the needle base maneuvers required for a tip to follow this trajectory are calculated, enabling a robot to perform controlled needle insertion. Assuming small displacements, the flexible needle is modeled as a linear beam supported by virtual springs, where the stiffness coefficients of the springs can vary along the needle. Using this simplified model, the forward and inverse kinematics of the needle are solved analytically, enabling both path planning and path correction in real time. The needle shape is detected in real time from fluoroscopic images, and the controller commands the needle base motion that minimizes the needle tip error. This approach was verified experimentally using a robot to maneuver the base of a flexible needle inserted into a muscle tissue. Along the 40-mm trajectory that avoids the obstacle and hits the target, the error stayed below the 0.5-mm level. This study demonstrates the ability to perform closed-loop control and steering of a flexible needle by maneuvering the needle base so that its tip achieves a planned trajectory.},
	number = {3},
	journal = {IEEE Transactions on Robotics},
	author = {Glozman, D. and Shoham, M.},
	month = jun,
	year = {2007},
	keywords = {Biological tissues, Biomedical imaging, Kinematics, Motion detection, Needles, Path planning, Real time systems, Robot control, Shape control, Springs, Trajectory, closed loop systems, closed-loop control, collision avoidance, flexible needle steering, flexible structures, fluorescence, image-guided robotic, inverse kinematics, medical image processing, medical robotics, medical treatment, muscle tissue, needle insertion, obstacle locations, real-time fluoroscopic guidance, robot vision, robots},
	pages = {459--467}
}

@article{bakker_susceptibility_1993,
	title = {Susceptibility artifacts in 2DFT spin-echo and gradient-echo imaging: {The} cylinder model revisited},
	volume = {11},
	issn = {0730-725X},
	shorttitle = {Susceptibility artifacts in 2DFT spin-echo and gradient-echo imaging},
	url = {http://www.sciencedirect.com/science/article/pii/0730725X9390473Q},
	doi = {10.1016/0730-725X(93)90473-Q},
	abstract = {Susceptibility-induced geometry and intensity distortions are a familiar observation in MR imaging. In the past few years several attempts have been made to aid in the understanding of susceptibility artifacts by means of simulation studies. Although these studies, which were mostly carried out with simple test objects, have produced some qualitative insight into χ-artifacts, the results lacked precision in describing finer details. In this paper we show the discrepancy between theory and experiment in previous work to be the result of an inadequate theoretical approach. In most studies so far, ΔB0 effects are taken into account in the frequency domain, that is, after Fourier transformation of the data. In our view the simulation should follow the actual sequence of events in an imaging experiment and deal with the effect of error fields in the time domain (k-space) already. The correctness of this view is demonstrated here by comparing the results of time and frequency domain simulation against experimental observation for a coaxial cylinder phantom, a widely used model in this type of work. Having established the superiority of the time domain simulation, we demonstrate its use in predicting χ-artifacts under various experimental conditions, for example, in spin-echo and gradient-echo imaging with a reduced number of phaseencoding steps.},
	number = {4},
	urldate = {2018-04-23TZ},
	journal = {Magnetic Resonance Imaging},
	author = {Bakker, C. J. G. and Bhagwandien, R. and Moerland, M. A. and Fuderer, M.},
	month = jan,
	year = {1993},
	keywords = {Geometric distortion, Intensity distortion, Magnetic resonance imaging, Susceptibility artifacts},
	pages = {539--548}
}

@inproceedings{reed_integrated_2008,
	title = {Integrated planning and image-guided control for planar needle steering},
	doi = {10.1109/BIOROB.2008.4762833},
	abstract = {Flexible, tip-steerable needles promise to enhance physicianspsila abilities to accurately reach targets and maneuver inside the human body while minimizing patient trauma. Here, we present a functional needle steering system that integrates two components: (1) a patient-specific 2D pre- and intraoperative planner that finds an achievable route to a target within a planar slice of tissue (Stochastic Motion Roadmap), and (2) a low-level image-guided feedback controller that keeps the needle tip within that slice. The planner generates a sequence of circular arcs that can be realized by interleaving pure insertions with 180deg rotations of the needle shaft. This pre-planned sequence is updated in realtime at regular intervals. Concurrently, the low-level image-based controller servos the needle to remain close to the desired plane between plan updates. Both planner and controller are predicated on a previously developed kinematic nonholonomic model of beveltip needle steering. We use slighly different needles here that have a small bend near the tip, so we extend the model to account for discontinuities of the tip position caused by 180deg rotations. Further, during large rotations of the needle base, we maintain the desired tip angle by compensating for torsional compliance in the needle shaft, neglected in previous needle steering work. By integrating planning, control, and torsion compensation, we demonstrate both accurate targeting and obstacle avoidance.},
	booktitle = {2008 2nd {IEEE} {RAS} {EMBS} {International} {Conference} on {Biomedical} {Robotics} and {Biomechatronics}},
	author = {Reed, K. B. and Kallem, V. and Alterovitz, R. and Goldbergxz, K. and Okamura, A. M. and Cowan, N. J.},
	month = oct,
	year = {2008},
	keywords = {Automatic control, Biological tissues, Biomechatronics, Control systems, Medical control systems, Needles, Physics computing, Robot sensing systems, Shafts, USA Councils, beveltip needle steering, biomedical imaging, controllers, functional needle steering system, image-guided control, intraoperative planner, kinematic nonholonomic model, low-level image-guided feedback controller, medical control systems, medical diagnostic computing, needles, patient treatment, patient-specific 2D preoperative planner, stochastic motion roadmap},
	pages = {819--824}
}

@article{reed_modeling_2009,
	title = {Modeling and {Control} of {Needles} {With} {Torsional} {Friction}},
	volume = {56},
	issn = {0018-9294},
	doi = {10.1109/TBME.2009.2029240},
	abstract = {A flexible needle can be accurately steered by robotically controlling the bevel tip orientation as the needle is inserted into tissue. Friction between the long, flexible needle shaft and the tissue can cause a significant discrepancy between the orientation of the needle tip and the orientation of the base where the needle angle is controlled. Our experiments show that several common phantom tissues used in needle steering experiments impart substantial friction forces to the needle shaft, resulting in a lag of more than 45deg for a 10 cm insertion depth in some phantoms; clinical studies report torques large enough to cause similar errors during needle insertions. Such angle discrepancies will result in poor performance or failure of path planners and image-guided controllers, since the needles used in percutaneous procedures are too small for state-of-the-art imaging to accurately measure the tip angle. To compensate for the angle discrepancy, we develop an estimator using a mechanics-based model of the rotational dynamics of a needle being inserted into tissue. Compared to controllers that assume a rigid needle in a frictionless environment, our estimator-based controller improves the tip angle convergence time by nearly 50\% and reduces the path deviation of the needle by 70\%.},
	number = {12},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Reed, K. B. and Okamura, A. M. and Cowan, N. J.},
	month = dec,
	year = {2009},
	keywords = {Biological materials, Biomechanics, Biopsy, Brachytherapy, Computer Simulation, Computer-Aided Design, Equipment Design, Equipment Failure Analysis, Friction, Imaging phantoms, Mechanical engineering, Medical robotics, Models, Biological, Needles, Permission, Prosthesis Implantation, Reproducibility of Results, Robot sensing systems, Robotics, Robotics and automation, Sensitivity and Specificity, Shafts, Torque, biological tissues, biomechanics, controllers, depth 10 cm, estimator-based controller, failure (mechanical), feedforward systems, finite element analysis, flexible needle shaft, friction, image-guided controllers, mechanics-based model, needle steering experiments, needles, path planner failure, phantom tissues, phantoms, robots, rotational dynamics, steering systems, surgery, torsion, torsional friction},
	pages = {2905--2916}
}

@inproceedings{lehocky_needle_2012,
	title = {Needle steering by duty-cycled spinning: {Modeling} the mechanics},
	shorttitle = {Needle steering by duty-cycled spinning},
	doi = {10.1109/NEBC.2012.6206959},
	abstract = {Techniques have been developed in recent years that enable steering of flexible needles along nonlinear paths to reach deep anatomical structures. This study builds upon previous work involving steering bevel-tipped needles by rotating with a duty cycle during insertion. The paper describes work toward the development of a model of the relation between needle properties, tissue properties, rotational duty cycle, and curvature that is sufficiently simple to serve as an intuitive guide for selection of needle geometry or duty-cycled steering range.},
	booktitle = {2012 38th {Annual} {Northeast} {Bioengineering} {Conference} ({NEBEC})},
	author = {Lehocky, C. A. and Riviere, C. N.},
	month = mar,
	year = {2012},
	keywords = {Force, Heart, Media, Needles, Spinning, Wires, bevel tipped needles, bioMEMS, deep anatomical structures, duty cycled spinning, duty cycled steering range, flexible needle steering, mechanics modeling, medical robotics, microrobots, mobile robots, needle geometry, needle properties, needles, patient treatment, position control, rotational duty cycle, tissue properties},
	pages = {55--56}
}

@article{wood_needle_nodate,
	title = {Needle {Steering} {System} {Using} {Duty}-{Cycled} {Rotation} for {Percutaneous} {Kidney} {Access}},
	abstract = {The authors present ongoing work on the use of a variable curvature flexible needle steering system to gain percutaneous access to the kidney for medical interventions. A nonlinear control law is introduced which drives the needle to track a predetermined planar path using a steering approach based on duty-cycled rotation during insertion. Renal access is performed in simulation and tested in vitro in a tissue phantom to validate the proposed control method.},
	language = {en},
	author = {Wood, Nathan* and Shahrour, Khaled and Ost, Michael and Riviere, Cameron N},
	pages = {4}
}

@article{menard_mri_nodate,
	title = {{MRI} and {Biopsy} {Performance} in {Delineating} {Recurrent} {Tumor} {Boundaries} after {Radiotherapy} for {Prostate} {Cancer}},
	language = {en},
	author = {Menard, C and Iupati, D and Lee, J and Simeonov, A and Abed, J and Publicover, J and Chung, P and Bayley, A and Catton, C and Milosevic, M and Bristow, R and Morton, G and Warde, P and Brock, K and Haider, M},
	pages = {1}
}

@article{damico_transperineal_2000,
	title = {{TRANSPERINEAL} {MAGNETIC} {RESONANCE} {IMAGE} {GUIDED} {PROSTATE} {BIOPSY}},
	volume = {164},
	issn = {0022-5347},
	url = {http://www.sciencedirect.com/science/article/pii/S0022534705673661},
	doi = {10.1016/S0022-5347(05)67366-1},
	abstract = {Purpose
We report the findings of a transperineal magnetic resonance image (MRI) guided biopsy of the prostate in a man with increasing prostate specific antigen who was not a candidate for a transrectal ultrasound guided biopsy.
Materials and Methods
Using an open configuration 0.5 Tesla MRI scanner and pelvic coil, a random sextant sample was obtained under real time MRI guidance from the peripheral zone of the prostate gland as well as a single core from each MRI defined lesion. The patient had previously undergone proctocolectomy for ulcerative colitis and, therefore, was not a candidate for transrectal ultrasound guided biopsy. Prior attempts to make the diagnosis of prostate cancer using a transurethral approach were unsuccessful.
Results
The random sextant samples contained benign prostatic hyperplasia, whereas Gleason grade 3 + 3 = 6 adenocarcinoma was confirmed in 15\% and 25\% of the 2 cores obtained from the MRI targeted specimens of 2 defined lesions. The procedure was well tolerated by the patient.
Conclusions
Transperineal MRI guided biopsy is a new technique that may be useful in detecting prostate cancer in men with increasing prostate specific antigen who are not candidates for transrectal ultrasound guided biopsy.},
	number = {2},
	urldate = {2018-04-22TZ},
	journal = {The Journal of Urology},
	author = {D’amico, A. V. and Tempany, C. M. and Cormack, R. and Hata, N. and Jinzaki, M. and Tuncali, K. and Weinstein, M. and Richie, J. P.},
	month = aug,
	year = {2000},
	keywords = {biopsy, magnetic resonance imaging, prostate, prostate-specific antigen, prostatic neoplasms},
	pages = {385--387}
}

@article{wang_evaluation_2015,
	title = {Evaluation of an active magnetic resonance tracking system for interstitial brachytherapy},
	volume = {42},
	issn = {0094-2405},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4662673/},
	doi = {10.1118/1.4935535},
	abstract = {Purpose:
In gynecologic cancers, magnetic resonance (MR) imaging is the modality of choice for visualizing tumors and their surroundings because of superior soft-tissue contrast. Real-time MR guidance of catheter placement in interstitial brachytherapy facilitates target coverage, and would be further improved by providing intraprocedural estimates of dosimetric coverage. A major obstacle to intraprocedural dosimetry is the time needed for catheter trajectory reconstruction. Herein the authors evaluate an active MR tracking (MRTR) system which provides rapid catheter tip localization and trajectory reconstruction. The authors assess the reliability and spatial accuracy of the MRTR system in comparison to standard catheter digitization using magnetic resonance imaging (MRI) and CT.

Methods:
The MRTR system includes a stylet with microcoils mounted on its shaft, which can be inserted into brachytherapy catheters and tracked by a dedicated MRTR sequence. Catheter tip localization errors of the MRTR system and their dependence on catheter locations and orientation inside the MR scanner were quantified with a water phantom. The distances between the tracked tip positions of the MRTR stylet and the predefined ground-truth tip positions were calculated for measurements performed at seven locations and with nine orientations. To evaluate catheter trajectory reconstruction, fifteen brachytherapy catheters were placed into a gel phantom with an embedded catheter fixation framework, with parallel or crossed paths. The MRTR stylet was then inserted sequentially into each catheter. During the removal of the MRTR stylet from within each catheter, a MRTR measurement was performed at 40 Hz to acquire the instantaneous stylet tip position, resulting in a series of three-dimensional (3D) positions along the catheter’s trajectory. A 3D polynomial curve was fit to the tracked positions for each catheter, and equally spaced dwell points were then generated along the curve. High-resolution 3D MRI of the phantom was performed followed by catheter digitization based on the catheter’s imaging artifacts. The catheter trajectory error was characterized in terms of the mean distance between corresponding dwell points in MRTR-generated catheter trajectory and MRI-based catheter digitization. The MRTR-based catheter trajectory reconstruction process was also performed on three gynecologic cancer patients, and then compared with catheter digitization based on MRI and CT.

Results:
The catheter tip localization error increased as the MRTR stylet moved further off-center and as the stylet’s orientation deviated from the main magnetic field direction. Fifteen catheters’ trajectories were reconstructed by MRTR. Compared with MRI-based digitization, the mean 3D error of MRTR-generated trajectories was 1.5 ± 0.5 mm with an in-plane error of 0.7 ± 0.2 mm and a tip error of 1.7 ± 0.5 mm. MRTR resolved ambiguity in catheter assignment due to crossed catheter paths, which is a common problem in image-based catheter digitization. In the patient studies, the MRTR-generated catheter trajectory was consistent with digitization based on both MRI and CT.

Conclusions:
The MRTR system provides accurate catheter tip localization and trajectory reconstruction in the MR environment. Relative to the image-based methods, it improves the speed, safety, and reliability of the catheter trajectory reconstruction in interstitial brachytherapy. MRTR may enable in-procedural dosimetric evaluation of implant target coverage.},
	number = {12},
	urldate = {2018-04-22TZ},
	journal = {Medical Physics},
	author = {Wang, Wei and Viswanathan, Akila N. and Damato, Antonio L. and Chen, Yue and Tse, Zion and Pan, Li and Tokuda, Junichi and Seethamraju, Ravi T. and Dumoulin, Charles L. and Schmidt, Ehud J. and Cormack, Robert A.},
	month = dec,
	year = {2015},
	pmid = {26632065},
	pmcid = {PMC4662673},
	pages = {7114--7121}
}

@article{wang_evaluation_2015-1,
	title = {Evaluation of an active magnetic resonance tracking system for interstitial brachytherapy},
	volume = {42},
	issn = {2473-4209},
	doi = {10.1118/1.4935535},
	number = {12},
	journal = {Med Phys},
	author = {Wang, Wei and Viswanathan, Akila and Damato, Antonio and Chen, Yue and Tse, Zion and Pan, Li and Tokuda, Junichi and Seethamraju, Ravi and Dumoulin, Charles and Schmidt, Ehud and Cormack, Robert},
	year = {2015}
}

@article{wang_real-time_2015,
	title = {Real-time active {MR}-tracking of metallic stylets in {MR}-guided radiation therapy},
	volume = {73},
	issn = {0740-3194},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4257908/},
	doi = {10.1002/mrm.25300},
	abstract = {Purpose
To develop an active MR-tracking system to guide placement of metallic devices for radiation therapy.

Methods
An actively tracked metallic stylet for brachytherapy was constructed by adding printed-circuit micro-coils to a commercial stylet. The coil design was optimized by electromagnetic simulation, and has a radio-frequency lobe pattern extending {\textasciitilde}5 mm beyond the strong B0 inhomogeneity region near the metal surface. An MR-tracking sequence with phase-field dithering was used to overcome residual effects of B0 and B1 inhomogeneities caused by the metal, as well as from inductive coupling to surrounding metallic stylets. The tracking system was integrated with a graphical workstation for real-time visualization. 3T MRI catheter-insertion procedures were tested in phantoms and ex-vivo animal tissue, and then performed in three patients during interstitial brachytherapy.

Results
The tracking system provided high-resolution (0.6 × 0.6 × 0.6 mm3) and rapid (16 to 40 frames per second, with three to one phase-field dithering directions) catheter localization in phantoms, animals, and three gynecologic cancer patients.

Conclusion
This is the first demonstration of active tracking of the shaft of metallic stylet in MR-guided brachytherapy. It holds the promise of assisting physicians to achieve better targeting and improving outcomes in interstitial brachytherapy.},
	number = {5},
	urldate = {2018-04-22TZ},
	journal = {Magnetic resonance in medicine : official journal of the Society of Magnetic Resonance in Medicine / Society of Magnetic Resonance in Medicine},
	author = {Wang, Wei and Dumoulin, Charles L. and Viswanathan, Akila N. and Tse, Zion T. H. and Mehrtash, Alireza and Loew, Wolfgang and Norton, Isaiah and Tokuda, Junichi and Seethamraju, Ravi T. and Kapur, Tina and Damato, Antonio L. and Cormack, Robert A. and Schmidt, Ehud J.},
	month = may,
	year = {2015},
	pmid = {24903165},
	pmcid = {PMC4257908},
	pages = {1803--1811}
}

@article{tilak_3t_2015,
	title = {3T {MR} {Guided} in bore transperineal prostate biopsy: {A} {Comparison} of robotic and manual needle-guidance templates},
	volume = {42},
	issn = {1053-1807},
	shorttitle = {3T {MR} {Guided} in bore transperineal prostate biopsy},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4376663/},
	doi = {10.1002/jmri.24770},
	abstract = {Purpose
To demonstrate the utility of a robotic needle-guidance template device as compared to a manual template for in-bore 3T transperineal MR-guided prostate biopsy.

Materials and Methods
This two-arm mixed retrospective-prospective study included 99 cases of targeted transperineal prostate biopsies. The biopsy needles were aimed at suspicious foci noted on multiparametric 3T MRI using manual template (historical control) as compared with a robotic template. The following data was obtained: the accuracy of average and closest needle placement to the focus, histologic yield, percentage of cancer volume in positive core samples, complication rate, and time to complete the procedure.

Results
56 cases were performed using the manual template, and 43 cases were performed using the robotic template. The mean accuracy of the best needle placement attempt was higher in the robotic group (2.39 mm) than the manual group (3.71 mm, p{\textless}0.027). The mean core procedure time was shorter in the robotic (90.82min) than the manual group (100.63min, p{\textless}0.030). Percentage of cancer volume in positive core samples was higher in robotic group (p{\textless}0.001). Cancer yields and complication rates were not statistically different between the two sub-groups (p = 0.557 and p=0.172 respectively).

Conclusion
The robotic needle-guidance template helps accurate placement of biopsy needles in MRI-guided core biopsy of prostate cancer.},
	number = {1},
	urldate = {2018-04-22TZ},
	journal = {Journal of magnetic resonance imaging : JMRI},
	author = {Tilak, Gaurie and Tuncali, Kemal and Song, Sang-Eun and Tokuda, Junichi and Olubiyi, Olutayo and Fennessy, Fiona and Fedorov, Andriy and Penzkofer, Tobias and Tempany, Clare and Hata, Nobuhiko},
	month = jul,
	year = {2015},
	pmid = {25263213},
	pmcid = {PMC4376663},
	pages = {63--71}
}

@article{eslami_-bore_2016,
	title = {In-{Bore} {Prostate} {Transperineal} {Interventions} with an {MRI}-guided {Parallel} {Manipulator}: {System} {Development} and {Preliminary} {Evaluation}},
	volume = {12},
	issn = {1478-5951},
	shorttitle = {In-{Bore} {Prostate} {Transperineal} {Interventions} with an {MRI}-guided {Parallel} {Manipulator}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4691445/},
	doi = {10.1002/rcs.1671},
	abstract = {Background
The robot-assisted minimally-invasive surgery is well recognized as a feasible solution for diagnosis and treatment of the prostate cancer in human.

Methods
In this paper the kinematics of a parallel 4 Degrees-of-Freedom (DOF) surgical manipulator designed for minimally invasive in-bore prostate percutaneous interventions through the patient's perineum. The proposed manipulator takes advantage of 4 sliders actuated by MRI-compatible piezoelectric motors and incremental rotary encoders. Errors, mostly originating from the design and manufacturing process, need to be identified and reduced before the robot is deployed in the clinical trials.

Results
The manipulator has undergone several experiments to evaluate the repeatability and accuracy of the needle placement which is an essential concern in percutaneous prostate interventions.

Conclusion
The acquired results endorse the sustainability, precision (about 1 mm in air (in x or y direction) at the needle's reference point) and reliability of the manipulator.},
	number = {2},
	urldate = {2018-04-22TZ},
	journal = {The international journal of medical robotics + computer assisted surgery : MRCAS},
	author = {Eslami, Sohrab and Shang, Weijian and Li, Gang and Patel, Nirav and Fischer, Gregory S. and Tokuda, Junichi and Hata, Nobuhiko and Tempany, Clare M. and Iordachita, Iulian},
	month = jun,
	year = {2016},
	pmid = {26111458},
	pmcid = {PMC4691445},
	pages = {199--213}
}

@article{onik_ct-guided_1988,
	title = {{CT}-guided aspirations for the body: comparison of hand guidance with stereotaxis},
	volume = {166},
	issn = {0033-8419},
	shorttitle = {{CT}-guided aspirations for the body},
	doi = {10.1148/radiology.166.2.3275980},
	abstract = {Forty computed tomography (CT)-assisted aspirations performed with only hand guidance were prospectively compared with 40 performed with a CT body-stereotaxic system. Although there was no statistically significant difference in lesion size and path length between the two groups, use of stereotaxis compared with hand guidance decreased by 75\% the number of needle manipulations required to place a needle within a lesion. With the stereotaxic method, only 43 needle manipulations were required to confirm a needle placement in 40 lesions, with no lesion requiring more than two attempts. Use of stereotaxis decreased the number of localization scans by 80\% and biopsy time by 50\%. It is concluded that CT-guided needle placements with hand guidance are often inaccurate and, unless the lesion is large, require multiple needle manipulations to place a needle within the lesion. Stereotaxis-guided biopsies, on the other hand, decrease radiation exposure, biopsy time, and trauma from multiple needle punctures.},
	language = {eng},
	number = {2},
	journal = {Radiology},
	author = {Onik, G. and Cosman, E. R. and Wells, T. H. and Goldberg, H. I. and Moss, A. A. and Costello, P. and Kane, R. A. and Hoddick, W. I. and Demas, B.},
	month = feb,
	year = {1988},
	pmid = {3275980},
	keywords = {Biopsy, Needle, Humans, Prospective Studies, Stereotaxic Techniques, Time Factors, Tomography, X-Ray Computed},
	pages = {389--394}
}

@article{honganoor_ct_2016,
	title = {{CT} guided biopsy using additional laser guidance: {Case} series from {India} comparing with conventional free hand technique},
	volume = {47},
	issn = {0378-603X},
	shorttitle = {{CT} guided biopsy using additional laser guidance},
	url = {http://www.sciencedirect.com/science/article/pii/S0378603X15002636},
	doi = {10.1016/j.ejrnm.2015.12.005},
	abstract = {Additional laser guidance during CT guided biopsy has shown promising results in terms of accuracy and patient throughput. We used a simple laser guidance unit that can be easily integrated with any of the CT units for additional laser guidance. We report the first case series of CT guided procedures done using this laser device in India comparing it with conventional free hand techniques.},
	number = {2},
	urldate = {2018-04-22TZ},
	journal = {The Egyptian Journal of Radiology and Nuclear Medicine},
	author = {Honganoor, Vyshakh V. and Keshava, Shyam Kumar N. and Moses, Vinu and Ahmed, Munawwar},
	month = jun,
	year = {2016},
	keywords = {CT guided procedures, Laser guidance, Radiation dose},
	pages = {493--499}
}

@article{busse_targeting_2015,
	title = {Targeting {Accuracy}, {Procedure} {Times} and {User} {Experience} of 240 {Experimental} {MRI} {Biopsies} {Guided} by a {Clinical} {Add}-{On} {Navigation} {System}},
	volume = {10},
	issn = {1932-6203},
	url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0134370},
	doi = {10.1371/journal.pone.0134370},
	abstract = {Objectives MRI is of great clinical utility for the guidance of special diagnostic and therapeutic interventions. The majority of such procedures are performed iteratively ("in-and-out") in standard, closed-bore MRI systems with control imaging inside the bore and needle adjustments outside the bore. The fundamental limitations of such an approach have led to the development of various assistance techniques, from simple guidance tools to advanced navigation systems. The purpose of this work was to thoroughly assess the targeting accuracy, workflow and usability of a clinical add-on navigation solution on 240 simulated biopsies by different medical operators. Methods Navigation relied on a virtual 3D MRI scene with real-time overlay of the optically tracked biopsy needle. Smart reference markers on a freely adjustable arm ensured proper registration. Twenty-four operators – attending (AR) and resident radiologists (RR) as well as medical students (MS) – performed well-controlled biopsies of 10 embedded model targets (mean diameter: 8.5 mm, insertion depths: 17-76 mm). Targeting accuracy, procedure times and 13 Likert scores on system performance were determined (strong agreement: 5.0). Results Differences in diagnostic success rates (AR: 93\%, RR: 88\%, MS: 81\%) were not significant. In contrast, between-group differences in biopsy times (AR: 4:15, RR: 4:40, MS: 5:06 min:sec) differed significantly (p{\textless}0.01). Mean overall rating was 4.2. The average operator would use the system again (4.8) and stated that the outcome justifies the extra effort (4.4). Lowest agreement was reported for the robustness against external perturbations (2.8). Conclusions The described combination of optical tracking technology with an automatic MRI registration appears to be sufficiently accurate for instrument guidance in a standard (closed-bore) MRI environment. High targeting accuracy and usability was demonstrated on a relatively large number of procedures and operators. Between groups with different expertise there were significant differences in experimental procedure times but not in the number of successful biopsies.},
	language = {en},
	number = {7},
	urldate = {2018-04-22TZ},
	journal = {PLOS ONE},
	author = {Busse, Harald and Riedel, Tim and Garnov, Nikita and Thörmer, Gregor and Kahn, Thomas and Moche, Michael},
	month = jul,
	year = {2015},
	keywords = {Biopsy, Imaging techniques, Magnetic resonance imaging, Navigation, Peas, Perturbation (geology), Radiologists, Screening guidelines},
	pages = {e0134370}
}

@article{xu_mri-guided_2010,
	title = {{MRI}-{Guided} {Robotic} {Prostate} {Biopsy}: {A} {Clinical} {Accuracy} {Validation}},
	volume = {13},
	shorttitle = {{MRI}-{Guided} {Robotic} {Prostate} {Biopsy}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2976594/},
	abstract = {Prostate cancer is a major health threat for men. For over five years, the U.S. National Cancer Institute has performed prostate biopsies with a magnetic resonance imaging (MRI)-guided robotic system.},
	number = {Pt 3},
	urldate = {2018-04-22TZ},
	journal = {Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention},
	author = {Xu, Helen and Lasso, Andras and Vikal, Siddharth and Guion, Peter and Krieger, Axel and Kaushal, Aradhana and Whitcomb, Louis L. and Fichtinger, Gabor},
	year = {2010},
	pmid = {20879423},
	pmcid = {PMC2976594},
	pages = {383--391}
}

@article{koethe_accuracy_2014,
	title = {Accuracy and efficacy of percutaneous biopsy and ablation using robotic assistance under computed tomography guidance: a phantom study},
	volume = {24},
	issn = {0938-7994},
	shorttitle = {Accuracy and efficacy of percutaneous biopsy and ablation using robotic assistance under computed tomography guidance},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3945277/},
	doi = {10.1007/s00330-013-3056-y},
	abstract = {Objective
To compare the accuracy of a robotic interventional radiologist (IR) assistance platform with a standard freehand technique for computed-tomography (CT)-guided biopsy and simulated radiofrequency ablation (RFA).

Methods
The accuracy of freehand single-pass needle insertions into abdominal phantoms was compared with insertions facilitated with the use of a robotic assistance platform (n = 20 each). Post-procedural CTs were analysed for needle placement error. Percutaneous RFA was simulated by sequentially placing five 17-gauge needle introducers into 5-cm diameter masses (n = 5) embedded within an abdominal phantom. Simulated ablations were planned based on pre-procedural CT, before multi-probe placement was executed freehand. Multi-probe placement was then performed on the same 5-cm mass using the ablation planning software and robotic assistance. Post-procedural CTs were analysed to determine the percentage of untreated residual target.

Results
Mean needle tip-to-target errors were reduced with use of the IR assistance platform (both P {\textless} 0.0001). Reduced percentage residual tumour was observed with treatment planning (P = 0.02).

Conclusion
Improved needle accuracy and optimised probe geometry are observed during simulated CT-guided biopsy and percutaneous ablation with use of a robotic IR assistance platform. This technology may be useful for clinical CT-guided biopsy and RFA, when accuracy may have an impact on outcome.},
	number = {3},
	urldate = {2018-04-22TZ},
	journal = {European radiology},
	author = {Koethe, Yilun and Xu, Sheng and Velusamy, Gnanasekar and Wood, Bradford J. and Venkatesan, Aradhana M.},
	month = mar,
	year = {2014},
	pmid = {24220755},
	pmcid = {PMC3945277},
	pages = {723--730}
}

@article{xu_accuracy_2013,
	title = {Accuracy analysis in {MRI}-guided robotic prostate biopsy},
	volume = {8},
	issn = {1861-6410},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4139961/},
	doi = {10.1007/s11548-013-0831-9},
	abstract = {Purpose
To assess retrospectively the clinical accuracy of an magnetic
resonance imaging-guided robotic prostate biopsy system that has been used
in the US National Cancer Institute for over 6 years.

Methods
Series of 2D transverse volumetric MR image slices of the prostate
both pre (high-resolution T2-weighted)-and post (low-resolution)-needle
insertions were used to evaluate biopsy accuracy. A three-stage registration
algorithm consisting of an initial two-step rigid registration followed by a
B-spline deformable alignment was developed to capture prostate motion
during biopsy. The target displacement (distance between planned and actual
biopsy target), needle placement error (distance from planned biopsy target
to needle trajectory), and biopsy error (distance from actual biopsy target
to needle trajectory) were calculated as accuracy assessment.

Results
A total of 90 biopsies from 24 patients were studied. The
registrations were validated by checking prostate contour alignment using
image overlay, and the results were accurate to within 2 mm. The mean target
displacement, needle placement error, and clinical biopsy error were 5.2,
2.5, and 4.3 mm, respectively.

Conclusion
The biopsy error reported suggests that quantitative imaging
techniques for prostate registration and motion compensation may improve
prostate biopsy targeting accuracy.},
	number = {6},
	urldate = {2018-04-22TZ},
	journal = {International journal of computer assisted radiology and surgery},
	author = {Xu, Helen and Lasso, Andras and Guion, Peter and Krieger, Axel and Kaushal, Aradhana and Singh, Anurag K. and Pinto, Peter A. and Coleman, Jonathan and Grubb, Robert L. and Lattouf, Jean-Baptiste and Menard, Cynthia and Whitcomb, Louis L. and Fichtinger, Gabor},
	month = nov,
	year = {2013},
	pmid = {23532560},
	pmcid = {PMC4139961},
	pages = {937--944}
}

@article{nath_dosimetric_2000,
	title = {Dosimetric effects of needle divergence in prostate seed implant using 125I and 103Pd radioactive seeds},
	volume = {27},
	issn = {0094-2405},
	doi = {10.1118/1.598971},
	abstract = {In prostate seed implants, radioactive seeds are implanted into the prostate through a guiding needle with the help of a template and real-time imaging. The ideal locations of the guiding needles and the relative positions of the seeds in each needle are determined before the implantation under the assumption that the needles inserted at different locations will remain parallel. In actual implantation, the direction of the needle is subject variation. In this work, we studied how the dosimetry quality of an implant may be affected when the guiding needles deviate from its planned orientations. Needle divergence of varying degree was simulated on spherical models and actual patient implants. It was found that needle divergence degraded the dosimetric quality of an implant: The minimum target dose, the target dose coverage and therefore the tumor biological effective dose were quantitatively decreased as compared to the reference implant. The magnitude of degradation increased almost linearly with respect to the magnitude of needle divergence. For iodine-125 implants, the average reduction in minimum target dose was about 10\% and 20\% for needle divergence of standard deviation of 5(0) and 10(0), respectively. The dose coverage in the target was reduced by about 1\% and 3\% for needle divergence of standard deviation of 5(0) and 10(0), respectively. Implants designed with palladium-103 showed additional 5\% reduction in minimum target dose while the effect on dose coverage was about the same as compared to the iodine-125 implants. The degree of dosimetry degradation was shown to be dependent on the size of target volume, the seed spacing used, the use of seeding margin, and on the actual configuration of needle orientations in a given implant. One needs to minimize the physical causes of needle divergence in order to minimize its impact on planned dosimetry. The study suggests that the displacement between a needle image and its planned grid point at the base of prostate should be kept less than 5 mm in order to minimize the reduction in D(min)({\textless}5\%) and the increase in cell-survival ({\textless} a factor of 10) from the planned dosimetry.},
	language = {eng},
	number = {5},
	journal = {Medical Physics},
	author = {Nath, S. and Chen, Z. and Yue, N. and Trumpore, S. and Peschel, R.},
	month = may,
	year = {2000},
	pmid = {10841410},
	keywords = {Biophysical Phenomena, Biophysics, Brachytherapy, Humans, Iodine Radioisotopes, Male, Models, Theoretical, Palladium, Prostatic Neoplasms, Radioisotopes, Radiotherapy Planning, Computer-Assisted},
	pages = {1058--1066}
}

@article{youk_missed_2007,
	title = {Missed breast cancers at {US}-guided core needle biopsy: how to reduce them},
	volume = {27},
	issn = {1527-1323},
	shorttitle = {Missed breast cancers at {US}-guided core needle biopsy},
	doi = {10.1148/rg.271065029},
	abstract = {Ultrasonographically (US) guided core needle biopsy is currently recognized as a reliable alternative to surgical biopsy for the histopathologic diagnosis of breast lesions. However, despite advances in biopsy devices and techniques, false-negative diagnoses are unavoidable and may delay the diagnosis and treatment of breast cancer. The most common reasons for false-negative diagnosis are (a) technical or sampling errors, (b) failure to recognize or act on radiologic-histologic discordance, and (c) lack of imaging follow-up after a benign biopsy result. Technical difficulties (eg, poor lesion or needle visualization, deeply located lesions, dense fibrotic tissue) cause inaccurate sampling but can be reduced by using modified standard techniques. Radiologic-histologic correlation is also of critical importance in US-guided core needle biopsy. Radiologic-histologic discordance occurs when the histologic results do not provide a sufficient explanation for the imaging features and indicates that the lesion may not have been sampled adequately, so that repeat biopsy is warranted. Appropriate follow-up imaging is invaluable; even patients with concordant benign findings after US-guided core needle biopsy are directed to undergo follow-up imaging because there may be delays in the recognition of false-negative findings. Optimization of technique, radiologic-histologic correlation, and postbiopsy follow-up protocols are recommended to reduce the occurrence of false-negative diagnosis at US-guided core needle biopsy performed by radiologists.},
	language = {eng},
	number = {1},
	journal = {Radiographics: A Review Publication of the Radiological Society of North America, Inc},
	author = {Youk, Ji Hyun and Kim, Eun-Kyung and Kim, Min Jung and Lee, Ji Young and Oh, Ki Keun},
	month = feb,
	year = {2007},
	pmid = {17235000},
	keywords = {Biopsy, Needle, Breast Neoplasms, Diagnostic Errors, False Positive Reactions, Female, Humans, Image Enhancement, Practice Guidelines as Topic, Practice Patterns, Physicians', Quality Assurance, Health Care, Reproducibility of Results, Sensitivity and Specificity, Surgery, Computer-Assisted, Ultrasonography},
	pages = {79--94}
}

@inproceedings{reed_controlling_2009,
	title = {Controlling a robotically steered needle in the presence of torsional friction},
	doi = {10.1109/ROBOT.2009.5152749},
	abstract = {A flexible needle can be accurately steered by robotically controlling the orientation of the bevel tip as the needle is inserted into tissue. Here, we demonstrate the significant effect of friction between the long, flexible needle shaft and the tissue, which can cause a significant discrepancy between the orientation of the needle tip and the orientation of the base where the needle is controlled. Our experiments show that several common phantom tissues used in needle steering experiments impart substantial frictional forces to the needle shaft, resulting in a lag of over 45deg for a 10 cm insertion depth in some phantoms; clinical studies have reported torques large enough to could cause similar errors during needle insertions. Such angle discrepancies will result in poor performance or failure of path planners and image-guided controllers, since the needles used in percutaneous procedures are too small for state-of-the-art imaging to accurately measure the tip angle. To compensate for the angle discrepancy, we develop a model for the rotational dynamics of a needle being continuously inserted into tissue and show how a PD controller is sufficient to compensate for the rotational dynamics.},
	booktitle = {2009 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Reed, K. B. and Okamura, A. M. and Cowan, N. J.},
	month = may,
	year = {2009},
	keywords = {Automatic control, Brachytherapy, Friction, Image resolution, Imaging phantoms, Needles, PD control, PD controller, Robot control, Robotics and automation, Shafts, Ultrasonic imaging, angle discrepancy compensation, bevel tip, biological tissues, biomedical imaging, friction, image-guided controller, medical robotics, mobile robots, path planner, path planning, percutaneous procedure, robot dynamics, robotically steered needle, rotational dynamics, tissue, torsion, torsional friction},
	pages = {3476--3481}
}

@article{sze_use_2001,
	title = {Use of {Curved} {Needles} to {Perform} {Biopsies} and {Drainages} of {Inaccessible} {Targets}},
	volume = {12},
	issn = {1051-0443, 1535-7732},
	url = {http://www.jvir.org/article/S1051-0443(07)61706-0/abstract},
	doi = {10.1016/S1051-0443(07)61706-0},
	language = {English},
	number = {12},
	urldate = {2018-04-22TZ},
	journal = {Journal of Vascular and Interventional Radiology},
	author = {Sze, Daniel Y.},
	month = dec,
	year = {2001},
	pmid = {11742022},
	keywords = {Abscess, Biopsies, percutaneous drainage, technology},
	pages = {1441--1444}
}

@article{singh_core_2008,
	title = {Core {Biopsy} with {Curved} {Needle} {Technique}},
	volume = {191},
	issn = {0361-803X},
	url = {https://www.ajronline.org/doi/full/10.2214/AJR.08.1165},
	doi = {10.2214/AJR.08.1165},
	abstract = {Choose
                    Top of pageABSTRACT {\textless}{\textless}IntroductionMaterials and MethodsResultsDiscussionReferencesCITING ARTICLESOBJECTIVE. The purpose of this study was to define the technique and study the feasibility of curved needle biopsy performed with a coaxial core biopsy system.CONCLUSION. Curved core needle biopsy is a simple and feasible technique with a high technical success rate even with suboptimal coaxial needle placement. With the technique, different parts of a focal lesion can be biopsied without manipulation of the coaxial needle. This feature may help in avoiding injury to vital structures.},
	number = {6},
	urldate = {2018-04-22TZ},
	journal = {American Journal of Roentgenology},
	author = {Singh, Ajay K. and Leeman, Joshua and Shankar, Sridhar and Ferrucci, Joseph T.},
	month = dec,
	year = {2008},
	keywords = {CT-guided biopsy, biopsy gun, core biopsy, curved needle biopsy, fine-needle aspiration},
	pages = {1745--1750}
}

@article{sitzman_effects_1996,
	title = {The effects of needle type, gauge, and tip bend on spinal needle deflection},
	volume = {82},
	issn = {0003-2999},
	abstract = {Although the use of fine-gauge spinal needles reduces the incidence of postdural puncture headache, they are associated with increased risk of placement failure as a result of deflection and bending. This in vitro study quantifies spinal needle deflection from the axis of insertion with respect to needle type, gauge, and tip bend. In addition to straight-tip needles, those with standardized 5 degrees and 10 degrees tip bends were studied. The purpose was to examine the effect of tip bend, which has been described with small gauge spinal needles after bony contact, on needle path deflection. Needles studied included Quincke (Q), Sprotte (S), and Whitacre (W) in sizes ranging from 18-gauge to 29-gauge. Needles were inserted perpendicularly into porcine paraspinous muscle followed by radiologic investigation. Measurements of needle deflection from the axis of insertion at depths of 20, 40, and 60 mm were performed in a blinded fashion. Straight-tip Q needle deflection, but not W or S, was correlated with gauge and depth of insertion. Although there were differences within needle type groups, needle deflection was generally correlated with the degree of tip bend. We conclude that spinal needle deflection is dependent on the type of needle (W {\textless} S {\textless} Q), and that the magnitude of deflection is related to gauge (large {\textless} small) and tip bend (straight {\textless} 5 degrees {\textless} 10 degrees).},
	language = {eng},
	number = {2},
	journal = {Anesthesia and Analgesia},
	author = {Sitzman, B. T. and Uncles, D. R.},
	month = feb,
	year = {1996},
	pmid = {8561330},
	keywords = {Animals, In Vitro Techniques, Muscles, Needles, Spinal Puncture, Swine},
	pages = {297--301}
}

@inproceedings{reed_integrated_2008-1,
	title = {Integrated planning and image-guided control for planar needle steering},
	doi = {10.1109/BIOROB.2008.4762833},
	abstract = {Flexible, tip-steerable needles promise to enhance physicianspsila abilities to accurately reach targets and maneuver inside the human body while minimizing patient trauma. Here, we present a functional needle steering system that integrates two components: (1) a patient-specific 2D pre- and intraoperative planner that finds an achievable route to a target within a planar slice of tissue (Stochastic Motion Roadmap), and (2) a low-level image-guided feedback controller that keeps the needle tip within that slice. The planner generates a sequence of circular arcs that can be realized by interleaving pure insertions with 180deg rotations of the needle shaft. This pre-planned sequence is updated in realtime at regular intervals. Concurrently, the low-level image-based controller servos the needle to remain close to the desired plane between plan updates. Both planner and controller are predicated on a previously developed kinematic nonholonomic model of beveltip needle steering. We use slighly different needles here that have a small bend near the tip, so we extend the model to account for discontinuities of the tip position caused by 180deg rotations. Further, during large rotations of the needle base, we maintain the desired tip angle by compensating for torsional compliance in the needle shaft, neglected in previous needle steering work. By integrating planning, control, and torsion compensation, we demonstrate both accurate targeting and obstacle avoidance.},
	booktitle = {2008 2nd {IEEE} {RAS} {EMBS} {International} {Conference} on {Biomedical} {Robotics} and {Biomechatronics}},
	author = {Reed, K. B. and Kallem, V. and Alterovitz, R. and Goldbergxz, K. and Okamura, A. M. and Cowan, N. J.},
	month = oct,
	year = {2008},
	keywords = {Automatic control, Biological tissues, Biomechatronics, Control systems, Medical control systems, Needles, Physics computing, Robot sensing systems, Shafts, USA Councils, beveltip needle steering, biomedical imaging, controllers, functional needle steering system, image-guided control, intraoperative planner, kinematic nonholonomic model, low-level image-guided feedback controller, medical control systems, medical diagnostic computing, needles, patient treatment, patient-specific 2D preoperative planner, stochastic motion roadmap},
	pages = {819--824}
}

@article{webster_design_2007,
	title = {Design and {Mechanics} of {Continuum} {Robots} for {Surgery}},
	language = {en},
	author = {Webster, Robert J},
	month = dec,
	year = {2007},
	pages = {250}
}

@article{j_webster_design_2008,
	title = {Design and mechanics of continuum robots for surgery},
	author = {J Webster, Robert},
	month = jan,
	year = {2008}
}

@article{webster_mechanics_2009,
	title = {Mechanics of {Precurved}-{Tube} {Continuum} {Robots}},
	volume = {25},
	issn = {1552-3098},
	doi = {10.1109/TRO.2008.2006868},
	abstract = {This paper presents a new class of thin, dexterous continuum robots, which we call active cannulas due to their potential medical applications. An active cannula is composed of telescoping, concentric, precurved superelastic tubes that can be axially translated and rotated at the base relative to one another. Active cannulas derive bending not from tendon wires or other external mechanisms but from elastic tube interaction in the backbone itself, permitting high dexterity and small size, and dexterity improves with miniaturization. They are designed to traverse narrow and winding environments without relying on ldquoguidingrdquo environmental reaction forces. These features seem ideal for a variety of applications where a very thin robot with tentacle-like dexterity is needed. In this paper, we apply beam mechanics to obtain a kinematic model of active cannula shape and describe design tools that result from the modeling process. After deriving general equations, we apply them to a simple three-link active cannula. Experimental results illustrate the importance of including torsional effects and the ability of our model to predict energy bifurcation and active cannula shape.},
	number = {1},
	journal = {IEEE Transactions on Robotics},
	author = {Webster, R. J. and Romano, J. M. and Cowan, N. J.},
	month = feb,
	year = {2009},
	keywords = {Continuum robot, active cannulas, bifurcation, dexterous continuum robots, dexterous manipulators, elastic tube interaction, energy bifurcation, flexible manipulator, flexible manipulators, mechanics, medical applications, medical robot, medical robotics, pipes, precurved superelastic tubes, precurved-tube continuum robots, snake-like robot, telescoping superelastic tubes},
	pages = {67--78}
}

@article{swaney_toward_2016,
	title = {Toward {Transoral} {Peripheral} {Lung} {Access}: {Combining} {Continuum} {Robots} and {Steerable} {Needles}},
	volume = {02},
	issn = {2424-905X},
	shorttitle = {Toward {Transoral} {Peripheral} {Lung} {Access}},
	url = {https://www.worldscientific.com/doi/abs/10.1142/S2424905X17500015},
	doi = {10.1142/S2424905X17500015},
	abstract = {Lung cancer is the most deadly form of cancer in part because of the challenges associated with accessing nodules for diagnosis and therapy. Transoral access is preferred to percutaneous access since it has a lower risk of lung collapse, yet many sites are currently unreachable transorally due to limitations with current bronchoscopic instruments. Toward this end, we present a new robotic system for image-guided trans-bronchoscopic lung access. The system uses a bronchoscope to navigate in the airway and bronchial tubes to a site near the desired target, a concentric tube robot to move through the bronchial wall and aim at the target, and a bevel-tip steerable needle with magnetic tracking to maneuver through lung tissue to the target under closed-loop control. In this work, we illustrate the workflow of our system and show accurate targeting in phantom experiments. Ex vivo porcine lung experiments show that our steerable needle can be tuned to achieve appreciable curvature in lung tissue. Lastly, we present targeting results with our system using two scenarios based on patient cases. In these experiments, phantoms were created from patient-specific computed tomography information and our system was used to target the locations of suspicious nodules, illustrating the ability of our system to reach sites that are traditionally inaccessible transorally.},
	number = {01},
	urldate = {2018-04-21TZ},
	journal = {Journal of Medical Robotics Research},
	author = {Swaney, Philip J. and Mahoney, Arthur W. and Hartley, Bryan I. and Remirez, Andria A. and Lamers, Erik and Feins, Richard H. and Alterovitz, Ron and Webster, Robert J.},
	month = oct,
	year = {2016},
	pages = {1750001}
}

@article{pitt_follow--leader_2016,
	title = {Follow-the-{Leader} {Deployment} of {Steerable} {Needles} {Using} a {Magnetic} {Resonance}-{Compatible} {Robot} {With} {Stepper} {Actuators}},
	volume = {10},
	issn = {1932-6181},
	url = {http://medicaldevices.asmedigitalcollection.asme.org/article.aspx?articleid=2522808},
	doi = {10.1115/1.4033242},
	number = {2},
	urldate = {2018-04-21TZ},
	journal = {Journal of Medical Devices},
	author = {Pitt, E. Bryn and Comber, David B. and Chen, Yue and Neimat, Joseph S. and Webster, Robert J. and Barth, Eric J.},
	month = jun,
	year = {2016},
	pages = {020945}
}

@article{wedlick_characterization_2009,
	title = {Characterization of {Pre}-{Curved} {Needles} for {Steering} in {Tissue}},
	volume = {2009},
	issn = {1557-170X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2860535/},
	doi = {10.1109/IEMBS.2009.5333407},
	abstract = {Needles with tip asymmetry deflect upon insertion into soft tissue, an effect that can be used to steer needles within the body. This paper presents a phenomenological characterization of the steering behavior of pre-curved needles, which have tip asymmetry due to curvature of the needle near the tip. We describe needle construction methods and a needle shaft triangulation algorithm to compute the shape of the needle based on images. Experimental results show that pre-curved needles possess greater dexterity than bevel-tipped needles and achieve radii of curvature similar to pre-bent needles. For long pre-curve arc lengths, the radius of curvature of the needle was found to approach the radius of curvature of the pre-curve. Pre-curved needles were found to display behaviors not seen with bevel-tipped needles, such as the insertion velocity influencing the path of the tip within the tissue and the ability to plastically deform the needle during steering.},
	urldate = {2018-04-21TZ},
	journal = {Conference proceedings : ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Conference},
	author = {Wedlick, Thomas R. and Okamura, Allison M.},
	year = {2009},
	pmid = {19963994},
	pmcid = {PMC2860535},
	pages = {1200--1203}
}

@article{abolhassani_needle_2007,
	title = {Needle insertion into soft tissue: {A} survey},
	volume = {29},
	issn = {1350-4533},
	shorttitle = {Needle insertion into soft tissue},
	url = {http://www.sciencedirect.com/science/article/pii/S1350453306001457},
	doi = {10.1016/j.medengphy.2006.07.003},
	abstract = {Needle insertion in soft tissue has attracted considerable attention in recent years due to its application in minimally invasive percutaneous procedures such as biopsies and brachytherapy. This paper presents a survey of the current state of research on needle insertion in soft tissue. It examines the topic from several aspects, e.g. modeling needle insertion forces, modeling tissue deformation and needle deflection during insertion, robot-assisted needle insertion, and the effect of different trajectories on tissue deformation. All studies show that the axial force of a needle during insertion in soft tissue is the summation of different forces distributed along the needle shaft such as stiffness force, frictional force and cutting force. Some studies have modeled these forces. The force data in some procedures is used for identifying tissue layers as the needle is inserted or for path planning. Needle deflection and tissue deformation are major problems for accurate needle insertion and attempts have been made to model them. Using current models several insertion techniques have been developed which are briefly reviewed in this paper.},
	number = {4},
	urldate = {2018-04-21TZ},
	journal = {Medical Engineering \& Physics},
	author = {Abolhassani, Niki and Patel, Rajni and Moallem, Mehrdad},
	month = may,
	year = {2007},
	keywords = {Modeling and simulation, Needle deflection, Needle insertion, Needle steering, Robot-assisted needle insertion, Tissue deformation, Trajectory generation},
	pages = {413--431}
}

@article{swaney_flexure-based_2013,
	title = {A {Flexure}-{Based} {Steerable} {Needle}: {High} {Curvature} {With} {Reduced} {Tissue} {Damage}},
	volume = {60},
	issn = {0018-9294},
	shorttitle = {A {Flexure}-{Based} {Steerable} {Needle}},
	doi = {10.1109/TBME.2012.2230001},
	abstract = {In the quest to design higher curvature bevel-steered needles, kinked bevel-tips have been one of the most successful approaches yet proposed. However, the price to be paid for enhancing steerability in this way has been increased tissue damage, since the prebent tip cuts a local helical path into tissue when axially rotated. This is problematic when closed-loop control is desired, because the controller will typically require the needle to rotate rapidly, and it is particularly problematic when duty cycling (i.e., continual needle spinning) is used to adjust curvature. In this paper, we propose a new flexure-based needle tip design that provides the enhanced steerability of kinked bevel-tip needles, while simultaneously minimizing tissue damage.},
	number = {4},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Swaney, P. J. and Burgner, J. and Gilbert, H. B. and Webster, R. J.},
	month = apr,
	year = {2013},
	keywords = {Animals, Duty cycling, Educational institutions, Equipment Design, Models, Biological, Muscle, Skeletal, Needles, Phantoms, Phantoms, Imaging, Pliability, Robotics, Robots, Shafts, Surgery, Computer-Assisted, Swine, Tissue damage, bending, biological tissues, closed loop systems, closed-loop control, continual needle spinning, duty cycling, flexure, flexure-based steerable needle, higher curvature bevel-steered needles, image-guided surgery, kinked bevel-tips, local helical path, medical robotics, needle design, needles, prebent tip cuts, reduced tissue damage, steerability, steerable needle, surgery},
	pages = {906--909}
}

@article{wellborn_curving_2016,
	title = {Curving {Clinical} {Biopsy} {Needles}: {Can} {We} {Steer} {Needles} and {Still} {Obtain} {Core} {Biopsy} {Samples}?},
	volume = {10},
	issn = {1932-6181},
	shorttitle = {Curving {Clinical} {Biopsy} {Needles}},
	url = {http://medicaldevices.asmedigitalcollection.asme.org/article.aspx?articleid=2542235},
	doi = {10.1115/1.4033783},
	number = {3},
	urldate = {2018-04-21TZ},
	journal = {Journal of Medical Devices},
	author = {Wellborn, Patrick S. and Swaney, Philip J. and Webster, Robert J.},
	month = sep,
	year = {2016},
	pages = {030904}
}

@article{anderson_continuum_2017,
	title = {Continuum {Reconfigurable} {Parallel} {Robots} for {Surgery}: {Shape} {Sensing} and {State} {Estimation} {With} {Uncertainty}},
	volume = {2},
	shorttitle = {Continuum {Reconfigurable} {Parallel} {Robots} for {Surgery}},
	doi = {10.1109/LRA.2017.2678606},
	abstract = {This letter examines shape sensing for a new class of surgical robot that consists of parallel flexible structures that can be reconfigured inside the human body. Known as continuum reconfigurable incisionless surgical parallel (CRISP) robots, these devices provide access to the human body through needle-sized entry points, yet can be configured into trusslike structures capable of dexterous movement and large force application. They can also be reconfigured as needed during a surgical procedure. Since CRISP robots are elastic, they will deform when subjected to external forces or other perturbations. In this letter, we explore how to combine sensor information with mechanics-based models for CRISP robots to estimate their shapes under applied loads. The end result is a shape sensing framework for CRISP robots that will enable future research on control under applied loads, autonomous motion, force sensing, and other robot behaviors.},
	number = {3},
	journal = {IEEE Robotics and Automation Letters},
	author = {Anderson, P. L. and Mahoney, A. W. and Webster, R. J.},
	month = jul,
	year = {2017},
	keywords = {CRISP robots, Flexible robots, Needles, Parallel robots, Robot sensing systems, Shape, Uncertainty, autonomous motion, continuum reconfigurable incisionless surgical parallel robots, continuum reconfigurable parallel robots, dexterous manipulators, dexterous movement, flexible manipulators, force sensing, mechanics-based models, medical robotics, parallel flexible structures, shape sensing, state estimation, surgery, surgical robot, surgical robotics: laparoscopy, surgical robotics: steerable catheters/needles, truss-like structures},
	pages = {1617--1624}
}
@article{boctor_three-dimensional_2008,
	title = {Three-dimensional ultrasound-guided robotic needle placement: an experimental evaluation},
	volume = {4},
	issn = {1478-596X},
	shorttitle = {Three-dimensional ultrasound-guided robotic needle placement},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/rcs.184},
	doi = {10.1002/rcs.184},
	abstract = {Background Clinical use of image-guided needle placement robots has lagged behind laboratory-demonstrated robotic capability. Bridging this gap requires reliable and easy-to-use robotic systems. Methods Our system for image-guided needle placement requires only simple, low-cost components and minimal, entirely off-line calibration. It rapidly aligns needles to planned entry paths using 3D ultrasound (US) reconstructed from freehand 2D scans. We compare system accuracy against clinical standard manual needle placement. Results The US-guided robotic system is significantly more accurate than single manual insertions. When several manual withdrawals and reinsertions are allowed, accuracy becomes equivalent. In ex vivo experiments, robotic repeatability was 1.56 mm, compared to 3.19 and 4.63 mm for two sets of manual insertions. In an in vivo experiment with heartbeat and respiratory effects, robotic system accuracy was 5.5 mm. Conclusions A 3D US-guided robot can eliminate error bias and reduce invasiveness (the number of insertions required) compared to manual needle insertion. Remaining future challenges include target motion compensation. Copyright © 2008 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {2},
	urldate = {2018-04-21TZ},
	journal = {The International Journal of Medical Robotics and Computer Assisted Surgery},
	author = {Boctor, Emad M. and Choti, Michael A. and Burdette, Everette C. and Iii, Robert J. Webster},
	month = jun,
	year = {2008},
	keywords = {3DUS, CIS, IGT, RFA, ablation, liver, medical robots},
	pages = {180--191}
}

@article{iii_mechanics_2009,
	title = {Mechanics of {Precurved}-{Tube} {Continuum} {Robots}},
	volume = {25},
	issn = {1552-3098},
	doi = {10.1109/TRO.2008.2006868},
	abstract = {This paper presents a new class of thin, dexterous continuum robots, which we call active cannulas due to their potential medical applications. An active cannula is composed of telescoping, concentric, precurved superelastic tubes that can be axially translated and rotated at the base relative to one another. Active cannulas derive bending not from tendon wires or other external mechanisms but from elastic tube interaction in the backbone itself, permitting high dexterity and small size, and dexterity improves with miniaturization. They are designed to traverse narrow and winding environments without relying on ldquoguidingrdquo environmental reaction forces. These features seem ideal for a variety of applications where a very thin robot with tentacle-like dexterity is needed. In this paper, we apply beam mechanics to obtain a kinematic model of active cannula shape and describe design tools that result from the modeling process. After deriving general equations, we apply them to a simple three-link active cannula. Experimental results illustrate the importance of including torsional effects and the ability of our model to predict energy bifurcation and active cannula shape.},
	number = {1},
	journal = {IEEE Transactions on Robotics},
	author = {III, R. J. Webster and Romano, J. M. and Cowan, N. J.},
	month = feb,
	year = {2009},
	keywords = {Continuum robot, active cannulas, bifurcation, dexterous continuum robots, dexterous manipulators, elastic tube interaction, energy bifurcation, flexible manipulator, flexible manipulators, mechanics, medical applications, medical robot, medical robotics, pipes, precurved superelastic tubes, precurved-tube continuum robots, snake-like robot, telescoping superelastic tubes},
	pages = {67--78}
}

@article{swaney_flexure-based_2013,
	title = {A {Flexure}-{Based} {Steerable} {Needle}: {High} {Curvature} {With} {Reduced} {Tissue} {Damage}},
	volume = {60},
	issn = {0018-9294},
	shorttitle = {A {Flexure}-{Based} {Steerable} {Needle}},
	doi = {10.1109/TBME.2012.2230001},
	abstract = {In the quest to design higher curvature bevel-steered needles, kinked bevel-tips have been one of the most successful approaches yet proposed. However, the price to be paid for enhancing steerability in this way has been increased tissue damage, since the prebent tip cuts a local helical path into tissue when axially rotated. This is problematic when closed-loop control is desired, because the controller will typically require the needle to rotate rapidly, and it is particularly problematic when duty cycling (i.e., continual needle spinning) is used to adjust curvature. In this paper, we propose a new flexure-based needle tip design that provides the enhanced steerability of kinked bevel-tip needles, while simultaneously minimizing tissue damage.},
	number = {4},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Swaney, P. J. and Burgner, J. and Gilbert, H. B. and Webster, R. J.},
	month = apr,
	year = {2013},
	keywords = {Animals, Duty cycling, Educational institutions, Equipment Design, Models, Biological, Muscle, Skeletal, Needles, Phantoms, Phantoms, Imaging, Pliability, Robotics, Robots, Shafts, Surgery, Computer-Assisted, Swine, Tissue damage, bending, biological tissues, closed loop systems, closed-loop control, continual needle spinning, duty cycling, flexure, flexure-based steerable needle, higher curvature bevel-steered needles, image-guided surgery, kinked bevel-tips, local helical path, medical robotics, needle design, needles, prebent tip cuts, reduced tissue damage, steerability, steerable needle, surgery},
	pages = {906--909}
}

@article{pernelle_validation_2013,
	title = {Validation of {Catheter} {Segmentation} for {MR}-guided {Gynecologic} {Cancer} {Brachytherapy}},
	volume = {16},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4005335/},
	abstract = {Segmentation of interstitial catheters from MRI needs to be addressed in order for MRI-based brachytherapy treatment planning to become part of the clinical practice of gynecologic cancer radiotherapy. This paper presents a validation study of a novel image-processing method for catheter segmentation. The method extends the distal catheter tip, interactively provided by the physician, to its proximal end, using knowledge of catheter geometry and appearance in MRI sequences. The validation study consisted of comparison of the algorithm results to expert manual segmentations, first on images of a phantom, and then on patient MRI images obtained during MRI-guided insertion of brachytherapy catheters for the treatment of gynecologic cancer. In the phantom experiment, the maximum disagreement between automatic and manual segmentation of the same MRI image, as computed using the Hausdorf distance, was 1.5 mm, which is of the same order as the MR image spatial resolution, while the disagreement between automatic segmentation of MR images and “ground truth”, manual segmentation of CT images, was 3.5 mm. The segmentation method was applied to an IRB-approved retrospective database of 10 interstitial brachytherapy patients which included a total of 101 catheters. Compared with manual expert segmentations, the automatic method correctly segmented 93 out of 101 catheters, at an average rate of 0.3 seconds per catheter using a 3GHz Intel Core i7 computer with 16 GB RAM and running Mac OS X 10.7. These results suggest that the proposed catheter segmentation is both technically and clinically feasible.},
	number = {0 3},
	urldate = {2018-04-17TZ},
	journal = {Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention},
	author = {Pernelle, Guillaume and Mehrtash, Alireza and Barber, Lauren and Damato, Antonio and Wang, Wei and Seethamraju, Ravi Teja and Schmidt, Ehud and Cormack, Robert and Wells, Williams and Viswanathan, Akila and Kapur, Tina},
	year = {2013},
	pmid = {24505784},
	pmcid = {PMC4005335},
	pages = {380--387}
}

@article{pernelle_validation_2013-1,
	title = {Validation of catheter segmentation for {MR}-guided gynecologic cancer brachytherapy},
	volume = {16},
	abstract = {Segmentation of interstitial catheters from MRI needs to be addressed in order for MRI-based brachytherapy treatment planning to become part of the clinical practice of gynecologic cancer radiotherapy. This paper presents a validation study of a novel image-processing method for catheter segmentation. The method extends the distal catheter tip, interactively provided by the physician, to its proximal end, using knowledge of catheter geometry and appearance in MRI sequences. The validation study consisted of comparison of the algorithm results to expert manual segmentations, first on images of a phantom, and then on patient MRI images obtained during MRI-guided insertion of brachytherapy catheters for the treatment of gynecologic cancer. In the phantom experiment, the maximum disagreement between automatic and manual segmentation of the same MRI image, as computed using the Hausdorf distance, was 1.5 mm, which is of the same order as the MR image spatial resolution, while the disagreement between automatic segmentation of MR images and "ground truth", manual segmentation of CT images, was 3.5 mm. The segmentation method was applied to an IRB-approved retrospective database of 10 interstitial brachytherapy patients which included a total of 101 catheters. Compared with manual expert segmentations, the automatic method correctly segmented 93 out of 101 catheters, at an average rate of 0.3 seconds per catheter using a 3 GHz Intel Core i7 computer with 16 GB RAM and running Mac OS X 10.7. These results suggest that the proposed catheter segmentation is both technically and clinically feasible.},
	language = {eng},
	number = {Pt 3},
	journal = {Medical image computing and computer-assisted intervention: MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention},
	author = {Pernelle, Guillaume and Mehrtash, Alireza and Barber, Lauren and Damato, Antonio and Wang, Wei and Seethamraju, Ravi Teja and Schmidt, Ehud and Cormack, Robert A. and Wells, Williams and Viswanathan, Akila and Kapur, Tina},
	year = {2013},
	pmid = {24505784},
	pmcid = {PMC4005335},
	keywords = {Artifacts, Brachytherapy, Catheters, Indwelling, Female, Humans, Magnetic Resonance Imaging, Interventional, Pattern Recognition, Automated, Prostheses and Implants, Reproducibility of Results, Sensitivity and Specificity, Uterine Cervical Neoplasms},
	pages = {380--387}
}

@article{khadem_ultrasound-guided_2016,
	title = {Ultrasound-{Guided} {Model} {Predictive} {Control} of {Needle} {Steering} in {Biological} {Tissue}},
	volume = {01},
	issn = {2424-905X},
	url = {https://www.worldscientific.com/doi/abs/10.1142/S2424905X16400079},
	doi = {10.1142/S2424905X16400079},
	abstract = {In needle-based medical procedures, beveled tip flexible needles are steered inside soft tissue to reach the desired target locations. In this paper, we have developed an autonomous image-guided needle steering system that enhances targeting accuracy in needle insertion while minimizing tissue trauma. The system has three main components. First is a novel mechanics-based needle steering model that predicts needle deflection and accepts needle tip rotation as an input for needle steering. The second is a needle tip tracking system that determines needle deflection from the ultrasound images. The needle steering model employs the estimated needle deflection at the present time to predict needle tip trajectory in the future steps. The third component is a nonlinear model predictive controller (NMPC) that steers the needle inside the tissue by rotating the needle beveled tip. The MPC controller calculates control decisions based on iterative optimization of the predictions of the needle steering model. To validate the proposed ultrasound-guided needle steering system, needle insertion experiments in biological tissue phantoms are performed in two cases–with and without obstacle. The results demonstrate that our needle steering strategy guides the needle to the desired targets with the maximum error of 2.85{\textless}math display="inline" overflow="scroll" altimg="eq-00001.gif"{\textgreater}{\textless}mspace width=".17em"{\textgreater}{\textless}/mspace{\textgreater}{\textless}/math{\textgreater}mm.},
	number = {01},
	urldate = {2018-04-17TZ},
	journal = {Journal of Medical Robotics Research},
	author = {Khadem, Mohsen and Rossa, Carlos and Sloboda, Ron S. and Usmani, Nawaid and Tavakoli, Mahdi},
	month = mar,
	year = {2016},
	pages = {1640007}
}

@phdthesis{janga_fast_2013,
	address = {Worcester, MA},
	title = {A {Fast} and {Robust} {Image}-{Based} {Method} for tracking {Robot}-assisted {Needle} {Placement} in {Real}-time {MR} {Images}},
	url = {https://web.wpi.edu/Pubs/ETD/Available/etd-011514-181525/unrestricted/sjanga.pdf},
	abstract = {This thesis deals with automatic localization and tracking of surgical tools such as needles in Magnetic Resonance Imaging(MRI). The accurate and precise localization of needles is very important for medical interventions such as biopsy, brachytherapy, anaesthesia and many other needle based percutaneous interventions. Needle tracking has to be really precise, because the target may reside adjacent to organs which are sensitive to injury. More over during the needle insertion, Magnetic Resonance Imaging(MRI) scan plane must be aligned such that needle is in the field of view (FOV) for surgeon. Many approaches were proposed for needle tracking and automatic MRI scan plane control over last decade that use external markers, but they are not able to account for possible needle bending. Significant amount of work has already been done by using the image based approaches for needle tracking in Image Guided Therapy (IGT) but the existing approaches for surgical robots under MRI guidance are purely based on imaging information; they are missing the important fact that, a lot of important information (for example, depth of insertion, entry point and angle of insertion) is available from the kinematic model of the robot. The existing approaches are also not considering the fact that the needle insertion results in a time sequence of images. So the information about needle positions from the images seen so far can be used to make an approximate estimate about the needle position in the subsequent images. During the course of this thesis we have investigated an image based approach for needle tracking in real-time MR images that leverages additional information available from robot's kinematics model, supplementing the acquired images. The proposed approach uses Standard Hough Transform(SHT) for needle detection in 2D MR image and uses Kalman Filter for tracking the needle over the sequence of images. We have demonstrated experimental validation of the method on Real MRI data using gel phantom and artificially created test images. The results proved that the proposed method can track the needle tip position with root mean squared error of 1.5 mm for straight needle and 2.5mm for curved needle.},
	urldate = {2018-04-16TZ},
	school = {Worcester Polytechnic Institute},
	author = {Janga, Satyanarayana Reddy},
	month = jul,
	year = {2013}
}

@misc{noauthor_title_nodate,
	title = {Title page for {ETD} etd-011514-181525},
	url = {https://web.wpi.edu/Pubs/ETD/Available/etd-011514-181525/},
	urldate = {2018-04-16TZ}
}

@article{rossa_adaptive_2016,
	title = {Adaptive {Quasi}-{Static} {Modelling} of {Needle} {Deflection} {During} {Steering} in {Soft} {Tissue}},
	volume = {1},
	doi = {10.1109/LRA.2016.2527065},
	abstract = {In this letter, we present a model for needle deflection estimation in soft tissue. The needle is modelled as a vibrating compliant cantilever beam that experiences forces applied by the tissue as it is inserted. Each of the assumed vibration modes are associated with a weighting coefficient whose magnitude is calculated using the minimum potential energy method. The model only requires as input the tissue stiffness and needle-tissue cutting force. Contributions of this letter include the estimation of needle-tissue contact forces as a function of the tissue displacement along the needle shaft, while allowing for multiple bends of the needle. The model is combined with partial ultrasound image feedback in order to adaptively calculate the needle-tissue cutting force as the needle is inserted. The image feedback is obtained by an ultrasound probe that follows the needle tip and stops at an appropriate position to avoid further tissue displacement. Images obtained during early stages of the insertion are used to predict the deflection of the needle further along the insertion process. Experimental results in biological and phantom tissue show an average error in predicting needle deflection of 0.36 mm.},
	number = {2},
	journal = {IEEE Robotics and Automation Letters},
	author = {Rossa, C. and Khadem, M. and Sloboda, R. and Usmani, N. and Tavakoli, M.},
	month = jul,
	year = {2016},
	keywords = {Biological system modeling, Biological tissues, Deformable models, Force, Medical robots and systems, Needles, Shafts, Ultrasonic imaging, adaptive quasistatic modelling, beams (structures), biological tissues, biomedical equipment, biomedical ultrasonics, cantilevers, mechanical contact, medical computing, medical image processing, medical robotics, medical robots, minimum potential energy method, needle deection, needle deflection, needle deflection estimation, needle shaft, needle-tissue contact force estimation, needle-tissue cutting force, needle-tissue interaction, partial ultrasound image feedback, quasi-static modelling, soft tissue steering, steerable needles, tissue displacement, tissue stiffness, ultrasonic imaging, ultrasound probe, vibrating compliant cantilever beam, vibrations, weighting coefficient},
	pages = {916--923}
}

@inproceedings{carriere_needle_2015,
	title = {Needle shape estimation in soft tissue based on partial ultrasound image observation},
	doi = {10.1109/ICRA.2015.7139501},
	abstract = {We propose a method to estimate the entire shape of a long flexible needle, suitable for a needle insertion assistant robot. This method bases its prediction on only a small segment of a needle, imaged via ultrasound, after insertion. An algorithm is developed that can segment a needle observed partially in ultrasound images and fully in camera images, returning a polynomial representation of the needle shape after RANSAC processing. The polynomial corresponding to the partial needle observation in ultrasound images is used as the input to a needle-tissue interaction model that predicts the entire needle shape. The needle shape predicted by the model is compared to the segmented needle shape based on camera images to validate the proposed approach. The results show that the entire needle shape can be accurately predicted in tissues of varying stiffness based on observation of parts of the needle in an ultrasound image.},
	booktitle = {2015 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Carriere, J. and Rossa, C. and Usmani, N. and Sloboda, R. and Tavakoli, M.},
	month = may,
	year = {2015},
	keywords = {Cameras, Image segmentation, Needles, Polynomials, Probes, RANSAC processing, Shape, Ultrasonic imaging, biological tissues, biomedical ultrasonics, camera images, flexible needle, image representation, medical image processing, medical robotics, needle insertion assistant robot, needle observation, needle shape estimation, needle shape polynomial representation, needle shape prediction, needle-tissue interaction model, needles, partial ultrasound image observation, random processes, random sample consensus, sampling methods, shape recognition, soft tissue, stiffness},
	pages = {2277--2282}
}

@article{barnett_fracture_2015,
	title = {Fracture {Mechanics} {Model} of {Needle} {Cutting} {Tissue}},
	volume = {138},
	issn = {1087-1357},
	url = {http://dx.doi.org/10.1115/1.4030374},
	doi = {10.1115/1.4030374},
	abstract = {This work develops a needle insertion force model based on fracture mechanics, which incorporates the fracture toughness, shear modulus, and friction force of the needle and tissue. Ex vivo tissue experiments were performed to determine these mechanical tissue properties. A double insertion of the needle into the tissue was utilized to determine the fracture toughness. The shear modulus was found by applying an Ogden fit to the stress–strain curve of the tissue achieved through tension experiments. The frictional force was measured by inserting the needle through precut tissue. Results show that the force model predicts within 0.2 N of experimental needle insertion force and the fracture toughness is primarily affected by the needle diameter and needle edge geometry. On average, the tearing force was found to account for 61\% of the total insertion force, the spreading force to account for 18\%, and the friction force to account for the remaining 21\%.},
	number = {1},
	urldate = {2018-04-16TZ},
	journal = {Journal of Manufacturing Science and Engineering},
	author = {Barnett, Andrew C. and Lee, Yuan-Shin and Moore, Jason Z.},
	month = sep,
	year = {2015},
	pages = {011005--011005--8}
}

@article{goksel_modeling_2009,
	title = {Modeling and simulation of flexible needles},
	volume = {31},
	issn = {1350-4533},
	url = {http://www.medengphys.com/article/S1350-4533(09)00147-7/fulltext},
	doi = {10.1016/j.medengphy.2009.07.007},
	language = {English},
	number = {9},
	urldate = {2018-04-16TZ},
	journal = {Medical Engineering and Physics},
	author = {Goksel, Orcun and Dehghan, Ehsan and Salcudean, Septimiu E.},
	month = nov,
	year = {2009},
	pmid = {19674926},
	keywords = {Angular springs, Brachytherapy simulation, Flexible needles, Modeling bending, Twisting/torsion},
	pages = {1069--1078}
}

@article{rossa_issues_2017,
	title = {Issues in closed-loop needle steering},
	volume = {62},
	issn = {0967-0661},
	url = {http://www.sciencedirect.com/science/article/pii/S0967066117300606},
	doi = {10.1016/j.conengprac.2017.03.004},
	abstract = {Percutaneous needle insertion is amongst the most prevalent clinical procedures. The effectiveness of needle-base interventions heavily relies on needle targeting accuracy. However, the needle interacts with the surrounding tissue during insertion and deflects away from its intended trajectory. To overcome this problem, a significant research effort has been made towards developing robotic systems to automatically steer bevel-tipped needles percutaneously, which is a comprehensive and challenging control problem. A flexible needle inserted in soft tissue is an under-actuated system with nonholonomic constraints. Closed-loop feedback control of needle in tissue is challenging due to measurement errors, unmodelled dynamics created by tissue heterogeneity, and motion of targets within the tissue. In this paper, we review recent progress made in each of the complementary components that constitute a closed-loop needle steering system, including modelling needle-tissue interaction, sensing needle deflection, controlling needle trajectory, and hardware implementation.},
	urldate = {2018-04-16TZ},
	journal = {Control Engineering Practice},
	author = {Rossa, Carlos and Tavakoli, Mahdi},
	month = may,
	year = {2017},
	keywords = {Feedback control, Robotic assistance, Sensors, Steerable needles, Surgical robotics},
	pages = {55--69}
}

@article{dehghan_needle_2009,
	title = {Needle {Insertion} {Parameter} {Optimization} for {Brachytherapy}},
	volume = {25},
	issn = {1552-3098},
	doi = {10.1109/TRO.2008.2011415},
	abstract = {This paper presents a new needle path planning method for the insertion of rigid needles into deformable tissue. The needle insertion point, needle heading, and needle depth are optimized by minimizing the distance between a rigid needle and a number of targets in the tissue. The optimization method is based on iterative simulations performed using a tissue finite element model. At each iteration, the best 3-D line fitted to the displaced targets in the deformed tissue is used as a candidate for a new insertion line. First, this method is implemented in a prostate brachytherapy simulator under different boundary conditions to minimize the targeting error. It is shown that the optimization method converges in a few iterations and decreases the seed misplacement error to less than the needle diameter. Second, the efficacy of the optimization algorithm is verified by optimizing the insertion parameters for a brachytherapy needle before insertion into a prostate tissue phantom. The elastic properties of the phantom and the needle-tissue interaction parameters were identified in an independent experiment. The optimization algorithm is effective in decreasing the targeting error.},
	number = {2},
	journal = {IEEE Transactions on Robotics},
	author = {Dehghan, E. and Salcudean, S. E.},
	month = apr,
	year = {2009},
	keywords = {Brachytherapy, Finite Element Method (FEM), brachytherapy, brachytherapy needle, finite element analysis, medical robotics, needle depth, needle heading, needle insertion, needle insertion parameter optimization, needle insertion point, needle path planning, needle path planning method, needle-tissue interaction parameters, needles, optimization algorithm, path planning, phantom elastic properties, prostate brachytherapy simulator, prostate tissue phantom, seed misplacement error, tissue finite element model},
	pages = {303--315}
}

@article{chentanez_interactive_2009,
	title = {Interactive {Simulation} of {Surgical} {Needle} {Insertion} and {Steering}},
	abstract = {We present algorithms for simulating and visualizing the insertion and steering of needles through deformable tissues for surgical training and planning. Needle insertion is an essential component of many clinical procedures such as biopsies, injections, neurosurgery, and brachytherapy cancer treatment. The success of these procedures depends on accurate guidance of the needle tip to a clinical target while avoiding vital tissues. Needle insertion deforms body tissues, making accurate placement diﬃcult. Our interactive needle insertion simulator models the coupling between a steerable needle and deformable tissue. We introduce (1) a novel algorithm for local remeshing that quickly enforces the conformity of a tetrahedral mesh to a curvilinear needle path, enabling accurate computation of contact forces, (2) an eﬃcient method for coupling a 3D ﬁnite element simulation with a 1D inextensible rod with stick-slip friction, and (3) optimizations that reduce the computation time for physically based simulations. We can realistically and interactively simulate needle insertion into a prostate mesh of 13,375 tetrahedra and 2,763 vertices at a 25 Hz frame rate on an 8-core 3.0 GHz Intel Xeon PC. The simulation models prostate brachytherapy with needles of varying stiﬀness, steering needles around obstacles, and supports motion planning for robotic needle insertion. We evaluate the accuracy of the simulation by comparing against real-world experiments in which ﬂexible, steerable needles were inserted into gel tissue phantoms.},
	language = {en},
	author = {Chentanez, Alterovitz and Ritchie, Cho and Hauser, Goldberg and Shewchuk, O'Brien},
	year = {2009},
	pages = {10}
}

@article{misra_mechanics_2010,
	title = {Mechanics of {Flexible} {Needles} {Robotically} {Steered} through {Soft} {Tissue}},
	volume = {29},
	issn = {0278-3649},
	url = {https://doi.org/10.1177/0278364910369714},
	doi = {10.1177/0278364910369714},
	abstract = {The tip asymmetry of a bevel-tip needle results in the needle naturally bending when it is inserted into soft tissue. This enables robotic needle steering, which can be used in medical procedures to reach subsurface targets inaccessible by straight-line trajectories. However, accurate path planning and control of needle steering require models of needle-tissue interaction. Previous kinematic models required empirical observations of each needle and tissue combination in order to fit model parameters. This study describes a mechanics-based model of robotic needle steering, which can be used to predict needle behavior and optimize system design based on fundamental mechanical and geometrical properties of the needle and tissue. We first present an analytical model for the loads developed at the tip, based on the geometry of the bevel edge and material properties of soft-tissue simulants (gels). We then present a mechanics-based model that calculates the deflection of a bevel-tipped needle inserted through a soft elastic medium. The model design is guided by microscopic observations of needle-gel interactions. The energy-based formulation incorporates tissue-specific parameters, and the geometry and material properties of the needle. Simulation results follow similar trends (deflection and radius of curvature) to those observed in experimental studies of robotic needle insertion.},
	language = {en},
	number = {13},
	urldate = {2018-04-16TZ},
	journal = {The International Journal of Robotics Research},
	author = {Misra, S. and Reed, K.B. and Schafer, B.W. and Ramesh, K.T. and Okamura, A.M.},
	month = nov,
	year = {2010},
	pages = {1640--1660}
}

@article{rossa_adaptive_2016-1,
	title = {Adaptive {Quasi}-{Static} {Modelling} of {Needle} {Deflection} {During} {Steering} in {Soft} {Tissue}},
	volume = {1},
	doi = {10.1109/LRA.2016.2527065},
	abstract = {In this letter, we present a model for needle deflection estimation in soft tissue. The needle is modelled as a vibrating compliant cantilever beam that experiences forces applied by the tissue as it is inserted. Each of the assumed vibration modes are associated with a weighting coefficient whose magnitude is calculated using the minimum potential energy method. The model only requires as input the tissue stiffness and needle-tissue cutting force. Contributions of this letter include the estimation of needle-tissue contact forces as a function of the tissue displacement along the needle shaft, while allowing for multiple bends of the needle. The model is combined with partial ultrasound image feedback in order to adaptively calculate the needle-tissue cutting force as the needle is inserted. The image feedback is obtained by an ultrasound probe that follows the needle tip and stops at an appropriate position to avoid further tissue displacement. Images obtained during early stages of the insertion are used to predict the deflection of the needle further along the insertion process. Experimental results in biological and phantom tissue show an average error in predicting needle deflection of 0.36 mm.},
	number = {2},
	journal = {IEEE Robotics and Automation Letters},
	author = {Rossa, C. and Khadem, M. and Sloboda, R. and Usmani, N. and Tavakoli, M.},
	month = jul,
	year = {2016},
	keywords = {Biological system modeling, Biological tissues, Deformable models, Force, Medical robots and systems, Needles, Shafts, Ultrasonic imaging, adaptive quasistatic modelling, beams (structures), biological tissues, biomedical equipment, biomedical ultrasonics, cantilevers, mechanical contact, medical computing, medical image processing, medical robotics, medical robots, minimum potential energy method, needle deection, needle deflection, needle deflection estimation, needle shaft, needle-tissue contact force estimation, needle-tissue cutting force, needle-tissue interaction, partial ultrasound image feedback, quasi-static modelling, soft tissue steering, steerable needles, tissue displacement, tissue stiffness, ultrasonic imaging, ultrasound probe, vibrating compliant cantilever beam, vibrations, weighting coefficient},
	pages = {916--923}
}

@article{misra_mechanics_2010-1,
	title = {Mechanics of {Flexible} {Needles} {Robotically} {Steered} through {Soft} {Tissue}},
	volume = {29},
	issn = {0278-3649},
	url = {https://doi.org/10.1177/0278364910369714},
	doi = {10.1177/0278364910369714},
	abstract = {The tip asymmetry of a bevel-tip needle results in the needle naturally bending when it is inserted into soft tissue. This enables robotic needle steering, which can be used in medical procedures to reach subsurface targets inaccessible by straight-line trajectories. However, accurate path planning and control of needle steering require models of needle-tissue interaction. Previous kinematic models required empirical observations of each needle and tissue combination in order to fit model parameters. This study describes a mechanics-based model of robotic needle steering, which can be used to predict needle behavior and optimize system design based on fundamental mechanical and geometrical properties of the needle and tissue. We first present an analytical model for the loads developed at the tip, based on the geometry of the bevel edge and material properties of soft-tissue simulants (gels). We then present a mechanics-based model that calculates the deflection of a bevel-tipped needle inserted through a soft elastic medium. The model design is guided by microscopic observations of needle-gel interactions. The energy-based formulation incorporates tissue-specific parameters, and the geometry and material properties of the needle. Simulation results follow similar trends (deflection and radius of curvature) to those observed in experimental studies of robotic needle insertion.},
	language = {en},
	number = {13},
	urldate = {2018-04-16TZ},
	journal = {The International Journal of Robotics Research},
	author = {Misra, S. and Reed, K.B. and Schafer, B.W. and Ramesh, K.T. and Okamura, A.M.},
	month = nov,
	year = {2010},
	pages = {1640--1660}
}

@article{rossa_adaptive_2016-2,
	title = {Adaptive {Quasi}-{Static} {Modelling} of {Needle} {Deflection} {During} {Steering} in {Soft} {Tissue}},
	volume = {1},
	doi = {10.1109/LRA.2016.2527065},
	abstract = {In this letter, we present a model for needle deflection estimation in soft tissue. The needle is modelled as a vibrating compliant cantilever beam that experiences forces applied by the tissue as it is inserted. Each of the assumed vibration modes are associated with a weighting coefficient whose magnitude is calculated using the minimum potential energy method. The model only requires as input the tissue stiffness and needle-tissue cutting force. Contributions of this letter include the estimation of needle-tissue contact forces as a function of the tissue displacement along the needle shaft, while allowing for multiple bends of the needle. The model is combined with partial ultrasound image feedback in order to adaptively calculate the needle-tissue cutting force as the needle is inserted. The image feedback is obtained by an ultrasound probe that follows the needle tip and stops at an appropriate position to avoid further tissue displacement. Images obtained during early stages of the insertion are used to predict the deflection of the needle further along the insertion process. Experimental results in biological and phantom tissue show an average error in predicting needle deflection of 0.36 mm.},
	number = {2},
	journal = {IEEE Robotics and Automation Letters},
	author = {Rossa, C. and Khadem, M. and Sloboda, R. and Usmani, N. and Tavakoli, M.},
	month = jul,
	year = {2016},
	keywords = {Biological system modeling, Biological tissues, Deformable models, Force, Medical robots and systems, Needles, Shafts, Ultrasonic imaging, adaptive quasistatic modelling, beams (structures), biological tissues, biomedical equipment, biomedical ultrasonics, cantilevers, mechanical contact, medical computing, medical image processing, medical robotics, medical robots, minimum potential energy method, needle deection, needle deflection, needle deflection estimation, needle shaft, needle-tissue contact force estimation, needle-tissue cutting force, needle-tissue interaction, partial ultrasound image feedback, quasi-static modelling, soft tissue steering, steerable needles, tissue displacement, tissue stiffness, ultrasonic imaging, ultrasound probe, vibrating compliant cantilever beam, vibrations, weighting coefficient},
	pages = {916--923}
}

@article{rossa_adaptive_2016-3,
	title = {Adaptive {Quasi}-{Static} {Modelling} of {Needle} {Deflection} {During} {Steering} in {Soft} {Tissue}},
	volume = {1},
	doi = {10.1109/LRA.2016.2527065},
	abstract = {In this letter, we present a model for needle deflection estimation in soft tissue. The needle is modelled as a vibrating compliant cantilever beam that experiences forces applied by the tissue as it is inserted. Each of the assumed vibration modes are associated with a weighting coefficient whose magnitude is calculated using the minimum potential energy method. The model only requires as input the tissue stiffness and needle-tissue cutting force. Contributions of this letter include the estimation of needle-tissue contact forces as a function of the tissue displacement along the needle shaft, while allowing for multiple bends of the needle. The model is combined with partial ultrasound image feedback in order to adaptively calculate the needle-tissue cutting force as the needle is inserted. The image feedback is obtained by an ultrasound probe that follows the needle tip and stops at an appropriate position to avoid further tissue displacement. Images obtained during early stages of the insertion are used to predict the deflection of the needle further along the insertion process. Experimental results in biological and phantom tissue show an average error in predicting needle deflection of 0.36 mm.},
	number = {2},
	journal = {IEEE Robotics and Automation Letters},
	author = {Rossa, C. and Khadem, M. and Sloboda, R. and Usmani, N. and Tavakoli, M.},
	month = jul,
	year = {2016},
	keywords = {Biological system modeling, Biological tissues, Deformable models, Force, Medical robots and systems, Needles, Shafts, Ultrasonic imaging, adaptive quasistatic modelling, beams (structures), biological tissues, biomedical equipment, biomedical ultrasonics, cantilevers, mechanical contact, medical computing, medical image processing, medical robotics, medical robots, minimum potential energy method, needle deection, needle deflection, needle deflection estimation, needle shaft, needle-tissue contact force estimation, needle-tissue cutting force, needle-tissue interaction, partial ultrasound image feedback, quasi-static modelling, soft tissue steering, steerable needles, tissue displacement, tissue stiffness, ultrasonic imaging, ultrasound probe, vibrating compliant cantilever beam, vibrations, weighting coefficient},
	pages = {916--923}
}

@article{rossa_issues_2017-1,
	title = {Issues in closed-loop needle steering},
	volume = {62},
	issn = {0967-0661},
	url = {http://www.sciencedirect.com/science/article/pii/S0967066117300606},
	doi = {10.1016/j.conengprac.2017.03.004},
	abstract = {Percutaneous needle insertion is amongst the most prevalent clinical procedures. The effectiveness of needle-base interventions heavily relies on needle targeting accuracy. However, the needle interacts with the surrounding tissue during insertion and deflects away from its intended trajectory. To overcome this problem, a significant research effort has been made towards developing robotic systems to automatically steer bevel-tipped needles percutaneously, which is a comprehensive and challenging control problem. A flexible needle inserted in soft tissue is an under-actuated system with nonholonomic constraints. Closed-loop feedback control of needle in tissue is challenging due to measurement errors, unmodelled dynamics created by tissue heterogeneity, and motion of targets within the tissue. In this paper, we review recent progress made in each of the complementary components that constitute a closed-loop needle steering system, including modelling needle-tissue interaction, sensing needle deflection, controlling needle trajectory, and hardware implementation.},
	urldate = {2018-04-15TZ},
	journal = {Control Engineering Practice},
	author = {Rossa, Carlos and Tavakoli, Mahdi},
	month = may,
	year = {2017},
	keywords = {Feedback control, Robotic assistance, Sensors, Steerable needles, Surgical robotics},
	pages = {55--69}
}

@article{rossa_issues_2017-2,
	title = {Issues in closed-loop needle steering},
	volume = {62},
	issn = {0967-0661},
	url = {http://www.sciencedirect.com/science/article/pii/S0967066117300606},
	doi = {10.1016/j.conengprac.2017.03.004},
	abstract = {Percutaneous needle insertion is amongst the most prevalent clinical procedures. The effectiveness of needle-base interventions heavily relies on needle targeting accuracy. However, the needle interacts with the surrounding tissue during insertion and deflects away from its intended trajectory. To overcome this problem, a significant research effort has been made towards developing robotic systems to automatically steer bevel-tipped needles percutaneously, which is a comprehensive and challenging control problem. A flexible needle inserted in soft tissue is an under-actuated system with nonholonomic constraints. Closed-loop feedback control of needle in tissue is challenging due to measurement errors, unmodelled dynamics created by tissue heterogeneity, and motion of targets within the tissue. In this paper, we review recent progress made in each of the complementary components that constitute a closed-loop needle steering system, including modelling needle-tissue interaction, sensing needle deflection, controlling needle trajectory, and hardware implementation.},
	urldate = {2018-04-15TZ},
	journal = {Control Engineering Practice},
	author = {Rossa, Carlos and Tavakoli, Mahdi},
	month = may,
	year = {2017},
	keywords = {Feedback control, Robotic assistance, Sensors, Steerable needles, Surgical robotics},
	pages = {55--69}
}

@article{khadem_ultrasound-guided_2016-1,
	title = {Ultrasound-{Guided} {Model} {Predictive} {Control} of {Needle} {Steering} in {Biological} {Tissue}},
	volume = {01},
	issn = {2424-905X},
	url = {https://www.worldscientific.com/doi/abs/10.1142/S2424905X16400079},
	doi = {10.1142/S2424905X16400079},
	abstract = {In needle-based medical procedures, beveled tip flexible needles are steered inside soft tissue to reach the desired target locations. In this paper, we have developed an autonomous image-guided needle steering system that enhances targeting accuracy in needle insertion while minimizing tissue trauma. The system has three main components. First is a novel mechanics-based needle steering model that predicts needle deflection and accepts needle tip rotation as an input for needle steering. The second is a needle tip tracking system that determines needle deflection from the ultrasound images. The needle steering model employs the estimated needle deflection at the present time to predict needle tip trajectory in the future steps. The third component is a nonlinear model predictive controller (NMPC) that steers the needle inside the tissue by rotating the needle beveled tip. The MPC controller calculates control decisions based on iterative optimization of the predictions of the needle steering model. To validate the proposed ultrasound-guided needle steering system, needle insertion experiments in biological tissue phantoms are performed in two cases–with and without obstacle. The results demonstrate that our needle steering strategy guides the needle to the desired targets with the maximum error of 2.85{\textless}math display="inline" overflow="scroll" altimg="eq-00001.gif"{\textgreater}{\textless}mspace width=".17em"{\textgreater}{\textless}/mspace{\textgreater}{\textless}/math{\textgreater}mm.},
	number = {01},
	urldate = {2018-04-15TZ},
	journal = {Journal of Medical Robotics Research},
	author = {Khadem, Mohsen and Rossa, Carlos and Sloboda, Ron S. and Usmani, Nawaid and Tavakoli, Mahdi},
	month = mar,
	year = {2016},
	pages = {1640007}
}

@article{roesthuis_three-dimensional_2014,
	title = {Three-{Dimensional} {Needle} {Shape} {Reconstruction} {Using} an {Array} of {Fiber} {Bragg} {Grating} {Sensors}},
	volume = {19},
	issn = {1083-4435},
	doi = {10.1109/TMECH.2013.2269836},
	abstract = {We present a prototype of a flexible nitinol needle (φ 1.0 mm and length 172 mm) integrated with an array of 12 Fiber Bragg Grating (FBG) sensors. These sensors measure the axial strain, which enables the computation of the needle curvature. We reconstruct the three-dimensional (3-D) needle shape from the curvature. Experiments are performed where the needle is deflected in free space. The maximum errors between the experiments and beam theory-based model are 0.20 mm (in-plane deflection with single bend), 0.51 mm (in-plane deflection with double bend), and 1.66 mm (out-of-plane). We also describe kinematics-based and mechanics-based models for predicting the 3-D needle shape during insertion into soft tissue. We perform experiments where the needle is inserted into a soft-tissue simulant, and the 3-D needle shape is reconstructed using the FBG sensors. We compare the reconstructed needle shape to deflection obtained from camera images and our models. The maximum error between the experiments and the camera images is 0.74 mm. The maximum errors between the kinematics-based and mechanics-based models and the camera images are 3.77 mm and 2.20 mm, respectively. This study demonstrates that deflection models and needles integrated with FBG sensors have the potential to be used in combination with clinical imaging modalities in order to enable accurate needle steering.},
	number = {4},
	journal = {IEEE/ASME Transactions on Mechatronics},
	author = {Roesthuis, R. J. and Kemp, M. and Dobbelsteen, J. J. van den and Misra, S.},
	month = aug,
	year = {2014},
	keywords = {3D needle shape, Bragg gratings, FBG sensors, Fiber Bragg gratings (FBGs), Fiber gratings, Force, Needles, Sensors, Shape, Strain, axial strain measurement, beam theory-based model, biomedical equipment, clinical imaging modalities, fiber Bragg grating sensors, fibre optic sensors, flexible nitinol needle, in-plane deflection, kinematics-based model, kinematics-based models, mechanics-based model, mechanics-based models, needle curvature, needle deflection models, needles, shape reconstruction, soft tissue, soft-tissue simulant, strain measurement, three-dimensional needle shape reconstruction},
	pages = {1115--1126}
}

@article{khadem_two-body_2016,
	title = {A {Two}-{Body} {Rigid}/{Flexible} {Model} of {Needle} {Steering} {Dynamics} in {Soft} {Tissue}},
	volume = {21},
	issn = {1083-4435},
	doi = {10.1109/TMECH.2016.2549505},
	abstract = {Robotics-assisted needle steering can enhance targeting accuracy in percutaneous interventions. This paper presents a novel dynamical model for robotically controlled needle steering. This is the first model that predicts both needle shape and tip position in soft tissue, and accepts needle insertion velocity, needle 180° axial rotation, and needle base force/torque as inputs. A hybrid formulation of needle steering dynamics in soft tissue is presented, which considers the needle as a two-body rigid/flexible coupled system composed of a moving, discrete, and rigid part attached to a vibrating compliant part that is subject to external excitation forces. The former is the carrier representing the surgeon's hand or the needle inserting robot, while the latter is a beam modeling the continuous deflection of the needle inside tissue. A novel time-delayed tissue model and a fracture mechanics-based model are developed to model the tissue reaction forces and cutting force at the needle tip, respectively. Experiments are performed on synthetic and ex vivo animal tissues to identify the model parameters and validate the needle steering model. The maximum error of the 2-D model in predicting the needle tip position in the insertion plane was 1.59 mm in the case of no axial rotation and 0.74 mm with axial rotation.},
	number = {5},
	journal = {IEEE/ASME Transactions on Mechatronics},
	author = {Khadem, M. and Rossa, C. and Usmani, N. and Sloboda, R. S. and Tavakoli, M.},
	month = oct,
	year = {2016},
	keywords = {Biological tissues, Computational modeling, Dynamic modeling, Dynamics, Force, IEEE transactions, Needles, Robots, animal tissues, axial rotation, biological tissues, dynamic modeling, flexible coupled system, fracture mechanics, fracture mechanics-based model, hybrid formulation, medical robotics, needle continuous deflection, needle inserting robot, needle shape prediction, needle steering, needle steering dynamics, needle tip cutting force, needles, percutaneous interventions, robot dynamics, robotically controlled needle steering, robotics-assisted needle steering, soft tissue, surgery, targeting accuracy enhancement, time-delayed tissue model, two-body rigid model},
	pages = {2352--2364}
}

@inproceedings{ijspeert_movement_2002,
	title = {Movement imitation with nonlinear dynamical systems in humanoid robots},
	volume = {2},
	doi = {10.1109/ROBOT.2002.1014739},
	abstract = {Presents an approach to movement planning, on-line trajectory modification, and imitation learning by representing movement plans based on a set of nonlinear differential equations with well-defined attractor dynamics. The resultant movement plan remains an autonomous set of nonlinear differential equations that forms a control policy (CP) which is robust to strong external perturbations and that can be modified on-line by additional perceptual variables. We evaluate the system with a humanoid robot simulation and an actual humanoid robot. Experiments are presented for the imitation of three types of movements: reaching movements with one arm, drawing movements of 2-D patterns, and tennis swings. Our results demonstrate (a) that multi-joint human movements can be encoded successfully by the CPs, (b) that a learned movement policy can readily be reused to produce robust trajectories towards different targets, (c) that a policy fitted for one particular target provides a good predictor of human reaching movements towards neighboring targets, and (d) that the parameter space which encodes a policy is suitable for measuring to which extent two trajectories are qualitatively similar},
	booktitle = {Proceedings 2002 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({Cat}. {No}.02CH37292)},
	author = {Ijspeert, A. J. and Nakanishi, J. and Schaal, S.},
	year = {2002},
	keywords = {Biological system modeling, Control systems, Convergence, Encoding, Humanoid robots, Humans, Laboratories, Nonlinear dynamical systems, Robustness, Trajectory, attractor dynamics, attractor landscape, control policy, humanoid robots, imitation learning, learning algorithm, learning by example, locally weighted regression technique, movement imitation, movement planning, movement plans, multi-joint human movements, nonlinear differential equations, nonlinear dynamical systems, online trajectory modification, path planning, robot kinematics, robot programming, stability},
	pages = {1398--1403}
}

@inproceedings{umlauft_dynamic_2014,
	title = {Dynamic {Movement} {Primitives} for cooperative manipulation and synchronized motions},
	doi = {10.1109/ICRA.2014.6906941},
	abstract = {Cooperative manipulation, where several robots jointly manipulate an object from an initial configuration to a final configuration while preserving the robot formation, poses a great challenge in robotics. Here, we treat the problem of designing motion primitives for cooperative manipulation such that the robots move in formation and are robust with respect to external disturbances. Individual robot trajectories are generated by Dynamic Movement Primitives (DMPs) and coupled by a formation control approach enabling the DMP-trajectories to preserve a given formation while performing the manipulation. The proposed control scheme achieves an increased adaptability under external disturbances. The approach is evaluated in a full-scale experiment with two prototypical cooperative manipulation and synchronized motion tasks.},
	booktitle = {2014 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Umlauft, J. and Sieber, D. and Hirche, S.},
	month = may,
	year = {2014},
	keywords = {DMP-trajectories, Impedance, Manipulator dynamics, Robot kinematics, Synchronization, Trajectory, control system synthesis, cooperative manipulation, dynamic movement primitives, external disturbances, formation control, manipulators, motion control, motion primitives design, object manipulation, robot formation, robot trajectories, robotics, robust, robust control, synchronisation, synchronized motion tasks, trajectory control},
	pages = {766--771}
}

@incollection{katz_extracting_2008,
	series = {Lecture {Notes} in {Electrical} {Engineering}},
	title = {Extracting {Planar} {Kinematic} {Models} {Using} {Interactive} {Perception}},
	isbn = {978-0-387-75521-2 978-0-387-75523-6},
	url = {https://link.springer.com/chapter/10.1007/978-0-387-75523-6_2},
	abstract = {Roboticists are working towards the deployment of autonomous mobile manipulators in unstructured and dynamic environments. Adequate autonomy and competency in unstructured environments would open up a variety of important applications for robotics, ranging from planetary exploration to elder care and from the disposal of improvised explosive devices to flexible manufacturing and construction in collaborationwith human experts. Ongoing research efforts seek to enable the use of autonomous robots for these applications through the development of adequate hardware platforms [10, 26, 31], robust and task-oriented control strategies [19], and new learning frameworks [2, 5, 6, 27].For unstructured and dynamic environments, it is not possible to provide the robot with a detailed a priori model of the world. Consequently, an autonomous robot has to continuously acquire perceptual information to successfully execute mobility and manipulation tasks [12, 17, 25, 29]. This extraction can be performed most effectively, if it occurs in the context of a specific task.},
	language = {en},
	urldate = {2018-04-12TZ},
	booktitle = {Unifying {Perspectives} in {Computational} and {Robot} {Vision}},
	publisher = {Springer, Boston, MA},
	author = {Katz, Dov and Brock, Oliver},
	year = {2008},
	doi = {10.1007/978-0-387-75523-6_2},
	pages = {11--23}
}

@incollection{edsinger_two_2007,
	series = {Lecture {Notes} in {Control} and {Information} {Sciences}},
	title = {Two {Arms} {Are} {Better} {Than} {One}: {A} {Behavior} {Based} {Control} {System} for {Assistive} {Bimanual} {Manipulation}},
	isbn = {978-3-540-76728-2 978-3-540-76729-9},
	shorttitle = {Two {Arms} {Are} {Better} {Than} {One}},
	url = {http://link.springer.com/chapter/10.1007/978-3-540-76729-9_27},
	abstract = {IntroductionRobots that work alongside people in their homes and workplaces could potentially extend the time an elderly person can live at home, provide physical assistance to a worker on an assembly line, or help with household chores. Human environments present special challenges for robot manipulation, since they are complex, dynamic, uncontrolled, and difficult to perceive reliably. For tasks that involve two handheld objects, the use of two arms can help overcome these challenges. With bimanual manipulation, a robot can simultaneously control two handheld objects in order to better perceive key features, control the objects with respect to one another, and interact with the user.},
	language = {en},
	urldate = {2018-04-12TZ},
	booktitle = {Recent {Progress} in {Robotics}: {Viable} {Robotic} {Service} to {Human}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Edsinger, Aaron and Kemp, Charles C.},
	year = {2007},
	doi = {10.1007/978-3-540-76729-9_27},
	pages = {345--355}
}

@incollection{edsinger_two_2007-1,
	series = {Lecture {Notes} in {Control} and {Information} {Sciences}},
	title = {Two {Arms} {Are} {Better} {Than} {One}: {A} {Behavior} {Based} {Control} {System} for {Assistive} {Bimanual} {Manipulation}},
	isbn = {978-3-540-76728-2 978-3-540-76729-9},
	shorttitle = {Two {Arms} {Are} {Better} {Than} {One}},
	url = {https://link.springer.com/chapter/10.1007/978-3-540-76729-9_27},
	abstract = {IntroductionRobots that work alongside people in their homes and workplaces could potentially extend the time an elderly person can live at home, provide physical assistance to a worker on an assembly line, or help with household chores. Human environments present special challenges for robot manipulation, since they are complex, dynamic, uncontrolled, and difficult to perceive reliably. For tasks that involve two handheld objects, the use of two arms can help overcome these challenges. With bimanual manipulation, a robot can simultaneously control two handheld objects in order to better perceive key features, control the objects with respect to one another, and interact with the user.},
	language = {en},
	urldate = {2018-04-12TZ},
	booktitle = {Recent {Progress} in {Robotics}: {Viable} {Robotic} {Service} to {Human}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Edsinger, Aaron and Kemp, Charles C.},
	year = {2007},
	doi = {10.1007/978-3-540-76729-9_27},
	pages = {345--355}
}

@incollection{katz_extracting_2008-1,
	series = {Lecture {Notes} in {Electrical} {Engineering}},
	title = {Extracting {Planar} {Kinematic} {Models} {Using} {Interactive} {Perception}},
	isbn = {978-0-387-75521-2 978-0-387-75523-6},
	url = {https://link.springer.com/chapter/10.1007/978-0-387-75523-6_2},
	abstract = {Roboticists are working towards the deployment of autonomous mobile manipulators in unstructured and dynamic environments. Adequate autonomy and competency in unstructured environments would open up a variety of important applications for robotics, ranging from planetary exploration to elder care and from the disposal of improvised explosive devices to flexible manufacturing and construction in collaborationwith human experts. Ongoing research efforts seek to enable the use of autonomous robots for these applications through the development of adequate hardware platforms [10, 26, 31], robust and task-oriented control strategies [19], and new learning frameworks [2, 5, 6, 27].For unstructured and dynamic environments, it is not possible to provide the robot with a detailed a priori model of the world. Consequently, an autonomous robot has to continuously acquire perceptual information to successfully execute mobility and manipulation tasks [12, 17, 25, 29]. This extraction can be performed most effectively, if it occurs in the context of a specific task.},
	language = {en},
	urldate = {2018-04-12TZ},
	booktitle = {Unifying {Perspectives} in {Computational} and {Robot} {Vision}},
	publisher = {Springer, Boston, MA},
	author = {Katz, Dov and Brock, Oliver},
	year = {2008},
	doi = {10.1007/978-0-387-75523-6_2},
	pages = {11--23}
}

@article{sian_operating_nodate,
	title = {Operating {Humanoid} {Robots} in {Human} {Environments}},
	abstract = {Depending on the autonomous capability of the robot and the familiarity of the robot system with the task and environment, the level of human intervention differs. This paper introduces a methodology which allows a human operator to seamlessly switch between the continuous control of motion using an analog input device and the discrete behavior control cooperating with the robot using symbolic commands. Using the proposed methods, a human operator is able to operate humanoid robots with high ﬂexibility by only using a simple operation interface. Successful experiments operating humanoid robot HRP-2 in executing everyday tasks proved the high reliability of the proposed operation system.},
	language = {en},
	author = {Sian, Neo Ee and Sakaguchi, Takeshi and Yokoi, Kazuhito and Kawai, Yoshihiro and Maruyama, Kenichi},
	pages = {6}
}

@inproceedings{edsinger_manipulation_2006,
	title = {Manipulation in {Human} {Environments}},
	isbn = {978-1-4244-0199-4 978-1-4244-0200-7},
	url = {http://ieeexplore.ieee.org/document/4115587/},
	doi = {10.1109/ICHR.2006.321370},
	language = {en},
	urldate = {2018-04-12TZ},
	publisher = {IEEE},
	author = {Edsinger, Aaron and Kemp, Charles},
	month = dec,
	year = {2006},
	pages = {102--109}
}

@inproceedings{stria_garment_2014,
	title = {Garment perception and its folding using a dual-arm robot},
	doi = {10.1109/IROS.2014.6942541},
	abstract = {The work addresses the problem of clothing perception and manipulation by a two armed industrial robot aiming at a real-time automated folding of a piece of garment spread out on a flat surface. A complete solution combining vision sensing, garment segmentation and understanding, planning of the manipulation and its real execution on a robot is proposed. A new polygonal model of a garment is introduced. Fitting the model into a segmented garment contour is used to detect garment landmark points. It is shown how folded variants of the unfolded model can be derived automatically. Universality and usefulness of the model is demonstrated by its favorable performance within the whole folding procedure which is applicable to a variety of garments categories (towel, pants, shirt, etc.) and evaluated experimentally using the two armed robot. The principal novelty with respect to the state of the art is in the new garment polygonal model and its manipulation planning algorithm which leads to the speed up by two orders of magnitude.},
	booktitle = {2014 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Stria, J. and Průša, D. and Hlaváč, V. and Wagner, L. and Petrík, V. and Krsek, P. and Smutný, V.},
	month = sep,
	year = {2014},
	keywords = {Clothing, Grippers, Heuristic algorithms, Image color analysis, Planning, Robot sensing systems, clothing industry, clothing manipulation, clothing perception, dual arm robot, garment contour segmentation, garment perception, garment segmentation, garments categories, industrial robot, industrial robots, polygonal model, real-time automated folding, robot real execution, vision sensing},
	pages = {61--67}
}

@misc{noauthor_garment_nodate,
	title = {Garment perception and its folding using a dual-arm robot - {IEEE} {Conference} {Publication}},
	url = {https://ieeexplore-ieee-org.ezproxy.wpi.edu/abstract/document/6942541/},
	urldate = {2018-04-12TZ}
}

@inproceedings{stria_garment_2014-1,
	title = {Garment perception and its folding using a dual-arm robot},
	doi = {10.1109/IROS.2014.6942541},
	abstract = {The work addresses the problem of clothing perception and manipulation by a two armed industrial robot aiming at a real-time automated folding of a piece of garment spread out on a flat surface. A complete solution combining vision sensing, garment segmentation and understanding, planning of the manipulation and its real execution on a robot is proposed. A new polygonal model of a garment is introduced. Fitting the model into a segmented garment contour is used to detect garment landmark points. It is shown how folded variants of the unfolded model can be derived automatically. Universality and usefulness of the model is demonstrated by its favorable performance within the whole folding procedure which is applicable to a variety of garments categories (towel, pants, shirt, etc.) and evaluated experimentally using the two armed robot. The principal novelty with respect to the state of the art is in the new garment polygonal model and its manipulation planning algorithm which leads to the speed up by two orders of magnitude.},
	booktitle = {2014 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Stria, J. and Průša, D. and Hlaváč, V. and Wagner, L. and Petrík, V. and Krsek, P. and Smutný, V.},
	month = sep,
	year = {2014},
	keywords = {Clothing, Grippers, Heuristic algorithms, Image color analysis, Planning, Robot sensing systems, clothing industry, clothing manipulation, clothing perception, dual arm robot, garment contour segmentation, garment perception, garment segmentation, garments categories, industrial robot, industrial robots, polygonal model, real-time automated folding, robot real execution, vision sensing},
	pages = {61--67}
}

@article{koppula_anticipating_2016,
	title = {Anticipating {Human} {Activities} {Using} {Object} {Affordances} for {Reactive} {Robotic} {Response}},
	volume = {38},
	issn = {0162-8828},
	doi = {10.1109/TPAMI.2015.2430335},
	abstract = {An important aspect of human perception is anticipation, which we use extensively in our day-to-day activities when interacting with other humans as well as with our surroundings. Anticipating which activities will a human do next (and how) can enable an assistive robot to plan ahead for reactive responses. Furthermore, anticipation can even improve the detection accuracy of past activities. The challenge, however, is two-fold: We need to capture the rich context for modeling the activities and object affordances, and we need to anticipate the distribution over a large space of future human activities. In this work, we represent each possible future using an anticipatory temporal conditional random field (ATCRF) that models the rich spatial-temporal relations through object affordances. We then consider each ATCRF as a particle and represent the distribution over the potential futures using a set of particles. In extensive evaluation on CAD-120 human activity RGB-D dataset, we first show that anticipation improves the state-of-the-art detection results. We then show that for new subjects (not seen in the training set), we obtain an activity anticipation accuracy (defined as whether one of top three predictions actually happened) of 84.1, 74.4 and 62.2 percent for an anticipation time of 1, 3 and 10 seconds respectively. Finally, we also show a robot using our algorithm for performing a few reactive responses.},
	number = {1},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Koppula, H. S. and Saxena, A.},
	month = jan,
	year = {2016},
	keywords = {3D Activity Understanding, 3D activity understanding, ATCRF, Algorithms, Anticipation, Psychological, Context, Context modeling, Heating, Hidden Markov models, Human Activities, Human Activity Anticipation, Humans, Imaging, Three-Dimensional, Machine Learning, Models, Statistical, Movement, Perception, RGBD Data, Robotics, Robotics Perception, Robots, Trajectory, Video Recording, Videos, anticipatory temporal conditional random field, assistive robot, human activities, human activity RGB-D dataset, human activity anticipation, machine learning, object affordances, reactive robotic response, robot vision, robotics perception, statistical analysis},
	pages = {14--29}
}

@article{xian_closed-chain_2017,
	title = {Closed-{Chain} {Manipulation} of {Large} {Objects} by {Multi}-{Arm} {Robotic} {Systems}},
	volume = {2},
	doi = {10.1109/LRA.2017.2708134},
	abstract = {Closed kinematic chains are created whenever multiple robot arms concurrently manipulate a single object. The closed-chain constraint, when coupled with robot joint limits, dramatically changes the connectivity of the configuration space. We propose a regrasping move, termed “IK-switch,” which allows efficiently bridging components of the configuration space that are otherwise mutually disconnected. This move, combined with several other developments, such as a method to stabilize the manipulated object using the environment, a new tree structure, and a compliant control scheme, enables us to address complex closed-chain manipulation tasks, such as flipping a chair frame, which is otherwise impossible to realize using existing multi-arm planning methods.},
	number = {4},
	journal = {IEEE Robotics and Automation Letters},
	author = {Xian, Z. and Lertkultanon, P. and Pham, Q. C.},
	month = oct,
	year = {2017},
	keywords = {Aerospace electronics, Dual arm manipulation, Grasping, IK-switch, Kinematics, Manifolds, Manipulators, Planning, closed kinematic chains, closed loop systems, closed-chain object manipulation, manipulation planning, manipulator kinematics, motion and path planning, multi-arm planning, multi-arm robotic systems, path planning, regrasping move, robot joint limits},
	pages = {1832--1839}
}

@inproceedings{su_improving_2017,
	title = {Improving robot grasping plans with affordance},
	doi = {10.1109/ARIS.2017.8297172},
	abstract = {The quality of grasping is supported by leveraging the concept of affordance in this paper to improve grasping operations. When introducing flexibility in handling different objects in a dynamically changing environment, uncertainty in grasping areas and operations may cause problems. We have studied the relationship between the objects, their associated operations, and the effect of performing such operations. With such information, the robot arm may be able to limit some improper grasping operations and angles in order to introduce better plans more efficiently. We use OpenRAVE as the simulation environment to carry out the plans generated. The experiments show that better plans were generated with affordance.},
	booktitle = {2017 {International} {Conference} on {Advanced} {Robotics} and {Intelligent} {Systems} ({ARIS})},
	author = {Su, Y. F. and Liu, A. and Lu, W. H.},
	month = sep,
	year = {2017},
	keywords = {Affordance, Grasping, HTN planning, Manipulators, Ontologies, OpenRAVE, Planning, Robot sensing systems, Task analysis, dynamically changing environment, improper grasping operations, manipulators, ontology, robot arm, robot grasping, robot grasping plans, task constraints},
	pages = {7--12}
}

@inproceedings{thota_learning_2016,
	title = {Learning and synchronization of movement primitives for bimanual manipulation tasks},
	doi = {10.1109/CDC.2016.7798389},
	abstract = {Bimanual manipulation tasks require strong coordination between the two hands performing the task. Trajectories of both arms must be temporally synchronized while satisfying certain spatial constraints while performing the task. In this paper, control laws for the desired trajectory tracking and synchronization of multiple agents modeled using dynamic movement primitives (DMPs) are developed. The control laws are developed using contraction analysis of nonlinear systems. Specific control laws and tracking and synchronization constraints for bimanual tasks are developed. Experimental results suggest that the proposed control laws are robust to spatial perturbations and on-the fly goal location changes.},
	booktitle = {2016 {IEEE} 55th {Conference} on {Decision} and {Control} ({CDC})},
	author = {Thota, P. K. and Ravichandar, H. c and Dani, A. P.},
	month = dec,
	year = {2016},
	keywords = {Contraction Analysis, Couplings, DMP, Dynamic Movement Primitive, Dynamics, Limit-cycles, Synchronization, Tracking, Trajectory, Transient analysis, bimanual manipulation tasks, contraction analysis, dynamic movement primitives, learning, learning (artificial intelligence), manipulators, multiple agents, nonlinear control systems, nonlinear systems, on-the fly goal location, spatial perturbations, specific control laws, synchronisation, synchronization, trajectory control, trajectory tracking},
	pages = {945--950}
}

@article{lertkultanon_certified-complete_2018,
	title = {A {Certified}-{Complete} {Bimanual} {Manipulation} {Planner}},
	issn = {1545-5955},
	doi = {10.1109/TASE.2018.2791478},
	abstract = {Planning motions for two robot arms to move an object collaboratively is a difficult problem, mainly because of the closed-chain constraint, which arises whenever two robot hands simultaneously grasp a single rigid object. In this paper, we propose a manipulation planning algorithm to bring an object from an initial stable placement (position and orientation of the object on a support surface) toward a goal stable placement. The key specificity of our algorithm is that it is certified-complete: for a given object and a given environment, we provide a certificate that the algorithm will find a solution to any bimanual manipulation query in that environment whenever one exists. Moreover, the certificate is constructive: at run-time, it can be used to quickly find a solution to a given query. The algorithm is tested in software and hardware on a number of large pieces of furniture.},
	journal = {IEEE Transactions on Automation Science and Engineering},
	author = {Lertkultanon, P. and Pham, Q. C.},
	year = {2018},
	keywords = {Bimanual manipulation, Grippers, Manipulators, Planning, Robot kinematics, Software algorithms, Task analysis, certified-completeness},
	pages = {1--14}
}
@article{mcmahon_multimodal_2018,
	title = {Multimodal {Trip} {Hazard} {Affordance} {Detection} on {Construction} {Sites}},
	volume = {3},
	doi = {10.1109/LRA.2017.2719763},
	abstract = {Trip hazards are a significant contributor to accidents on construction and manufacturing sites. Current safety inspections are labor intensive and limited by human fallibility, making automation of trip hazard detection appealing from both a safety and economic perspective. Trip hazards present an interesting challenge to modern learning techniques because they are defined as much by affordance as by object type, for example, wires on a table are not a trip hazard, but can be if lying on the ground. To address these challenges, we conduct a comprehensive investigation into the performance characteristics of 11 different colors and depth fusion approaches, including four fusion and one nonfusion approach, using color and two types of depth images. Trained and tested on more than 600 labeled trip hazards over four floors and 2000 m2 in an active construction site, this approach was able to differentiate between identical objects in different physical configurations. Outperforming a color-only detector, our multimodal trip detector fuses color and depth information to achieve a 4\% absolute improvement in F1-score. These investigative results and the extensive publicly available dataset move us one step closer to assistive or fully automated safety inspection systems on construction sites.},
	number = {1},
	journal = {IEEE Robotics and Automation Letters},
	author = {McMahon, S. and Sünderhauf, N. and Upcroft, B. and Milford, M.},
	month = jan,
	year = {2018},
	keywords = {Computer vision for other robotic applications, Detectors, Floors, Hazards, Image color analysis, Robots, Visualization, accidents, automated safety inspection systems, automatic optical inspection, color image, construction industry, construction robotics, construction sites, depth fusion, depth images, hazardous areas, image colour analysis, image fusion, industrial accidents, industrial robots, learning techniques, manufacturing sites, multimodal trip hazard affordance detection, robot vision, robotics in construction, safety inspections, visual learning},
	pages = {1--8}
}

@article{bui_corotational_2017,
	title = {Corotational {Cut} {Finite} {Element} {Method} for real-time surgical simulation: application to needle insertion simulation},
	shorttitle = {Corotational {Cut} {Finite} {Element} {Method} for real-time surgical simulation},
	url = {http://arxiv.org/abs/1712.03052},
	abstract = {This paper describes the use of the corotational cut Finite Element Method (FEM) for real-time surgical simulation. Users only need to provide a background mesh which is not necessarily conforming to the boundaries/interfaces of the simulated object. The details of the surface, which can be directly obtained from binary images, are taken into account by a multilevel embedding algorithm applied to elements of the background mesh that cut by the surface. Boundary conditions can be implicitly imposed on the surface using Lagrange multipliers. The implementation is verified by convergence studies with optimal rates. The algorithm is applied to various needle insertion simulations (e.g. for biopsy or brachytherapy) into brain and liver to verify the reliability of method, and numerical results show that the present method can make the discretisation independent from geometric description, and can avoid the complexity of mesh generation of complex geometries while retaining the accuracy of the standard FEM. Using the proposed approach is very suitable for real-time and patient specific simulations as it improves the simulation accuracy by taking into account automatically and properly the simulated geometry.},
	urldate = {2018-04-10TZ},
	journal = {arXiv:1712.03052 [cs]},
	author = {Bui, Huu Phuoc and Tomar, Satyendra and Bordas, Stéphane P. A.},
	month = dec,
	year = {2017},
	note = {arXiv: 1712.03052},
	keywords = {Computer Science - Computational Engineering, Finance, and Science, Computer Science - Numerical Analysis}
}

@article{oldfield_detailed_2013,
	title = {Detailed finite element modelling of deep needle insertions into a soft tissue phantom using a cohesive approach},
	volume = {16},
	issn = {1025-5842},
	url = {https://doi.org/10.1080/10255842.2011.628448},
	doi = {10.1080/10255842.2011.628448},
	abstract = {Detailed finite element modelling of needle insertions into soft tissue phantoms encounters difficulties of large deformations, high friction, contact loading and material failure. This paper demonstrates the use of cohesive elements in high-resolution finite element models to overcome some of the issues associated with these factors. Experiments are presented enabling extraction of the strain energy release rate during crack formation. Using data from these experiments, cohesive elements are calibrated and then implemented in models for validation of the needle insertion process. Successful modelling enables direct comparison of finite element and experimental force–displacement plots and energy distributions. Regions of crack creation, relaxation, cutting and full penetration are identified. By closing the loop between experiments and detailed finite element modelling, a methodology is established which will enable design modifications of a soft tissue probe that steers through complex mechanical interactions with the surrounding material.},
	number = {5},
	urldate = {2018-04-10TZ},
	journal = {Computer Methods in Biomechanics and Biomedical Engineering},
	author = {Oldfield, Matthew and Dini, Daniele and Giordano, Gianpaolo and Baena, Ferdinando Rodriguez y},
	month = may,
	year = {2013},
	pmid = {22229447},
	keywords = {cohesive elements, finite element method, flexible probe, fracture toughness, needle insertion, soft tissue},
	pages = {530--543}
}

@inproceedings{hermans_affordance_2011,
	title = {Affordance prediction via learned object attributes},
	abstract = {Abstract — We present a novel method for learning and predicting the affordances of an object based on its physical and visual attributes. Affordance prediction is a key task in autonomous robot learning, as it allows a robot to reason about the actions it can perform in order to accomplish its goals. Previous approaches to affordance prediction have either learned direct mappings from visual features to affordances, or have introduced object categories as an intermediate representation. In this paper, we argue that physical and visual attributes provide a more appropriate mid-level representation for affordance prediction, because they support informationsharing between affordances and objects, resulting in superior generalization performance. In particular, affordances are more likely to be correlated with the attributes of an object than they are with its visual appearance or a linguistically-derived object category. We provide preliminary validation of our method experimentally, and present empirical comparisons to both the direct and category-based approaches of affordance prediction. Our encouraging results suggest the promise of the attributebased approach to affordance prediction. I.},
	booktitle = {in {International} {Conference} on {Robotics} and {Automation}: {Workshop} on {Semantic} {Perception}, {Mapping}, and {Exploration}},
	author = {Hermans, Tucker and Rehg, James M. and Bobick, Aaron},
	year = {2011}
}

@article{moldovan_relational_2017,
	title = {Relational affordances for multiple-object manipulation},
	doi = {10.1007/s10514-017-9637-x},
	abstract = {The concept of affordances has been used in robotics to model action opportunities of a robot and as a basis for making decisions involving objects. Affordances capture the interdependencies between the objects and their properties, the executed actions on those objects, and the effects of those respective actions. However, existing affordance models cannot cope with multiple objects that may interact during action execution. Our approach is unique in that possesses the following four characteristics. First, our model employs recent advances in probabilistic programming to learn affordance models that take into account (spatial) relations between different objects, such as relative distances. Two-object interaction models are first learned from the robot interacting with the world in a behavioural exploration stage, and are then employed in worlds with an arbitrary number of objects. The model thus generalizes over both the number of and the particular objects used in the exploration stage, and it also effectively deals with uncertainty. Secondly, rather than using a (discrete) action repertoire, the actions are parametrised according to the motor capabilities of the robot, which allows to model and achieve goals at several levels of complexity. It also supports a two-arm parametrised action. Thirdly, the relational affordance model represents the state of the world using both discrete (action and object features) and continuous (effects) random variables. The effects follow a multivariate Gaussian distribution with the correlated discrete variables (actions and object properties). Fourthly, the learned model can be employed on planning for high-level goals that closely correspond to goals formulated in natural language. The goals are specified by means of (spatial) relations between the objects. The model is evaluated in real experiments using an iCub robot given a series of such planning goals of increasing difficulty.},
	journal = {Autonomous Robots},
	author = {Moldovan, Bogdan and Moreno, Plinio and Nitti, Davide and Santos-Victor, José and De Raedt, Luc},
	month = may,
	year = {2017}
}

@inproceedings{moldovan_learning_2014,
	title = {Learning relational affordance models for two-arm robots},
	doi = {10.1109/IROS.2014.6942964},
	abstract = {Affordances are used in robotics to model action opportunities of a robotic manipulator on an object in the environment. Previous work has shown how statistical relational learning can be used in a discrete setting to extend affordances to model relations and interactions between multiple objects being manipulated by a robotic arm and deal with environment uncertainty. In this paper, we first extend this concept of relational affordances to a continuous setting and then to a two-arm robot. A relational affordance model can first be learnt for one arm through a behavioural babbling stage, and then with the use of statistical relational learning, after constructing a symmetrical model for the other arm, two-arm manipulation actions can be modelled, where the arms can act sequentially or simultaneously. The model is evaluated in a two-arm action recognition task in a shelf object manipulation setting.},
	booktitle = {2014 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Moldovan, B. and Raedt, L. De},
	month = sep,
	year = {2014},
	keywords = {Data models, Manipulators, Mathematical model, Random variables, Robot sensing systems, Shape, behavioural babbling stage, environment uncertainty, learning (artificial intelligence), manipulators, relational affordance model, robotic manipulator, statistical relational learning, two-arm action recognition task, two-arm manipulation actions, two-arm robots},
	pages = {2916--2922}
}

@inproceedings{vahrenkamp_integrated_2010,
	title = {Integrated {Grasp} and motion planning},
	doi = {10.1109/ROBOT.2010.5509377},
	abstract = {In this work, we present an integrated planner for collision-free single and dual arm grasping motions. The proposed Grasp-RRT planner combines the three main tasks needed for grasping an object: finding a feasible grasp, solving the inverse kinematics and searching a collision-free trajectory that brings the hand to the grasping pose. Therefore, RRT-based algorithms are used to build a tree of reachable and collision-free configurations. During RRT-generation, potential grasping positions are generated and approach movements toward them are computed. The quality of reachable grasping poses is scored with an online grasp quality measurement module which is based on the computation of applied forces in order to diminish the net torque.We also present an extension to a dual arm planner which generates bimanual grasps together with corresponding dual arm grasping motions. The algorithms are evaluated with different setups in simulation and on the humanoid robot ARMAR-III.},
	booktitle = {2010 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Vahrenkamp, N. and Do, M. and Asfour, T. and Dillmann, R.},
	month = may,
	year = {2010},
	keywords = {Computational modeling, Databases, End effectors, Grasping, Humanoid robots, Kinematics, Motion analysis, Motion planning, Orbital robotics, Process planning, RRT-based algorithm, bimanual grasp, collision-free dual arm grasping motion, collision-free single arm grasping motion, collision-free trajectory, dexterous manipulators, dual arm planner, grasp-RRT planner, grasping position, humanoid robot ARMAR-III, humanoid robots, inverse kinematics, motion planning, net torque, object grasping, online grasp quality measurement module, path planning, position control, random processes, reachable grasping pose, robot kinematics, torque control},
	pages = {2883--2888}
}

@inproceedings{sommer_bimanual_2014,
	title = {Bimanual compliant tactile exploration for grasping unknown objects},
	doi = {10.1109/ICRA.2014.6907804},
	abstract = {Humans have an incredible capacity to learn properties of objects by pure tactile exploration with their two hands. With robots moving into human-centred environment, tactile exploration becomes more and more important as vision may be occluded easily by obstacles or fail because of different illumination conditions. In this paper, we present our first results on bimanual compliant tactile exploration, with the goal to identify objects and grasp them. An exploration strategy is proposed to guide the motion of the two arms and fingers along the object. From this tactile exploration, a point cloud is obtained for each object. As the point cloud is intrinsically noisy and un-uniformly distributed, a filter based on Gaussian Processes is proposed to smooth the data. This data is used at runtime for object identification. Experiments on an iCub humanoid robot have been conducted to validate our approach.},
	booktitle = {2014 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Sommer, N. and Li, M. and Billard, A.},
	month = may,
	year = {2014},
	keywords = {Gaussian processes, Robot kinematics, Tactile sensors, Three-dimensional displays, Training, Uncertainty, bimanual compliant tactile exploration, compliance control, humanoid robots, iCub humanoid robot, manipulators, motion control, object identification, point cloud, robots, unknown object grasping},
	pages = {6400--6407}
}

@article{lee_relative_2014,
	title = {Relative {Impedance} {Control} for {Dual}-{Arm} {Robots} {Performing} {Asymmetric} {Bimanual} {Tasks}},
	volume = {61},
	issn = {0278-0046},
	doi = {10.1109/TIE.2013.2266079},
	abstract = {This paper presents a method of implementing impedance control (with inertia, damping, and stiffness terms) on a dual-arm system by using the relative Jacobian technique. The proposed method significantly simplifies the control implementation because the dual arm is treated as a single manipulator, whose end-effector motion is defined by the relative motion between the two end effectors. As a result, task description becomes simpler and more intuitive when specifying the desired impedance and the desired trajectories. This is the basis for the relative impedance control. In addition, the use of time-delay estimation enhances ease of implementation of our proposed method to a physical system, which would have been otherwise a very tedious and complicated process.},
	number = {7},
	journal = {IEEE Transactions on Industrial Electronics},
	author = {Lee, J. and Chang, P. H. and Jamisola, R. S.},
	month = jul,
	year = {2014},
	keywords = {Asymmetric bimanual task (ABT), asymmetric bimanual tasks, delays, dual arm, dual-arm robots, dual-arm system, end effectors, end-effector motion, ideal-velocity feedback (IVF), impedance control, motion control, relative Jacobian, relative Jacobian technique, relative impedance control, single manipulator, time-delay estimation, time-delay estimation (TDE)},
	pages = {3786--3796}
}

@article{katz_perceiving_2014,
	title = {Perceiving, learning, and exploiting object affordances for autonomous pile manipulation},
	volume = {37},
	issn = {0929-5593, 1573-7527},
	url = {https://link.springer.com/article/10.1007/s10514-014-9407-y},
	doi = {10.1007/s10514-014-9407-y},
	abstract = {Autonomous manipulation in unstructured environments will enable a large variety of exciting and important applications. Despite its promise, autonomous manipulation remains largely unsolved. Even the most rudimentary manipulation task—such as removing objects from a pile—remains challenging for robots. We identify three major challenges that must be addressed to enable autonomous manipulation: object segmentation, action selection, and motion generation. These challenges become more pronounced when unknown man-made or natural objects are cluttered together in a pile. We present a system capable of manipulating unknown objects in such an environment. Our robot is tasked with clearing a table by removing objects from a pile and placing them into a bin. To that end, we address the three aforementioned challenges. Our robot perceives the environment with an RGB-D sensor, segmenting the pile into object hypotheses using non-parametric surface models. Our system then computes the affordances of each object, and selects the best affordance and its associated action to execute. Finally, our robot instantiates the proper compliant motion primitive to safely execute the desired action. For efficient and reliable action selection, we developed a framework for supervised learning of manipulation expertise. To verify the performance of our system, we conducted dozens of trials and report on several hours of experiments involving more than 1,500 interactions. The results show that our learning-based approach for pile manipulation outperforms a common sense heuristic as well as a random strategy, and is on par with human action selection.},
	language = {en},
	number = {4},
	urldate = {2018-04-10TZ},
	journal = {Autonomous Robots},
	author = {Katz, Dov and Venkatraman, Arun and Kazemi, Moslem and Bagnell, J. Andrew and Stentz, Anthony},
	month = dec,
	year = {2014},
	pages = {369--382}
}

@book{kraft_software_1988,
	address = {Koln},
	title = {A software package for sequential quadratic programming},
	publisher = {DFVLR},
	author = {Kraft, Dieter},
	year = {1988},
	note = {Open Library ID: OL18926873M},
	keywords = {Quadratic programming}
}

@inproceedings{abayazid_3d_2013,
	title = {3D flexible needle steering in soft-tissue phantoms using {Fiber} {Bragg} {Grating} sensors},
	doi = {10.1109/ICRA.2013.6631418},
	abstract = {Needle insertion procedures are commonly used for surgical interventions. In this paper, we develop a three-dimensional (3D) closed-loop control algorithm to robotically steer flexible needles with an asymmetric tip towards a target in a soft-tissue phantom. Twelve Fiber Bragg Grating (FBG) sensors are embedded on the needle shaft. FBG sensors measure the strain applied on the needle during insertion. A method is developed to reconstruct the needle shape using the strain data obtained from the FBG sensors. Four experimental cases are conducted to validate the reconstruction method (single-bend, double-bend, 3D double-bend and drilling insertions). In the experiments, the needle is inserted 120 mm into a soft-tissue phantom. Camera images are used as a reference for the reconstruction experiments. The results show that the mean needle tip accuracy of the reconstruction method is 1.8 mm. The reconstructed needle shape is used as feedback for the steering algorithm. The steering algorithm estimates the region that the needle can reach during insertion, and controls the needle to keep the target in this region. Steering experiments are performed for 110 mm insertion, and the mean targeting accuracy is 1.3 mm. The results demonstrate the capability of using FBG sensors to robotically steer needles.},
	booktitle = {2013 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Abayazid, M. and Kemp, M. and Misra, S.},
	month = may,
	year = {2013},
	keywords = {3D closed-loop control algorithm, 3D double-bend reconstruction method, 3D flexible needle steering algorithm, Bragg gratings, FBG sensors, Fiber gratings, Needles, Sensors, Shape, Strain, Three-dimensional displays, asymmetric tip, biological tissues, camera images, cameras, closed loop systems, double-bend reconstruction method, drilling reconstruction method, fiber Bragg grating sensors, fibre optic sensors, image reconstruction, medical robotics, needle insertion procedures, needle shaft, needle shape reconstruction method, needles, phantoms, single-bend reconstruction method, soft-tissue phantoms, strain data, surgery, surgical interventions, three-dimensional closed-loop control algorithm},
	pages = {5843--5849}
}

@article{janga_fast_nodate,
	title = {A {Fast} and {Robust} {Image}-{Based} {Method} for tracking {Robot}-assisted {Needle} {Placement} in {Real}-time {MR} {Images}},
	language = {en},
	author = {Janga, Satyanarayana Reddy},
	pages = {60}
}

@inproceedings{vahrenkamp_humanoid_2009,
	title = {Humanoid motion planning for dual-arm manipulation and re-grasping tasks},
	doi = {10.1109/IROS.2009.5354625},
	abstract = {In this paper, we present efficient solutions for planning motions of dual-arm manipulation and re-grasping tasks. Motion planning for such tasks on humanoid robots with a high number of degrees of freedom (DoF) requires computationally efficient approaches to determine the robot's full joint configuration at a given grasping position, i.e. solving the Inverse Kinematics (IK) problem for one or both hands of the robot. In this context, we investigate solving the inverse kinematics problem and motion planning for dual-arm manipulation and re-grasping tasks by combining a gradient-descent approach in the robot's pre-computed reachability space with random sampling of free parameters. This strategy provides feasible IK solutions at a low computation cost without resorting to iterative methods which could be trapped by joint-limits. We apply this strategy to dual-arm motion planning tasks in which the robot is holding an object with one hand in order to generate whole-body robot configurations suitable for grasping the object with both hands. In addition, we present two probabilistically complete RRT-based motion planning algorithms (J+-RRT and IK-RRT) that interleave the search for an IK solution with the search for a collision-free trajectory and the extension of these planners to solving re-grasping problems. The capabilities of combining IK methods and planners are shown both in simulation and on the humanoid robot ARMAR-III performing dual-arm tasks in a kitchen environment.},
	booktitle = {2009 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Vahrenkamp, N. and Berenson, D. and Asfour, T. and Kuffner, J. and Dillmann, R.},
	month = oct,
	year = {2009},
	keywords = {ARMAR-III humanoid robot, Computational efficiency, Grasping, Humanoid robots, Iterative methods, Kinematics, Motion planning, Orbital robotics, Sampling methods, Strategic planning, Trajectory, dual-arm manipulation, gradient descent approach, gradient methods, humanoid robots, inverse kinematics problem, manipulator kinematics, motion control, motion planning, path planning, random sampling, re-grasping tasks, robot reachability space, sampling methods},
	pages = {2464--2470}
}

@article{lippiello_grasping_2013,
	title = {A {Grasping} {Force} {Optimization} {Algorithm} for {Multiarm} {Robots} {With} {Multifingered} {Hands}},
	volume = {29},
	issn = {1552-3098},
	doi = {10.1109/TRO.2012.2212633},
	abstract = {The computation of the grasping forces for a multiarm robotic manipulation system (e.g., an anthropomorphic bimanual system) is considered in this paper. This problem is formulated as a convex optimization problem, also considering joint torque constraints. An algorithmic solution suitable for online implementation is presented, which allows a substantial reduction in the computational load by adopting a compact formulation and dynamically decreasing the number of active torque constrains. Moreover, for the case of a bimanual manipulation system, a suboptimal single-hand optimization algorithm is proposed and compared with that providing the optimal solution. Finally, a new algorithm for a valid initial-point evaluation is proposed. The effectiveness of the described methods has been tested in a simulation case study where the grasping forces of a humanoid torso equipped with two five-finger robotic hands are modified online to handle a load with a time-varying mass.},
	number = {1},
	journal = {IEEE Transactions on Robotics},
	author = {Lippiello, V. and Siciliano, B. and Villani, L.},
	month = feb,
	year = {2013},
	keywords = {Force, Friction, Grasping, Grasping force optimization (GFO), Joints, Optimization, Robots, Torque, active torque constrains, anthropomorphic bimanual system, compact formulation, computational load substantial reduction, convex optimization problem, convex programming, dexterous manipulators, five-finger robotic hands, grasping, grasping force optimization algorithm, humanoid robots, humanoid torso, initial-point evaluation, joint torque constraints, manipulation, multiarm robotic manipulation system, multifingered hands, suboptimal single-hand optimization algorithm, time-varying mass},
	pages = {55--67}
}

@article{misra_mechanics_2010,
	title = {Mechanics of {Flexible} {Needles} {Robotically} {Steered} through {Soft} {Tissue}},
	volume = {29},
	issn = {0278-3649, 1741-3176},
	url = {http://journals.sagepub.com/doi/10.1177/0278364910369714},
	doi = {10.1177/0278364910369714},
	abstract = {The tip asymmetry of a bevel-tip needle results in the needle naturally bending when it is inserted into soft tissue. This enables robotic needle steering, which can be used in medical procedures to reach subsurface targets inaccessible by straight-line trajectories. However, accurate path planning and control of needle steering require models of needle-tissue interaction. Previous kinematic models required empirical observations of each needle and tissue combination in order to fit model parameters. This study describes a mechanics-based model of robotic needle steering, which can be used to predict needle behavior and optimize system design based on fundamental mechanical and geometrical properties of the needle and tissue. We first present an analytical model for the loads developed at the tip, based on the geometry of the bevel edge and material properties of soft-tissue simulants (gels). We then present a mechanics-based model that calculates the deflection of a bevel-tipped needle inserted through a soft elastic medium. The model design is guided by microscopic observations of needle-gel interactions. The energy-based formulation incorporates tissue-specific parameters, and the geometry and material properties of the needle. Simulation results follow similar trends (deflection and radius of curvature) to those observed in experimental studies of robotic needle insertion.},
	language = {en},
	number = {13},
	urldate = {2018-03-24TZ},
	journal = {The International Journal of Robotics Research},
	author = {Misra, S. and Reed, K.B. and Schafer, B.W. and Ramesh, K.T. and Okamura, A.M.},
	month = nov,
	year = {2010},
	pages = {1640--1660}
}

@article{adorno_two-arm_nodate,
	title = {Two-arm {Manipulation}: {From} {Manipulators} to {Enhanced} {Human}-{Robot} {Collaboration}},
	language = {en},
	author = {Adorno, Bruno Vilhena},
	pages = {164}
}

@article{smith_dual_2012,
	title = {Dual arm manipulation—{A} survey},
	volume = {60},
	issn = {09218890},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S092188901200108X},
	doi = {10.1016/j.robot.2012.07.005},
	abstract = {Recent advances in both anthropomorphic robots and bimanual industrial manipulators had led to an increased interest in the speciﬁc problems pertaining to dual arm manipulation. For the future, we foresee robots performing humanlike tasks in both domestic and industrial settings. It is therefore natural to study speciﬁcs of dual arm manipulation in humans and methods for using the resulting knowledge in robot control. The related scientiﬁc problems range from low-level control to high level task planning and execution. This review aims to summarize the current state of the art from the heterogenous range of ﬁelds that study the diﬀerent aspects of these problems speciﬁcally in dual arm manipulation.},
	language = {en},
	number = {10},
	urldate = {2018-03-23TZ},
	journal = {Robotics and Autonomous Systems},
	author = {Smith, Christian and Karayiannidis, Yiannis and Nalpantidis, Lazaros and Gratal, Xavi and Qi, Peng and Dimarogonas, Dimos V. and Kragic, Danica},
	month = oct,
	year = {2012},
	pages = {1340--1353}
}

@article{adorno_two-arm_nodate-1,
	title = {Two-arm {Manipulation}: {From} {Manipulators} to {Enhanced} {Human}-{Robot} {Collaboration}},
	language = {en},
	author = {Adorno, Bruno Vilhena},
	pages = {164}
}

@inproceedings{zorin_curvature-based_2005,
	title = {Curvature-based energy for simulation and variational modeling},
	isbn = {978-0-7695-2379-8},
	url = {http://ieeexplore.ieee.org/document/1563225/},
	doi = {10.1109/SMI.2005.14},
	abstract = {Curvature-based energy and forces are used in a broad variety of contexts, ranging from modeling of thin plates and shells to surface fairing and variational surface design.},
	urldate = {2018-03-22TZ},
	publisher = {IEEE Comput. Soc},
	author = {Zorin, D.},
	year = {2005},
	pages = {196--204}
}

@article{hofer_constrained_nodate,
	title = {Constrained {Optimization} with {Energy}-{Minimizing} {Curves} and {Curve} {Networks} — {A} {Survey}},
	abstract = {We survey recent research results in constrained optimization with curves and curve networks. The addressed topics include constrained variational curve and curve network design, variational motion design, and guaranteed error bound approximation of point cloud data with curve networks. The main theoretic results are summarized with a focus on geometric solutions of the studied problems. A variety of applications is outlined including obstacle avoiding rigid body motion design and smoothing of digital terrain elevation data.},
	author = {Hofer, Michael},
	pages = {9}
}

@article{levien_spiral_nodate,
	title = {From {Spiral} to {Spline}: {Optimal} {Techniques} in {Interactive} {Curve} {Design}},
	author = {Levien, Raphael Linus},
	pages = {193}
}

@article{horn_curve_nodate,
	title = {The {Curve} of {Least} {Energy}},
	abstract = {Here we search for the curve which has the smallest integral of the square of curvature, whil e passing through two given points with given orientation . This is the true shape of a spline used in lofting . In computer-aided design, curves have been sought which maximize "smoothness" . The curve discussed here is the one arising in this way from a commonly used measure of smoothness . The human visual system may use such a curve when it constructs a subjective contour.},
	author = {Horn, B K P},
	pages = {35}
}

@article{moreton_scaleinvariant_1993,
	title = {Scale‐{Invariant} {Minimum}‐{Cost} {Curves}: {Fair} and {Robust} {Design} {Implements}},
	volume = {12},
	issn = {1467-8659},
	shorttitle = {Scale‐{Invariant} {Minimum}‐{Cost} {Curves}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1467-8659.1230473},
	doi = {10.1111/1467-8659.1230473},
	language = {en},
	number = {3},
	urldate = {2018-03-22TZ},
	journal = {Computer Graphics Forum},
	author = {Moreton, Henry P. and Séquin, Carlo H.},
	month = aug,
	year = {1993},
	pages = {473--484}
}

@inproceedings{vrooijink_real-time_2013,
	title = {Real-time three-dimensional flexible needle tracking using two-dimensional ultrasound},
	doi = {10.1109/ICRA.2013.6630797},
	abstract = {Needle insertion is one of the most commonly performed minimally invasive procedures. Visualization of the needle during insertion is key for either successful diagnosis or therapy. This work presents the real-time three-dimensional tracking of flexible needles during insertion into a soft-tissue simulant using a two-dimensional (2D) ultrasound transducer. The transducer is placed perpendicular to the needle tip to measure its position. During insertion the transducer is robotically repositioned to track the needle tip. Positioning of the transducer is accomplished by a compensator, that uses the needle insertion velocity corrected by needle tip velocities to determine out-of-plane motion. Experiments are performed to validate the needle tip pose during tracking. The maximum mean errors in needle tip position along the x-, y- and z-axes are 0.64 mm, 0.25 mm and 0.27 mm, respectively. The error in tip orientations (θ-about the y-axis and φ-about the z-axis) are 2.68° and 2.83°, respectively. This study demonstrates the ability to compute the needle tip pose using a 2D ultrasound transducer. The tip pose can be used to robotically steer needles, and thereby improve accuracy of medical procedures.},
	booktitle = {2013 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Vrooijink, G. J. and Abayazid, M. and Misra, S.},
	month = may,
	year = {2013},
	keywords = {2D ultrasound transducer, Image processing, Needles, Real-time systems, Three-dimensional displays, Tracking, Transducers, Ultrasonic imaging, biological tissues, biomedical ultrasonics, compensation, compensator, diagnosis, medical image processing, medical procedures, medical robotics, minimally invasive procedures, needle insertion, needle steering, needle tip tracking, needle visualization, needles, patient treatment, real-time three-dimensional flexible needle tracking, robot, soft-tissue simulant, therapy, tip pose, tracking, transducer positioning, transducers},
	pages = {1688--1693}
}

@article{abayazid_integrating_2013,
	title = {Integrating {Deflection} {Models} and {Image} {Feedback} for {Real}-{Time} {Flexible} {Needle} {Steering}},
	volume = {29},
	issn = {1552-3098},
	doi = {10.1109/TRO.2012.2230991},
	abstract = {Needle insertion procedures are commonly used for diagnostic and therapeutic purposes. In this paper, an image-guided control system is developed to robotically steer flexible needles with an asymmetric tip. Knowledge about needle deflection is required for accurate steering. Two different models to predict needle deflection are presented. The first is a kinematics-based model, and the second model predicts needle deflection that is based on the mechanics of needle-tissue interaction. Both models predict deflection of needles that undergo multiple bends. The maximum targeting errors of the kinematics-based and the mechanics-based models for 110-mm insertion distance using a φ 0.5-mm needle are 0.8 and 1.7 mm, respectively. The kinematics-based model is used in the proposed image-guided control system. The control system accounts for target motion during the insertion procedure by detecting the target position in each image frame. Five experimental cases are presented to validate the real-time control system using both camera and ultrasound images as feedback. The experimental results show that the targeting errors of camera and ultrasound image-guided steering toward a moving target are 0.35 and 0.42 mm, respectively. The targeting accuracy of the algorithm is sufficient to reach the smallest lesions (φ 2 mm) that can be detected using the state-of-the-art ultrasound imaging systems.},
	number = {2},
	journal = {IEEE Transactions on Robotics},
	author = {Abayazid, M. and Roesthuis, R. J. and Reilink, R. and Misra, S.},
	month = apr,
	year = {2013},
	keywords = {Computer-assisted surgery, Force, Needles, Predictive models, Real-time systems, Shape, Target tracking, Ultrasonic imaging, asymmetric tip, biological tissues, biomedical ultrasonics, camera, cameras, deflection model integration, distance 110 mm, feedback, image feedback, image guided control system, image-guided control, kinematics-based model, lesions, mechanics-based model, medical image processing, medical robotics, minimally invasive surgery, needle deflection, needle insertion procedure, needle-tissue interaction mechanics, needles, needle–tissue interactions, object detection, patient diagnosis, patient therapy, robotically steer flexible needle, size 0.35 mm, size 0.42 mm, size 0.8 mm, size 1.7 mm, steering systems, target position detection, ultrasonic imaging, ultrasound, ultrasound image guided steering, ultrasound imaging system},
	pages = {542--553}
}

@inproceedings{roesthuis_mechanics-based_2012,
	title = {Mechanics-based model for predicting in-plane needle deflection with multiple bends},
	doi = {10.1109/BioRob.2012.6290829},
	abstract = {Bevel-tipped flexible needles naturally bend when inserted into soft tissue. Steering such needles along curved paths allows one to avoid anatomical obstacles and reach locations inside the human body which are unreachable with rigid needles. In this study, a mechanics-based model is presented which predicts needle deflection for a needle undergoing multiple bends during insertion into soft tissue. The model is based on a Rayleigh-Ritz formulation, and inputs to the model are a force at the needle tip and a distributed load which acts along the needle shaft. Experiments are used to evaluate the distributed load, and needle deflection is then predicted using the model. The results of the model are compared with a kinematics-based model. Maximum errors in final tip deflection are found to be 0.5 mm and 0.6 mm for the mechanics-based and kinematics-based model, respectively. Though both models are found to be comparable, the mechanics-based model can account for deflection when the needle radius of curvature is not constant (e.g., biological tissue).},
	booktitle = {2012 4th {IEEE} {RAS} {EMBS} {International} {Conference} on {Biomedical} {Robotics} and {Biomechatronics} ({BioRob})},
	author = {Roesthuis, R. J. and Abayazid, M. and Misra, S.},
	month = jun,
	year = {2012},
	keywords = {Bicycles, Biological tissues, Force, Load modeling, Needles, Predictive models, Rayleigh-Ritz formulation, Rayleigh-Ritz methods, Shape, anatomical obstacles, bending, bevel-tipped flexible needles, biological tissue, biological tissues, distributed load, final tip deflection, human body, in-plane needle deflection prediction, kinematics-based model, mechanics-based model, medical robotics, multiple bends, needle shaft, needle tip, needles, physiological models, rigid needles, robot kinematics, soft tissue},
	pages = {69--74}
}

@article{goksel_modeling_2009,
	title = {Modeling and simulation of flexible needles},
	volume = {31},
	issn = {13504533},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1350453309001477},
	doi = {10.1016/j.medengphy.2009.07.007},
	abstract = {Needle insertion is performed in many clinical and therapeutic procedures. Tissue displacement and needle bending which result from needle-tissue interaction make accurate targeting diﬃcult. For performing physicians to gain essential needle targeting skills, needle insertion simulators can be used for training. An accurate needle bending model is essential for such simulators. These bending models are also needed for needle path planning.},
	language = {en},
	number = {9},
	urldate = {2018-03-18TZ},
	journal = {Medical Engineering \& Physics},
	author = {Goksel, Orcun and Dehghan, Ehsan and Salcudean, Septimiu E.},
	month = nov,
	year = {2009},
	pages = {1069--1078}
}

@article{okamura_force_2004,
	title = {Force modeling for needle insertion into soft tissue},
	volume = {51},
	issn = {0018-9294},
	doi = {10.1109/TBME.2004.831542},
	abstract = {The modeling of forces during needle insertion into soft tissue is important for accurate surgical simulation, preoperative planning, and intelligent robotic assistance for percutaneous therapies. We present a force model for needle insertion and experimental procedures for acquiring data from ex vivo tissue to populate that model. Data were collected from bovine livers using a one-degree-of-freedom robot equipped with a load cell and needle attachment. computed tomography imaging was used to segment the needle insertion process into phases identifying different relative velocities between the needle and tissue. The data were measured and modeled in three parts: 1) capsule stiffness, a nonlinear spring model; 2) friction, a modified Karnopp model; and 3) cutting, a constant for a given tissue. In addition, we characterized the effects of needle diameter and tip type on insertion force using a silicone rubber phantom. In comparison to triangular and diamond tips, a bevel tip causes more needle bending and is more easily affected by tissue density variations. Forces for larger diameter needles are higher due to increased cutting and friction forces.},
	number = {10},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Okamura, A. M. and Simone, C. and O'Leary, M. D.},
	month = oct,
	year = {2004},
	keywords = {Animals, Biological tissues, Biopsy, Needle, Bovine, Cattle, Computational modeling, Computed tomography, Computer Simulation, Connective Tissue, Elasticity, Friction, Hardness, Hardness Tests, Intelligent robots, Liver, Medical treatment, Models, Biological, Needles, Robotics, Stress, Mechanical, Surgery, Surgery, Computer-Assisted, Telemedicine, Transducers, Weight-Bearing, accurate surgical simulation, bevel needle tip, biological tissues, biomechanics, bovine livers, capsule stiffness, computed tomography imaging, computerised tomography, force modeling, friction, intelligent robotic assistance, intelligent robots, liver, medical robotics, modified Karnopp model, needle bending, needle insertion, nonlinear spring model, one-degree-of-freedom robot, percutaneous therapies, phantoms, physiological models, preoperative planning, silicone rubber phantom, soft tissue, surgery, tissue density variations},
	pages = {1707--1716}
}

@inproceedings{dehghan_comparison_2006,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Comparison} of {Needle} {Bending} {Models}},
	isbn = {978-3-540-44707-8 978-3-540-44708-5},
	url = {https://link.springer.com/chapter/10.1007/11866565_38},
	doi = {10.1007/11866565_38},
	abstract = {Modeling the deflection of flexible needles is an essential part of needle insertion simulation and path planning. In this paper, three models are compared in terms of accuracy in simulating the bending of a prostate brachytherapy needle. The first two utilize the finite element method, one using geometric non-linearity and triangular plane elements, the other using non-linear beam elements. The third model uses angular springs to model cantilever deflection. The simulations are compared with the experimental bent needle configurations. The models are assessed in terms of geometric conformity using independently identified and pre-identified model parameters. The results show that the angular spring model, which is also the simplest, simulates the needle more accurately than the others.},
	language = {en},
	urldate = {2018-03-18TZ},
	booktitle = {Medical {Image} {Computing} and {Computer}-{Assisted} {Intervention} – {MICCAI} 2006},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Dehghan, Ehsan and Goksel, Orcun and Salcudean, Septimiu E.},
	month = oct,
	year = {2006},
	pages = {305--312}
}

@article{karaman_sampling-based_2011,
	title = {Sampling-based {Algorithms} for {Optimal} {Motion} {Planning}},
	url = {https://arxiv.org/abs/1105.1186},
	language = {en},
	urldate = {2018-03-11TZ},
	author = {Karaman, Sertac and Frazzoli, Emilio},
	month = may,
	year = {2011}
}

@article{saade_random_2016,
	title = {Random {Projections} through multiple optical scattering: {Approximating} kernels at the speed of light},
	shorttitle = {Random {Projections} through multiple optical scattering},
	url = {http://arxiv.org/abs/1510.06664},
	doi = {10.1109/ICASSP.2016.7472872},
	abstract = {Random projections have proven extremely useful in many signal processing and machine learning applications. However, they often require either to store a very large random matrix, or to use a different, structured matrix to reduce the computational and memory costs. Here, we overcome this difficulty by proposing an analog, optical device, that performs the random projections literally at the speed of light without having to store any matrix in memory. This is achieved using the physical properties of multiple coherent scattering of coherent light in random media. We use this device on a simple task of classification with a kernel machine, and we show that, on the MNIST database, the experimental results closely match the theoretical performance of the corresponding kernel. This framework can help make kernel methods practical for applications that have large training sets and/or require real-time prediction. We discuss possible extensions of the method in terms of a class of kernels, speed, memory consumption and different problems.},
	urldate = {2018-03-05TZ},
	journal = {arXiv:1510.06664 [physics]},
	author = {Saade, Alaa and Caltagirone, Francesco and Carron, Igor and Daudet, Laurent and Drémeau, Angélique and Gigan, Sylvain and Krzakala, Florent},
	month = mar,
	year = {2016},
	note = {arXiv: 1510.06664},
	keywords = {Computer Science - Emerging Technologies, Computer Science - Learning, Physics - Optics},
	pages = {6215--6219}
}

@inproceedings{umlauft_dynamic_2014,
	title = {Dynamic {Movement} {Primitives} for cooperative manipulation and synchronized motions},
	doi = {10.1109/ICRA.2014.6906941},
	abstract = {Cooperative manipulation, where several robots jointly manipulate an object from an initial configuration to a final configuration while preserving the robot formation, poses a great challenge in robotics. Here, we treat the problem of designing motion primitives for cooperative manipulation such that the robots move in formation and are robust with respect to external disturbances. Individual robot trajectories are generated by Dynamic Movement Primitives (DMPs) and coupled by a formation control approach enabling the DMP-trajectories to preserve a given formation while performing the manipulation. The proposed control scheme achieves an increased adaptability under external disturbances. The approach is evaluated in a full-scale experiment with two prototypical cooperative manipulation and synchronized motion tasks.},
	booktitle = {2014 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Umlauft, J. and Sieber, D. and Hirche, S.},
	month = may,
	year = {2014},
	keywords = {DMP-trajectories, Impedance, Manipulator dynamics, Robot kinematics, Synchronization, Trajectory, control system synthesis, cooperative manipulation, dynamic movement primitives, external disturbances, formation control, manipulators, motion control, motion primitives design, object manipulation, robot formation, robot trajectories, robotics, robust, robust control, synchronisation, synchronized motion tasks, trajectory control},
	pages = {766--771}
}

@inproceedings{gribovskaya_combining_2008,
	title = {Combining {Dynamical} {Systems} control and programming by demonstration for teaching discrete bimanual coordination tasks to a humanoid robot},
	abstract = {We present a generic framework that combines Dynamical Systems movement control with Programming by Demonstration (PbD) to teach a robot bimanual coordination task. The model consists of two systems: a learning system that processes data collected during the demonstration of the task to extract coordination constraints and a motor system that reproduces the movements dynamically, while satisfying the coordination constraints learned by the first system. We validate the model through a series of experiments in which a robot is taught bimanual manipulatory tasks with the help of a human.},
	booktitle = {2008 3rd {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot} {Interaction} ({HRI})},
	author = {Gribovskaya, E. and Billard, A.},
	month = mar,
	year = {2008},
	keywords = {Bimanual Coordination, Dynamical Systems, Hidden Markov models, Human-Robot Interaction(HRI), Humanoid Robot, Humanoid robots, Humans, Joints, Learning by Imitation, Programming by Demonstration(PbD), Robot kinematics, Trajectory, automatic programming, coordination constraints, discrete bimanual coordination tasks, dynamical systems control, dynamical systems movement control, humanoid robot, humanoid robots, learning system, learning systems, motion control, motor system, programming by demonstration, robot programming},
	pages = {33--40}
}

@article{achanta_slic_2012,
	title = {{SLIC} {Superpixels} {Compared} to {State}-of-the-{Art} {Superpixel} {Methods}},
	volume = {34},
	issn = {0162-8828},
	doi = {10.1109/TPAMI.2012.120},
	abstract = {Computer vision applications have come to rely increasingly on superpixels in recent years, but it is not always clear what constitutes a good superpixel algorithm. In an effort to understand the benefits and drawbacks of existing methods, we empirically compare five state-of-the-art superpixel algorithms for their ability to adhere to image boundaries, speed, memory efficiency, and their impact on segmentation performance. We then introduce a new superpixel algorithm, simple linear iterative clustering (SLIC), which adapts a k-means clustering approach to efficiently generate superpixels. Despite its simplicity, SLIC adheres to boundaries as well as or better than previous methods. At the same time, it is faster and more memory efficient, improves segmentation performance, and is straightforward to extend to supervoxel generation.},
	number = {11},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Achanta, R. and Shaji, A. and Smith, K. and Lucchi, A. and Fua, P. and Süsstrunk, S.},
	month = nov,
	year = {2012},
	keywords = {Algorithms, Approximation algorithms, Clustering algorithms, Complexity theory, Image Enhancement, Image Interpretation, Computer-Assisted, Image color analysis, Image edge detection, Image segmentation, Measurement uncertainty, Pattern Recognition, Automated, Reproducibility of Results, SLIC superpixels, Sensitivity and Specificity, Signal Processing, Computer-Assisted, Superpixels, clustering, computer vision, image boundary, image segmentation, iterative methods, k-means, k-means clustering approach, memory efficiency, pattern clustering, segmentation, segmentation performance, simple linear iterative clustering, superpixel generation, supervoxel generation},
	pages = {2274--2282}
}

@article{lenz_deep_2015,
	title = {Deep learning for detecting robotic grasps},
	volume = {34},
	issn = {0278-3649},
	url = {https://doi.org/10.1177/0278364914549607},
	doi = {10.1177/0278364914549607},
	abstract = {We consider the problem of detecting robotic grasps in an RGB-D view of a scene containing objects. In this work, we apply a deep learning approach to solve this problem, which avoids time-consuming hand-design of features. This presents two main challenges. First, we need to evaluate a huge number of candidate grasps. In order to make detection fast and robust, we present a two-step cascaded system with two deep networks, where the top detections from the first are re-evaluated by the second. The first network has fewer features, is faster to run, and can effectively prune out unlikely candidate grasps. The second, with more features, is slower but has to run only on the top few detections. Second, we need to handle multimodal inputs effectively, for which we present a method that applies structured regularization on the weights based on multimodal group regularization. We show that our method improves performance on an RGBD robotic grasping dataset, and can be used to successfully execute grasps on two different robotic platforms.},
	language = {en},
	number = {4-5},
	urldate = {2018-02-23TZ},
	journal = {The International Journal of Robotics Research},
	author = {Lenz, Ian and Lee, Honglak and Saxena, Ashutosh},
	month = apr,
	year = {2015},
	pages = {705--724}
}

@article{bohg_learning_2010,
	title = {Learning grasping points with shape context},
	volume = {58},
	issn = {0921-8890},
	url = {http://www.sciencedirect.com/science/article/pii/S0921889009001699},
	doi = {10.1016/j.robot.2009.10.003},
	abstract = {This paper presents work on vision based robotic grasping. The proposed method adopts a learning framework where prototypical grasping points are learnt from several examples and then used on novel objects. For representation purposes, we apply the concept of shape context and for learning we use a supervised learning approach in which the classifier is trained with labelled synthetic images. We evaluate and compare the performance of linear and non-linear classifiers. Our results show that a combination of a descriptor based on shape context with a non-linear classification algorithm leads to a stable detection of grasping points for a variety of objects.},
	number = {4},
	urldate = {2018-02-23TZ},
	journal = {Robotics and Autonomous Systems},
	author = {Bohg, Jeannette and Kragic, Danica},
	month = apr,
	year = {2010},
	keywords = {Affordances, Grasping, SVM, Shape context},
	pages = {362--377}
}

@inproceedings{kontschieder_structured_2011,
	title = {Structured class-labels in random forests for semantic image labelling},
	doi = {10.1109/ICCV.2011.6126496},
	abstract = {In this paper we propose a simple and effective way to integrate structural information in random forests for semantic image labelling. By structural information we refer to the inherently available, topological distribution of object classes in a given image. Different object class labels will not be randomly distributed over an image but usually form coherently labelled regions. In this work we provide a way to incorporate this topological information in the popular random forest framework for performing low-level, unary classification. Our paper has several contributions: First, we show how random forests can be augmented with structured label information. In the second part, we introduce a novel data splitting function that exploits the joint distributions observed in the structured label space for learning typical label transitions between object classes. Finally, we provide two possibilities for integrating the structured output predictions into concise, semantic labellings. In our experiments on the challenging MSRC and CamVid databases, we compare our method to standard random forest and conditional random field classification results.},
	booktitle = {2011 {International} {Conference} on {Computer} {Vision}},
	author = {Kontschieder, P. and Bulò, S. R. and Bischof, H. and Pelillo, M.},
	month = nov,
	year = {2011},
	keywords = {CamVid databases, Decision trees, Joints, Labeling, MSRC databases, Semantics, Training, Training data, Vegetation, conditional random field classification, data splitting function, image classification, joint distributions, label transition learning, learning (artificial intelligence), semantic image labelling, standard random forest, structural information, structured class-labels, structured label information, unary classification},
	pages = {2190--2197}
}
@inproceedings{myers_affordance_2015,
	title = {Affordance detection of tool parts from geometric features},
	doi = {10.1109/ICRA.2015.7139369},
	abstract = {As robots begin to collaborate with humans in everyday workspaces, they will need to understand the functions of tools and their parts. To cut an apple or hammer a nail, robots need to not just know the tool's name, but they must localize the tool's parts and identify their functions. Intuitively, the geometry of a part is closely related to its possible functions, or its affordances. Therefore, we propose two approaches for learning affordances from local shape and geometry primitives: 1) superpixel based hierarchical matching pursuit (S-HMP); and 2) structured random forests (SRF). Moreover, since a part can be used in many ways, we introduce a large RGB-Depth dataset where tool parts are labeled with multiple affordances and their relative rankings. With ranked affordances, we evaluate the proposed methods on 3 cluttered scenes and over 105 kitchen, workshop and garden tools, using ranked correlation and a weighted F-measure score [26]. Experimental results over sequences containing clutter, occlusions, and viewpoint changes show that the approaches return precise predictions that could be used by a robot. S-HMP achieves high accuracy but at a significant computational cost, while SRF provides slightly less accurate predictions but in real-time. Finally, we validate the effectiveness of our approaches on the Cornell Grasping Dataset [25] for detecting graspable regions, and achieve state-of-the-art performance.},
	booktitle = {2015 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Myers, A. and Teo, C. L. and Fermüller, C. and Aloimonos, Y.},
	month = may,
	year = {2015},
	keywords = {Conferences, Cornell grasping dataset, Feature extraction, Geometry, Image segmentation, RGB-depth dataset, Robots, S-HMP, SRF, Shape, Three-dimensional displays, affordance detection, geometric features, geometry, human-robot interaction, image colour analysis, image matching, object detection, robot vision, robots, structured random forests, superpixel based hierarchical matching pursuit, tool parts},
	pages = {1374--1381}
}

@inproceedings{zhang_high_2017,
	title = {High resolution three-dimensional robotic synthetic tracked aperture ultrasound imaging: feasibility study},
	volume = {10139},
	shorttitle = {High resolution three-dimensional robotic synthetic tracked aperture ultrasound imaging},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10139/1013914/High-resolution-three-dimensional-robotic-synthetic-tracked-aperture-ultrasound-imaging/10.1117/12.2254707.short},
	doi = {10.1117/12.2254707},
	abstract = {Three dimensional (3D) ultrasound imaging is becoming a standard mode for medical ultrasound diagnoses. Conventional 3D ultrasound imaging is mostly scanned either by using a two dimensional matrix array or by motorizing a one dimensional array in the elevation direction. However, the former system is not widely assessable due to its cost, and the latter one has limited resolution and field-of-view in the elevation axis. Here, we propose a 3D ultrasound imaging system based on the synthetic tracked aperture approach, in which a robotic arm is used to provide accurate tracking and motion. While the ultrasound probe is moved by a robotic arm, each probe position is tracked and can be used to reconstruct a wider field-of-view as there are no physical barriers that restrict the elevational scanning. At the same time, synthetic aperture beamforming provides a better resolution in the elevation axis. To synthesize the elevational information, the single focal point is regarded as the virtual element, and forward and backward delay-andsum are applied to the radio-frequency (RF) data collected through the volume. The concept is experimentally validated using a general ultrasound phantom, and the elevational resolution improvement of 2.54 and 2.13 times was measured at the target depths of 20 mm and 110 mm, respectively.},
	urldate = {2018-02-20TZ},
	booktitle = {Medical {Imaging} 2017: {Ultrasonic} {Imaging} and {Tomography}},
	publisher = {International Society for Optics and Photonics},
	author = {Zhang, Haichong K. and Fang, Ting Yun and Finocchi, Rodolfo and Boctor, Emad M.},
	month = mar,
	year = {2017},
	pages = {1013914}
}

@article{sun_reusable_2015,
	title = {Reusable tissue-mimicking hydrogel phantoms for focused ultrasound ablation},
	volume = {23},
	issn = {1350-4177},
	url = {http://www.sciencedirect.com/science/article/pii/S1350417714003149},
	doi = {10.1016/j.ultsonch.2014.10.008},
	abstract = {The ability of N-isopropylacrylamide (NIPAM)-based hydrogel phantoms to mimic tissues with different acoustic and thermal properties under high-intensity focused ultrasound (HIFU) ablation was investigated. These phantoms were designed to model the formation of thermal lesions in tissues above the threshold temperature of protein denaturation. By adjusting the concentration of acrylic acid (AAc) in the NIPAM-based hydrogel phantoms, the cloud point (i.e., lower critical solution temperature) of the phantoms could be tailored to produce HIFU thermal lesions similar to those formed in different swine tissues in terms of size and shape. Additionally, energy thresholds for inducing transient or permanent bubbles in the phantoms during HIFU ablation were also identified to shed light on the onset of cavitation or material damage. The NIPAM-based hydrogel phantoms developed in this study possess major advantages such as transparent, reusable and tailorable properties, and are practical tools for characterizing an ablative device (or treatment) to determine its efficacy and safety.},
	urldate = {2018-02-20TZ},
	journal = {Ultrasonics Sonochemistry},
	author = {Sun, Ming-Kuan and Shieh, Jay and Lo, Chia-Wen and Chen, Chuin-Shan and Chen, Ben-Ting and Huang, Chang-Wei and Chen, Wen-Shiang},
	month = mar,
	year = {2015},
	keywords = {Cloud point, High-intensity focused ultrasound (HIFU), N-isopropylacrylamide (NIPAM), Phantom, Thermal lesion, Tissue-mimicking},
	pages = {399--405}
}

@article{liu_fast_2012,
	title = {Fast object localization and pose estimation in heavy clutter for robotic bin picking},
	volume = {31},
	issn = {0278-3649},
	url = {https://doi.org/10.1177/0278364911436018},
	doi = {10.1177/0278364911436018},
	abstract = {We present a practical vision-based robotic bin-picking system that performs detection and three-dimensional pose estimation of objects in an unstructured bin using a novel camera design, picks up parts from the bin, and performs error detection and pose correction while the part is in the gripper. Two main innovations enable our system to achieve real-time robust and accurate operation. First, we use a multi-flash camera that extracts robust depth edges. Second, we introduce an efficient shape-matching algorithm called fast directional chamfer matching (FDCM), which is used to reliably detect objects and estimate their poses. FDCM improves the accuracy of chamfer matching by including edge orientation. It also achieves massive improvements in matching speed using line-segment approximations of edges, a three-dimensional distance transform, and directional integral images. We empirically show that these speedups, combined with the use of bounds in the spatial and hypothesis domains, give the algorithm sublinear computational complexity. We also apply our FDCM method to other applications in the context of deformable and articulated shape matching. In addition to significantly improving upon the accuracy of previous chamfer matching methods in all of the evaluated applications, FDCM is up to two orders of magnitude faster than the previous methods.},
	language = {en},
	number = {8},
	urldate = {2018-02-19TZ},
	journal = {The International Journal of Robotics Research},
	author = {Liu, Ming-Yu and Tuzel, Oncel and Veeraraghavan, Ashok and Taguchi, Yuichi and Marks, Tim K. and Chellappa, Rama},
	month = jul,
	year = {2012},
	pages = {951--973}
}

@article{pas_using_2015,
	title = {Using {Geometry} to {Detect} {Grasps} in 3D {Point} {Clouds}},
	url = {http://arxiv.org/abs/1501.03100},
	abstract = {This paper proposes a new approach to detecting grasp points on novel objects presented in clutter. The input to our algorithm is a point cloud and the geometric parameters of the robot hand. The output is a set of hand configurations that are expected to be good grasps. Our key idea is to use knowledge of the geometry of a good grasp to improve detection. First, we use a geometrically necessary condition to sample a large set of high quality grasp hypotheses. We were surprised to find that using simple geometric conditions for detection can result in a relatively high grasp success rate. Second, we use the notion of an antipodal grasp (a standard characterization of a good two fingered grasp) to help us classify these grasp hypotheses. In particular, we generate a large automatically labeled training set that gives us high classification accuracy. Overall, our method achieves an average grasp success rate of 88\% when grasping novels objects presented in isolation and an average success rate of 73\% when grasping novel objects presented in dense clutter. This system is available as a ROS package at http://wiki.ros.org/agile\_grasp.},
	urldate = {2018-02-19TZ},
	journal = {arXiv:1501.03100 [cs]},
	author = {Pas, Andreas ten and Platt, Robert},
	month = jan,
	year = {2015},
	note = {arXiv: 1501.03100},
	keywords = {Computer Science - Robotics}
}

@inproceedings{nieuwenhuisen_mobile_2013,
	title = {Mobile bin picking with an anthropomorphic service robot},
	doi = {10.1109/ICRA.2013.6630892},
	abstract = {Grasping individual objects from an unordered pile in a box has been investigated in static scenarios so far. In this paper, we demonstrate bin picking with an anthropomorphic mobile robot. To this end, we extend global navigation techniques by precise local alignment with a transport box. Objects are detected in range images using a shape primitive-based approach. Our approach learns object models from single scans and employs active perception to cope with severe occlusions. Grasps and arm motions are planned in an efficient local multiresolution height map. All components are integrated and evaluated in a bin picking and part delivery task.},
	booktitle = {2013 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Nieuwenhuisen, M. and Droeschel, D. and Holz, D. and Stückler, J. and Berner, A. and Li, J. and Klein, R. and Behnke, S.},
	month = may,
	year = {2013},
	keywords = {Mobile communication, Navigation, Planning, Robot sensing systems, Service robots, Shape, anthropomorphic mobile robot, anthropomorphic service robot, arm motion, global navigation technique, grasp motion, local multiresolution height map, mobile bin picking, mobile robots, motion control, object detection, service robots, shape primitive-based approach},
	pages = {2327--2334}
}

@inproceedings{schwarz_nimbro_2017,
	title = {{NimbRo} picking: {Versatile} part handling for warehouse automation},
	shorttitle = {{NimbRo} picking},
	doi = {10.1109/ICRA.2017.7989348},
	abstract = {Part handling in warehouse automation is challenging if a large variety of items must be accommodated and items are stored in unordered piles. To foster research in this domain, Amazon holds picking challenges. We present our system which achieved second and third place in the Amazon Picking Challenge 2016 tasks. The challenge required participants to pick a list of items from a shelf or to stow items into the shelf. Using two deep-learning approaches for object detection and semantic segmentation and one item model registration method, our system localizes the requested item. Manipulation occurs using suction on points determined heuristically or from 6D item model registration. Parametrized motion primitives are chained to generate motions. We present a full-system evaluation during the APC 2016 and component-level evaluations of the perception system on an annotated dataset.},
	booktitle = {2017 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Schwarz, M. and Milan, A. and Lenz, C. and Muñoz, A. and Periyasamy, A. S. and Schreiber, M. and Schüller, S. and Behnke, S.},
	month = may,
	year = {2017},
	keywords = {6D item model registration, Amazon Picking Challenge 2016 tasks, Automation, Feature extraction, NimbRo picking, Proposals, Robot sensing systems, Support vector machines, Training, annotated dataset, deep-learning approach, image registration, image segmentation, industrial manipulators, learning (artificial intelligence), object detection, one item model registration method, pose estimation, robot vision, semantic segmentation, versatile part handling, warehouse automation},
	pages = {3032--3039}
}

@misc{noauthor_automatic_nodate,
	title = {Automatic grasp planning using shape primitives - {Semantic} {Scholar}},
	url = {/paper/Automatic-grasp-planning-using-shape-primitives-Miller-Knoop/1153691476241aed35de896998fd129589537a45},
	abstract = {Automatic grasp planning for robotic hands is a difficult problem because of the huge number of possible hand configurations. However, humans simplify the problem by choosing an appropriate prehensile posture appropriate for the object and task to be performed. By modeling an object as a set of shape primitives, such as spheres, cylinders, cones and boxes, we can use a set of rules to generate a set of grasp starting positions and pregrasp shapes that can then be tested on the object model. Each grasp is tested and evaluated within our grasping simulator “GraspIt!”, and the best grasps are presented to the user. The simulator can also plan grasps in a complex environment involving obstacles and the reachability constraints of a robot arm.},
	urldate = {2018-02-19TZ}
}

@inproceedings{schwarz_nimbro_2017-1,
	title = {{NimbRo} picking: {Versatile} part handling for warehouse automation},
	shorttitle = {{NimbRo} picking},
	doi = {10.1109/ICRA.2017.7989348},
	abstract = {Part handling in warehouse automation is challenging if a large variety of items must be accommodated and items are stored in unordered piles. To foster research in this domain, Amazon holds picking challenges. We present our system which achieved second and third place in the Amazon Picking Challenge 2016 tasks. The challenge required participants to pick a list of items from a shelf or to stow items into the shelf. Using two deep-learning approaches for object detection and semantic segmentation and one item model registration method, our system localizes the requested item. Manipulation occurs using suction on points determined heuristically or from 6D item model registration. Parametrized motion primitives are chained to generate motions. We present a full-system evaluation during the APC 2016 and component-level evaluations of the perception system on an annotated dataset.},
	booktitle = {2017 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Schwarz, M. and Milan, A. and Lenz, C. and Muñoz, A. and Periyasamy, A. S. and Schreiber, M. and Schüller, S. and Behnke, S.},
	month = may,
	year = {2017},
	keywords = {6D item model registration, Amazon Picking Challenge 2016 tasks, Automation, Feature extraction, NimbRo picking, Proposals, Robot sensing systems, Support vector machines, Training, annotated dataset, deep-learning approach, image registration, image segmentation, industrial manipulators, learning (artificial intelligence), object detection, one item model registration method, pose estimation, robot vision, semantic segmentation, versatile part handling, warehouse automation},
	pages = {3032--3039}
}

@article{zeng_multi-view_2016,
	title = {Multi-view {Self}-supervised {Deep} {Learning} for 6D {Pose} {Estimation} in the {Amazon} {Picking} {Challenge}},
	url = {http://arxiv.org/abs/1609.09475},
	abstract = {Robot warehouse automation has attracted significant interest in recent years, perhaps most visibly in the Amazon Picking Challenge (APC). A fully autonomous warehouse pick-and-place system requires robust vision that reliably recognizes and locates objects amid cluttered environments, self-occlusions, sensor noise, and a large variety of objects. In this paper we present an approach that leverages multi-view RGB-D data and self-supervised, data-driven learning to overcome those difficulties. The approach was part of the MIT-Princeton Team system that took 3rd- and 4th- place in the stowing and picking tasks, respectively at APC 2016. In the proposed approach, we segment and label multiple views of a scene with a fully convolutional neural network, and then fit pre-scanned 3D object models to the resulting segmentation to get the 6D object pose. Training a deep neural network for segmentation typically requires a large amount of training data. We propose a self-supervised method to generate a large labeled dataset without tedious manual segmentation. We demonstrate that our system can reliably estimate the 6D pose of objects under a variety of scenarios. All code, data, and benchmarks are available at http://apc.cs.princeton.edu/},
	urldate = {2018-02-19TZ},
	journal = {arXiv:1609.09475 [cs]},
	author = {Zeng, Andy and Yu, Kuan-Ting and Song, Shuran and Suo, Daniel and Walker Jr., Ed and Rodriguez, Alberto and Xiao, Jianxiong},
	month = sep,
	year = {2016},
	note = {arXiv: 1609.09475},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning, Computer Science - Robotics}
}

@article{hernandez_team_2016,
	title = {Team {Delft}'s {Robot} {Winner} of the {Amazon} {Picking} {Challenge} 2016},
	url = {http://arxiv.org/abs/1610.05514},
	abstract = {This paper describes Team Delft's robot, which won the Amazon Picking Challenge 2016, including both the Picking and the Stowing competitions. The goal of the challenge is to automate pick and place operations in unstructured environments, specifically the shelves in an Amazon warehouse. Team Delft's robot is based on an industrial robot arm, 3D cameras and a customized gripper. The robot's software uses ROS to integrate off-the-shelf components and modules developed specifically for the competition, implementing Deep Learning and other AI techniques for object recognition and pose estimation, grasp planning and motion planning. This paper describes the main components in the system, and discusses its performance and results at the Amazon Picking Challenge 2016 finals.},
	urldate = {2018-02-19TZ},
	journal = {arXiv:1610.05514 [cs]},
	author = {Hernandez, Carlos and Bharatheesha, Mukunda and Ko, Wilson and Gaiser, Hans and Tan, Jethro and van Deurzen, Kanter and de Vries, Maarten and Van Mil, Bas and van Egmond, Jeff and Burger, Ruben and Morariu, Mihai and Ju, Jihong and Gerrmann, Xander and Ensing, Ronald and Van Frankenhuyzen, Jan and Wisse, Martijn},
	month = oct,
	year = {2016},
	note = {arXiv: 1610.05514},
	keywords = {Computer Science - Robotics}
}

@inproceedings{jonschkowski_probabilistic_2016,
	title = {Probabilistic multi-class segmentation for the {Amazon} {Picking} {Challenge}},
	doi = {10.1109/IROS.2016.7758087},
	abstract = {We present a method for multi-class segmentation from RGB-D data in a realistic warehouse picking setting. The method computes pixel-wise probabilities and combines them to find a coherent object segmentation. It reliably segments objects in cluttered scenarios, even when objects are translucent, reflective, highly deformable, have fuzzy surfaces, or consist of loosely coupled components. The robust performance results from the exploitation of problem structure inherent to the warehouse setting. The proposed method proved its capabilities as part of our winning entry to the 2015 Amazon Picking Challenge. We present a detailed experimental analysis of the contribution of different information sources, compare our method to standard segmentation techniques, and assess possible extensions that further enhance the algorithm's capabilities. We release our software and data sets as open source.},
	booktitle = {2016 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Jonschkowski, R. and Eppner, C. and Höfer, S. and Martín-Martín, R. and Brock, O.},
	month = oct,
	year = {2016},
	keywords = {Amazon Picking Challenge, Histograms, Image color analysis, Image segmentation, Probabilistic logic, RGB-D data, Robots, Robustness, Three-dimensional displays, image colour analysis, image segmentation, object segmentation, probabilistic multiclass segmentation, probability, production engineering computing, red-green-blue-depth data, segmentation techniques, warehouse picking setting, warehousing},
	pages = {1--7}
}

@article{zeng_robotic_2017,
	title = {Robotic {Pick}-and-{Place} of {Novel} {Objects} in {Clutter} with {Multi}-{Affordance} {Grasping} and {Cross}-{Domain} {Image} {Matching}},
	url = {http://arxiv.org/abs/1710.01330},
	abstract = {This paper presents a robotic pick-and-place system that is capable of grasping and recognizing both known and novel objects in cluttered environments. The key new feature of the system is that it handles a wide range of object categories without needing any task-specific training data for novel objects. To achieve this, it first uses a category-agnostic affordance prediction algorithm to select among four different grasping primitive behaviors. It then recognizes picked objects with a cross-domain image classification framework that matches observed images to product images. Since product images are readily available for a wide range of objects (e.g., from the web), the system works out-of-the-box for novel objects without requiring any additional training data. Exhaustive experimental results demonstrate that our multi-affordance grasping achieves high success rates for a wide variety of objects in clutter, and our recognition algorithm achieves high accuracy for both known and novel grasped objects. The approach was part of the MIT-Princeton Team system that took 1st place in the stowing task at the 2017 Amazon Robotics Challenge. All code, datasets, and pre-trained models are available online at http://arc.cs.princeton.edu},
	urldate = {2018-02-17TZ},
	journal = {arXiv:1710.01330 [cs]},
	author = {Zeng, Andy and Song, Shuran and Yu, Kuan-Ting and Donlon, Elliott and Hogan, Francois R. and Bauza, Maria and Ma, Daolin and Taylor, Orion and Liu, Melody and Romo, Eudald and Fazeli, Nima and Alet, Ferran and Dafle, Nikhil Chavan and Holladay, Rachel and Morona, Isabella and Nair, Prem Qu and Green, Druck and Taylor, Ian and Liu, Weber and Funkhouser, Thomas and Rodriguez, Alberto},
	month = oct,
	year = {2017},
	note = {arXiv: 1710.01330},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics}
}

@article{negussie_thermochromic_2016,
	title = {Thermochromic tissue-mimicking phantom for optimisation of thermal tumour ablation},
	volume = {32},
	issn = {0265-6736},
	url = {https://doi.org/10.3109/02656736.2016.1145745},
	doi = {10.3109/02656736.2016.1145745},
	abstract = {Purpose The purpose of this study was to (1) develop a novel tissue-mimicking thermochromic (TMTC) phantom that permanently changes colour from white to magenta upon heating above ablative temperatures, and (2) assess its utility for specific applications in evaluating thermal therapy devices.Materials and methods Polyacrylamide gel mixed with thermochromic ink was custom made to produce a TMTC phantom that changes its colour upon heating above biological ablative temperatures ({\textgreater} 60 °C). The thermal properties of the phantom were characterised, and compared to those of human tissue. In addition, utility of this phantom as a tool for the assessment of laser and microwave thermal ablation was examined.Results The mass density, thermal conductivity, and thermal diffusivity of the TMTC phantom were measured as 1033 ± 1.0 kg/m3, 0.590 ± 0.015 W/m.K, and 0.145 ± 0.002 mm2/s, respectively, and found to be in agreement with reported values for human soft tissues. Heating the phantom with laser and microwave ablation devices produced clearly demarcated regions of permanent colour change geographically corresponding to regions with temperature elevations above 60 °C.Conclusion The TMTC phantom provides direct visualisation of ablation dynamics, including ablation volume and geometry as well as peak absolute temperatures within the treated region post-ablation. This phantom can be specifically tailored for different thermal therapy modalities, such as radiofrequency, laser, microwave, or therapeutic ultrasound ablation. Such modality-specific phantoms may enable better quality assurance, device characterisation, and ablation parameter optimisation, or optimise the study of dynamic heating parameters integral to drug device combination therapies relying upon heat.},
	number = {3},
	urldate = {2018-02-15TZ},
	journal = {International Journal of Hyperthermia},
	author = {Negussie, Ayele H. and Partanen, Ari and Mikhail, Andrew S. and Xu, Sheng and Abi-Jaoudeh, Nadine and Maruvada, Subha and Wood, Bradford J.},
	month = apr,
	year = {2016},
	pmid = {27099078},
	keywords = {HIFU, RF, laser, microwave, thermal ablation, thermal phantom, thermal therapy, thermochromic, tissue-mimicking},
	pages = {239--243}
}

@article{negussie_thermochromic_2016-1,
	title = {Thermochromic tissue-mimicking phantom for optimisation of thermal tumour ablation},
	volume = {32},
	issn = {1464-5157},
	doi = {10.3109/02656736.2016.1145745},
	abstract = {Purpose The purpose of this study was to (1) develop a novel tissue-mimicking thermochromic (TMTC) phantom that permanently changes colour from white to magenta upon heating above ablative temperatures, and (2) assess its utility for specific applications in evaluating thermal therapy devices. Materials and methods Polyacrylamide gel mixed with thermochromic ink was custom made to produce a TMTC phantom that changes its colour upon heating above biological ablative temperatures ({\textgreater} 60 °C). The thermal properties of the phantom were characterised, and compared to those of human tissue. In addition, utility of this phantom as a tool for the assessment of laser and microwave thermal ablation was examined. Results The mass density, thermal conductivity, and thermal diffusivity of the TMTC phantom were measured as 1033 ± 1.0 kg/m(3), 0.590 ± 0.015 W/m.K, and 0.145 ± 0.002 mm(2)/s, respectively, and found to be in agreement with reported values for human soft tissues. Heating the phantom with laser and microwave ablation devices produced clearly demarcated regions of permanent colour change geographically corresponding to regions with temperature elevations above 60 °C. Conclusion The TMTC phantom provides direct visualisation of ablation dynamics, including ablation volume and geometry as well as peak absolute temperatures within the treated region post-ablation. This phantom can be specifically tailored for different thermal therapy modalities, such as radiofrequency, laser, microwave, or therapeutic ultrasound ablation. Such modality-specific phantoms may enable better quality assurance, device characterisation, and ablation parameter optimisation, or optimise the study of dynamic heating parameters integral to drug device combination therapies relying upon heat.},
	language = {eng},
	number = {3},
	journal = {International Journal of Hyperthermia: The Official Journal of European Society for Hyperthermic Oncology, North American Hyperthermia Group},
	author = {Negussie, Ayele H. and Partanen, Ari and Mikhail, Andrew S. and Xu, Sheng and Abi-Jaoudeh, Nadine and Maruvada, Subha and Wood, Bradford J.},
	year = {2016},
	pmid = {27099078},
	keywords = {Ablation Techniques, Acrylic Resins, Color, HIFU, Humans, Hyperthermia, Induced, Lasers, Microwaves, Neoplasms, Phantoms, Imaging, RF, Temperature, Thermal Conductivity, laser, microwave, thermal ablation, thermal phantom, thermal therapy, thermochromic, tissue-mimicking},
	pages = {239--243}
}

@inproceedings{kim_development_2011,
	title = {Development of an agar phantom adaptable for visualization of thermal distribution caused by focused ultrasound},
	doi = {10.1109/ULTSYM.2011.0339},
	abstract = {To analyze the ultrasound power and exposure time in medical treatment, the temperature distribution due to the ultrasound must be measured. In this study, an agar phantom adaptable for visualization of thermal distribution was developed. Thermochromic particles were used to visualize the thermal distribution in the phantom instead of human tissue. The ultrasound field was focused by a concave-type transducer in the phantom, and the color pattern change with the change in temperature was observed.},
	booktitle = {2011 {IEEE} {International} {Ultrasonics} {Symposium}},
	author = {Kim, Jungsoon and Kim, Moojoon and Park, Yejoon and Ha, Kanglyeol},
	month = oct,
	year = {2011},
	keywords = {Acoustics, Phantoms, Sugar, Temperature distribution, Temperature measurement, Transducers, Ultrasonic imaging, agar phantom, biological tissues, biomedical transducers, biomedical ultrasonics, biothermics, color pattern, colour, concave-type transducer, focused ultrasound, focusing, human tissue, medical treatment, patient treatment, phantom, phantoms, temperature distribution, thermal distribution, thermo-optical effects, thermochromic, thermochromic particles, ultrasonic transducers, ultrasound, ultrasound field, ultrasound power, visualization},
	pages = {1372--1375}
}

@article{takegami_polyacrylamide_2004,
	title = {Polyacrylamide gel containing egg white as new model for irradiation experiments using focused ultrasound},
	volume = {30},
	issn = {0301-5629},
	url = {http://www.sciencedirect.com/science/article/pii/S0301562904001929},
	doi = {10.1016/j.ultrasmedbio.2004.07.016},
	abstract = {A polyacrylamide (PAA) gel containing egg white as a new model for irradiation experiments in high-intensity focused ultrasound HIFU is introduced. The gel is transparent except in thermally necrosed regions which are white. The model is similar to, and has the same benefits as, gels containing bovine serum albumin (BSA) protein, but egg is less expensive than BSA. The acoustic properties of the gel are very favorable, similar to those of soft tissues; density 1.0 g/cm3, sound speed 1540 m/s and acoustic attenuation 0.4 dB/cm at 2 MHz. We illustrate the usefulness of the gel in visualizing HIFU lesions and introduce a new model of gastric submucosal tumor in a rabbit stomach, showing that this gel can be formed into any desired shape. Our PAA gel containing egg white is an attractive candidate for a disposable acoustic material suitable for experimental applications of HIFU. (E-mail: ktakegami-tky@umin.ac.jp)},
	number = {10},
	urldate = {2018-02-15TZ},
	journal = {Ultrasound in Medicine \& Biology},
	author = {Takegami, Kenji and Kaneko, Yukio and Watanabe, Toshiaki and Maruyama, Toshiyuki and Matsumoto, Yoichiro and Nagawa, Hirokazu},
	month = oct,
	year = {2004},
	keywords = {High-intensity focused ultrasound, Polyacrylamide gel, Submucosal tumor, Tissue-mimicking phantom gel, Ultrasound},
	pages = {1419--1422}
}

@article{takegami_polyacrylamide_2004-1,
	title = {Polyacrylamide gel containing egg white as new model for irradiation experiments using focused ultrasound},
	volume = {30},
	issn = {0301-5629},
	url = {http://www.sciencedirect.com/science/article/pii/S0301562904001929},
	doi = {10.1016/j.ultrasmedbio.2004.07.016},
	abstract = {A polyacrylamide (PAA) gel containing egg white as a new model for irradiation experiments in high-intensity focused ultrasound HIFU is introduced. The gel is transparent except in thermally necrosed regions which are white. The model is similar to, and has the same benefits as, gels containing bovine serum albumin (BSA) protein, but egg is less expensive than BSA. The acoustic properties of the gel are very favorable, similar to those of soft tissues; density 1.0 g/cm3, sound speed 1540 m/s and acoustic attenuation 0.4 dB/cm at 2 MHz. We illustrate the usefulness of the gel in visualizing HIFU lesions and introduce a new model of gastric submucosal tumor in a rabbit stomach, showing that this gel can be formed into any desired shape. Our PAA gel containing egg white is an attractive candidate for a disposable acoustic material suitable for experimental applications of HIFU. (E-mail: ktakegami-tky@umin.ac.jp)},
	number = {10},
	urldate = {2018-02-15TZ},
	journal = {Ultrasound in Medicine \& Biology},
	author = {Takegami, Kenji and Kaneko, Yukio and Watanabe, Toshiaki and Maruyama, Toshiyuki and Matsumoto, Yoichiro and Nagawa, Hirokazu},
	month = oct,
	year = {2004},
	keywords = {High-intensity focused ultrasound, Polyacrylamide gel, Submucosal tumor, Tissue-mimicking phantom gel, Ultrasound},
	pages = {1419--1422}
}

@article{takegami_polyacrylamide_2004-2,
	title = {Polyacrylamide gel containing egg white as new model for irradiation experiments using focused ultrasound},
	volume = {30},
	issn = {0301-5629},
	doi = {10.1016/j.ultrasmedbio.2004.07.016},
	abstract = {A polyacrylamide (PAA) gel containing egg white as a new model for irradiation experiments in high-intensity focused ultrasound HIFU is introduced. The gel is transparent except in thermally necrosed regions which are white. The model is similar to, and has the same benefits as, gels containing bovine serum albumin (BSA) protein, but egg is less expensive than BSA. The acoustic properties of the gel are very favorable, similar to those of soft tissues; density 1.0 g/cm(3), sound speed 1540 m/s and acoustic attenuation 0.4 dB/cm at 2 MHz. We illustrate the usefulness of the gel in visualizing HIFU lesions and introduce a new model of gastric submucosal tumor in a rabbit stomach, showing that this gel can be formed into any desired shape. Our PAA gel containing egg white is an attractive candidate for a disposable acoustic material suitable for experimental applications of HIFU.},
	language = {eng},
	number = {10},
	journal = {Ultrasound in Medicine \& Biology},
	author = {Takegami, Kenji and Kaneko, Yukio and Watanabe, Toshiaki and Maruyama, Toshiyuki and Matsumoto, Yoichiro and Nagawa, Hirokazu},
	month = oct,
	year = {2004},
	pmid = {15582242},
	keywords = {Acrylic Resins, Animals, Egg White, Gastric Mucosa, Models, Biological, Phantoms, Imaging, Rabbits, Stomach Neoplasms, Ultrasonic Therapy, Ultrasonography},
	pages = {1419--1422}
}

@article{mikhail_evaluation_2016,
	title = {Evaluation of a tissue-mimicking thermochromic phantom for radiofrequency ablation},
	volume = {43},
	issn = {0094-2405},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4912564/},
	doi = {10.1118/1.4953394},
	abstract = {Purpose:
This work describes the characterization and evaluation of a tissue-mimicking thermochromic phantom (TMTCP) for direct visualization and quantitative determination of temperatures during radiofrequency ablation (RFA).

Methods:
TMTCP material was prepared using polyacrylamide gel and thermochromic ink that permanently changes color from white to magenta when heated. Color vs temperature calibration was generated in matlab by extracting RGB color values from digital photographs of phantom standards heated in a water bath at 25–75 °C. RGB and temperature values were plotted prior to curve fitting in mathematica using logistic functions of form f(t) = a + b/(1 + e(c(t−d))), where a, b, c, and d are coefficients and t denotes temperature. To quantify temperatures based on TMTCP color, phantom samples were heated to temperatures blinded to the investigators, and two methods were evaluated: (1) visual comparison of sample color to the calibration series and (2) in silico analysis using the inverse of the logistic functions to convert sample photograph RGB values to absolute temperatures. For evaluation of TMTCP performance with RFA, temperatures in phantom samples and in a bovine liver were measured radially from an RF electrode during heating using fiber-optic temperature probes. Heating and cooling rates as well as the area under the temperature vs time curves were compared. Finally, temperature isotherms were generated computationally based on color change in bisected phantoms following RFA and compared to temperature probe measurements.

Results:
TMTCP heating resulted in incremental, permanent color changes between 40 and 64 °C. Visual and computational temperature estimation methods were accurate to within 1.4 and 1.9 °C between 48 and 67 °C, respectively. Temperature estimates were most accurate between 52 and 62 °C, resulting in differences from actual temperatures of 0.6 and 1.6 °C for visual and computational methods, respectively. Temperature measurements during RFA using fiber-optic probes matched closely with maximum temperatures predicted by color changes in the TMTCP. Heating rate and cooling rate, as well as the area under the temperature vs time curve were similar for TMTCP and ex vivo liver.

Conclusions:
The TMTCP formulated for use with RFA can be used to provide quantitative temperature information in mild hyperthermic (40–45 °C), subablative (45–50 °C), and ablative ({\textgreater}50 °C) temperature ranges. Accurate visual or computational estimates of absolute temperatures and ablation zone geometry can be made with high spatial resolution based on TMTCP color. As such, the TMTCP can be used to assess RFA heating characteristics in a controlled, predictable environment.},
	number = {7},
	urldate = {2018-02-15TZ},
	journal = {Medical Physics},
	author = {Mikhail, Andrew S. and Negussie, Ayele H. and Graham, Cole and Mathew, Manoj and Wood, Bradford J. and Partanen, Ari},
	month = jul,
	year = {2016},
	pmid = {27370145},
	pmcid = {PMC4912564},
	pages = {4304--4311}
}

@misc{noauthor_bounded_nodate,
	title = {Bounded {Suboptimal} {Search}: {A} {Direct} {Approach} {Using} {Inadmissible} {Estimates} - {Semantic} {Scholar}},
	shorttitle = {Bounded {Suboptimal} {Search}},
	url = {/paper/Bounded-Suboptimal-Search-A-Direct-Approach-Using-Thayer-Ruml/52e010bab82c158a30c863a05847d7314c2dd964},
	abstract = {Bounded suboptimal search algorithms offer shorter solving times by sacrificing optimality and instead guaranteeing solution costs within a desired factor of optimal. Typically these algorithms use a single admissible heuristic both for guiding search and bounding solution cost. In this paper, we present a new approach to bounded suboptimal search, Explicit Estimation Search, that separates these roles, consulting potentially inadmissible information to determine search order and using admissible information to guarantee the cost bound. Unlike previous proposals, it successfully combines estimates of solution length and solution cost to predict which node will lead most quickly to a solution within the suboptimality bound. An empirical evaluation across six diverse benchmark domains shows that Explicit Estimation Search is competitive with the previous state of the art in domains with unit-cost actions and substantially outperforms previously proposed techniques for domains in which solution cost and length can differ.},
	urldate = {2018-02-08TZ}
}

@article{likhachev_anytime_2008,
	title = {Anytime search in dynamic graphs},
	volume = {172},
	issn = {0004-3702},
	url = {http://www.sciencedirect.com/science/article/pii/S000437020800060X},
	doi = {10.1016/j.artint.2007.11.009},
	abstract = {Agents operating in the real world often have limited time available for planning their next actions. Producing optimal plans is infeasible in these scenarios. Instead, agents must be satisfied with the best plans they can generate within the time available. One class of planners well-suited to this task are anytime planners, which quickly find an initial, highly suboptimal plan, and then improve this plan until time runs out. A second challenge associated with planning in the real world is that models are usually imperfect and environments are often dynamic. Thus, agents need to update their models and consequently plans over time. Incremental planners, which make use of the results of previous planning efforts to generate a new plan, can substantially speed up each planning episode in such cases. In this paper, we present an A∗-based anytime search algorithm that produces significantly better solutions than current approaches, while also providing suboptimality bounds on the quality of the solution at any point in time. We also present an extension of this algorithm that is both anytime and incremental. This extension improves its current solution while deliberation time allows and is able to incrementally repair its solution when changes to the world model occur. We provide a number of theoretical and experimental results and demonstrate the effectiveness of the approaches in a robot navigation domain involving two physical systems. We believe that the simplicity, theoretical properties, and generality of the presented methods make them well suited to a range of search problems involving dynamic graphs.},
	number = {14},
	urldate = {2018-02-08TZ},
	journal = {Artificial Intelligence},
	author = {Likhachev, Maxim and Ferguson, Dave and Gordon, Geoff and Stentz, Anthony and Thrun, Sebastian},
	month = sep,
	year = {2008},
	keywords = {A, Anytime planning, Anytime search, Heuristic search, Incremental search, Planning, Replanning, Search},
	pages = {1613--1643}
}

@article{karaman_sampling-based_2011,
	title = {Sampling-based algorithms for optimal motion planning},
	volume = {30},
	issn = {0278-3649},
	url = {https://doi.org/10.1177/0278364911406761},
	doi = {10.1177/0278364911406761},
	abstract = {During the last decade, sampling-based path planning algorithms, such as probabilistic roadmaps (PRM) and rapidly exploring random trees (RRT), have been shown to work well in practice and possess theoretical guarantees such as probabilistic completeness. However, little effort has been devoted to the formal analysis of the quality of the solution returned by such algorithms, e.g. as a function of the number of samples. The purpose of this paper is to fill this gap, by rigorously analyzing the asymptotic behavior of the cost of the solution returned by stochastic sampling-based algorithms as the number of samples increases. A number of negative results are provided, characterizing existing algorithms, e.g. showing that, under mild technical conditions, the cost of the solution returned by broadly used sampling-based algorithms converges almost surely to a non-optimal value. The main contribution of the paper is the introduction of new algorithms, namely, PRM* and RRT*, which are provably asymptotically optimal, i.e. such that the cost of the returned solution converges almost surely to the optimum. Moreover, it is shown that the computational complexity of the new algorithms is within a constant factor of that of their probabilistically complete (but not asymptotically optimal) counterparts. The analysis in this paper hinges on novel connections between stochastic sampling-based path planning algorithms and the theory of random geometric graphs.},
	language = {en},
	number = {7},
	urldate = {2018-02-08TZ},
	journal = {The International Journal of Robotics Research},
	author = {Karaman, Sertac and Frazzoli, Emilio},
	month = jun,
	year = {2011},
	pages = {846--894}
}

@inproceedings{lelis_improved_2011,
	title = {Improved {Prediction} of {IDA}*'s {Performance} via {Epsilon}-{Truncation}},
	author = {Lelis, Levi and Zilles, Sandra and Craig Holte, Robert},
	month = may,
	year = {2011}
}

@article{stern_potential-based_2014,
	title = {Potential-based bounded-cost search and {Anytime} {Non}-{Parametric} {A}⁎},
	volume = {214},
	issn = {0004-3702},
	url = {http://www.sciencedirect.com/science/article/pii/S0004370214000551},
	doi = {10.1016/j.artint.2014.05.002},
	abstract = {This paper presents two new search algorithms: Potential Search (PTS) and Anytime Potential Search/Anytime Non-Parametric A⁎ (APTS/ANA⁎). Both algorithms are based on a new evaluation function that is easy to implement and does not require user-tuned parameters. PTS is designed to solve bounded-cost search problems, which are problems where the task is to find as fast as possible a solution under a given cost bound. APTS/ANA⁎ is a non-parametric anytime search algorithm discovered independently by two research groups via two very different derivations. In this paper, co-authored by researchers from both groups, we present these derivations: as a sequence of calls to PTS and as a non-parametric greedy variant of Anytime Repairing A⁎. We describe experiments that evaluate the new algorithms in the 15-puzzle, KPP-COM, robot motion planning, gridworld navigation, and multiple sequence alignment search domains. Our results suggest that when compared with previous anytime algorithms, APTS/ANA⁎: (1) does not require user-set parameters, (2) finds an initial solution faster, (3) spends less time between solution improvements, (4) decreases the suboptimality bound of the current-best solution more gradually, and (5) converges faster to an optimal solution when reachable.},
	urldate = {2018-02-08TZ},
	journal = {Artificial Intelligence},
	author = {Stern, Roni and Felner, Ariel and van den Berg, Jur and Puzis, Rami and Shah, Rajat and Goldberg, Ken},
	month = sep,
	year = {2014},
	keywords = {Anytime algorithms, Heuristic search, Robotics},
	pages = {1--25}
}

@inproceedings{allouche_anytime_2015,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Anytime {Hybrid} {Best}-{First} {Search} with {Tree} {Decomposition} for {Weighted} {CSP}},
	isbn = {978-3-319-23218-8 978-3-319-23219-5},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-23219-5_2},
	doi = {10.1007/978-3-319-23219-5_2},
	abstract = {We propose Hybrid Best-First Search (HBFS), a search strategy for optimization problems that combines Best-First Search (BFS) and Depth-First Search (DFS). Like BFS, HBFS provides an anytime global lower bound on the optimum, while also providing anytime upper bounds, like DFS. Hence, it provides feedback on the progress of search and solution quality in the form of an optimality gap. In addition, it exhibits highly dynamic behavior that allows it to perform on par with methods like limited discrepancy search and frequent restarting in terms of quickly finding good solutions.We also use the lower bounds reported by HBFS in problems with small treewidth, by integrating it into Backtracking with Tree Decomposition (BTD). BTD-HBFS exploits the lower bounds reported by HBFS in individual clusters to improve the anytime behavior and global pruning lower bound of BTD.In an extensive empirical evaluation on optimization problems from a variety of application domains, we show that both HBFS and BTD-HBFS improve both anytime and overall performance compared to their counterparts.},
	language = {en},
	urldate = {2018-02-08TZ},
	booktitle = {Principles and {Practice} of {Constraint} {Programming}},
	publisher = {Springer, Cham},
	author = {Allouche, David and Givry, Simon de and Katsirelos, George and Schiex, Thomas and Zytnicki, Matthias},
	month = aug,
	year = {2015},
	pages = {12--29}
}

@article{stern_potential-based_2014-1,
	title = {Potential-based bounded-cost search and {Anytime} {Non}-{Parametric} {A}⁎},
	volume = {214},
	issn = {0004-3702},
	url = {http://www.sciencedirect.com/science/article/pii/S0004370214000551},
	doi = {10.1016/j.artint.2014.05.002},
	abstract = {This paper presents two new search algorithms: Potential Search (PTS) and Anytime Potential Search/Anytime Non-Parametric A⁎ (APTS/ANA⁎). Both algorithms are based on a new evaluation function that is easy to implement and does not require user-tuned parameters. PTS is designed to solve bounded-cost search problems, which are problems where the task is to find as fast as possible a solution under a given cost bound. APTS/ANA⁎ is a non-parametric anytime search algorithm discovered independently by two research groups via two very different derivations. In this paper, co-authored by researchers from both groups, we present these derivations: as a sequence of calls to PTS and as a non-parametric greedy variant of Anytime Repairing A⁎. We describe experiments that evaluate the new algorithms in the 15-puzzle, KPP-COM, robot motion planning, gridworld navigation, and multiple sequence alignment search domains. Our results suggest that when compared with previous anytime algorithms, APTS/ANA⁎: (1) does not require user-set parameters, (2) finds an initial solution faster, (3) spends less time between solution improvements, (4) decreases the suboptimality bound of the current-best solution more gradually, and (5) converges faster to an optimal solution when reachable.},
	urldate = {2018-02-08TZ},
	journal = {Artificial Intelligence},
	author = {Stern, Roni and Felner, Ariel and van den Berg, Jur and Puzis, Rami and Shah, Rajat and Goldberg, Ken},
	month = sep,
	year = {2014},
	keywords = {Anytime algorithms, Heuristic search, Robotics},
	pages = {1--25}
}

@article{sharon_increasing_2013,
	title = {The increasing cost tree search for optimal multi-agent pathfinding},
	volume = {195},
	issn = {0004-3702},
	url = {http://www.sciencedirect.com/science/article/pii/S0004370212001543},
	doi = {10.1016/j.artint.2012.11.006},
	abstract = {We address the problem of optimal pathfinding for multiple agents. Given a start state and a goal state for each of the agents, the task is to find minimal paths for the different agents while avoiding collisions. Previous work on solving this problem optimally, used traditional single-agent search variants of the A* algorithm. We present a novel formalization for this problem which includes a search tree called the increasing cost tree (ICT) and a corresponding search algorithm, called the increasing cost tree search (ICTS) that finds optimal solutions. ICTS is a two-level search algorithm. The high-level phase of ICTS searches the increasing cost tree for a set of costs (cost per agent). The low-level phase of ICTS searches for a valid path for every agent that is constrained to have the same cost as given by the high-level phase. We analyze this new formalization, compare it to the A* search formalization and provide the pros and cons of each. Following, we show how the unique formalization of ICTS allows even further pruning of the state space by grouping small sets of agents and identifying unsolvable combinations of costs. Experimental results on various domains show the benefits and limitations of our new approach. A speedup of up to 3 orders of magnitude was obtained in some cases.},
	urldate = {2018-02-08TZ},
	journal = {Artificial Intelligence},
	author = {Sharon, Guni and Stern, Roni and Goldenberg, Meir and Felner, Ariel},
	month = feb,
	year = {2013},
	keywords = {Heuristic search, Multi-agent pathfinding},
	pages = {470--495}
}

@incollection{celani_spacecraft_nodate,
	title = {Spacecraft {Attitude} {Motion} {Planning} using {GRAFS}},
	url = {https://arc.aiaa.org/doi/abs/10.2514/6.2018-0961},
	urldate = {2018-02-06TZ},
	booktitle = {2018 {Space} {Flight} {Mechanics} {Meeting}},
	publisher = {American Institute of Aeronautics and Astronautics},
	author = {Celani, Fabio and Lucarelli, Dennis G.},
	doi = {10.2514/6.2018-0961}
}

@misc{noauthor_incremental_nodate,
	title = {Incremental {Task} and {Motion} {Planning}: {A} {Constraint}-{Based} {Approach} - {Semantic} {Scholar}},
	shorttitle = {Incremental {Task} and {Motion} {Planning}},
	url = {/paper/Incremental-Task-and-Motion-Planning-A-Constraint-Dantam-Kingston/6d1e97df31e9a4b0255243d86608c4b7f725133b},
	abstract = {We present a new algorithm for task and motion planning (TMP) and discuss the requirements and abstractions necessary to obtain robust solutions for TMP in general. Our Iteratively Deepened Task and Motion Planning (IDTMP) method is probabilistically-complete and offers improved performance and generality compared to a similar, state-of-theart, probabilistically-complete planner. The key idea of IDTMP is to leverage incremental constraint solving to efficiently add and remove constraints on motion feasibility at the task level. We validate IDTMP on a physical manipulator and evaluate scalability on scenarios with many objects and long plans, showing order-of-magnitude gains compared to the benchmark planner and a four-times self-comparison speedup from our extensions. Finally, in addition to describing a new method for TMP and its implementation on a physical robot, we also put forward requirements and abstractions for the development of similar planners in the future.},
	urldate = {2018-02-05TZ}
}

@inproceedings{choudhury_pareto-optimal_2016,
	title = {Pareto-optimal search over configuration space beliefs for anytime motion planning},
	doi = {10.1109/IROS.2016.7759551},
	abstract = {We present POMP (Pareto Optimal Motion Planner), an anytime algorithm for geometric path planning on roadmaps. For robots with several degrees of freedom, collision checks are computationally expensive and often dominate planning time. Our goal is to minimize the number of collision checks for obtaining the first feasible path and successively shorter feasible paths. We assume that the roadmaps we search over are embedded in a continuous ambient space, where nearby points tend to share the same collision state. This enables us to formulate a probabilistic model that computes the probability of unevaluated configurations being collision-free. We update the model over time as more checks are performed. This model lets us define a weighting function for roadmap edges that is related to the probability of the edge being in collision. Our approach is to trade off between these two weights, gradually prioritizing edge length over collision likelihood. We also show that this tradeoff is approximately equivalent to minimizing the expected path length, with a penalty of being in collision. Our experiments demonstrate that POMP performs comparably with RRTConnect and LazyPRM for the first feasible path, and BIT* for anytime performance, both in terms of collision checks and total planning time.},
	booktitle = {2016 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Choudhury, S. and Dellin, C. M. and Srinivasa, S. S.},
	month = oct,
	year = {2016},
	keywords = {Collision avoidance, Computational modeling, LazyPRM, POMP, Pareto optimal motion planner, Pareto optimal search, Pareto optimisation, Pareto optimization, Path planning, Planning, Probabilistic logic, RRTConnect, Robots, anytime algorithm, anytime motion planning, collision checks, collision likelihood, collision state, configuration space beliefs, continuous ambient space, geometric path planning, mobile robots, path planning, planning time, probabilistic model, roadmap edges, robots, unevaluated configurations, weighting function},
	pages = {3742--3749}
}

@inproceedings{pivtoraiko_efficient_2005,
	title = {Efficient {Constrained} {Path} {Planning} via {Search} in {State} {Lattices}},
	volume = {603},
	url = {http://adsabs.harvard.edu/abs/2005ESASP.603E..33P},
	abstract = {Not Available},
	urldate = {2018-02-02TZ},
	author = {Pivtoraiko, M. and Kelly, A.},
	month = aug,
	year = {2005},
	pages = {33}
}

@inproceedings{ziegler_spatiotemporal_2009,
	title = {Spatiotemporal state lattices for fast trajectory planning in dynamic on-road driving scenarios},
	doi = {10.1109/IROS.2009.5354448},
	abstract = {We present a method for motion planning in the presence of moving obstacles that is aimed at dynamic on-road driving scenarios. Planning is performed within a geometric graph that is established by sampling deterministically from a manifold that is obtained by combining configuration space and time. We show that these graphs are acyclic and shortest path algorithms with linear runtime can be employed. By reparametrising the configuration space to match the course of the road, it can be sampled very economically with few vertices, and this reduces absolute runtime further. The trajectories generated are quintic splines. They are second order continuous, obey nonholonomic constraints and are optimised for minimum square of jerk. Planning time remains below 20 ms on general purpose hardware.},
	booktitle = {2009 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Ziegler, J. and Stiller, C.},
	month = oct,
	year = {2009},
	keywords = {Intelligent vehicles, Lattices, Motion planning, Road vehicles, Runtime, Sampling methods, Space vehicles, Spatiotemporal phenomena, Trajectory, Vehicle dynamics, dynamic on-road driving scenarios, fast trajectory planning, geometric graph, motion planning, moving obstacles, path planning, position control, remotely operated vehicles, spatiotemporal state lattices, telerobotics},
	pages = {1879--1884}
}
@article{sun_objectobject_2014,
	title = {Object–object interaction affordance learning},
	volume = {62},
	issn = {0921-8890},
	url = {http://www.sciencedirect.com/science/article/pii/S0921889013002339},
	doi = {10.1016/j.robot.2013.12.005},
	abstract = {This paper presents a novel object–object affordance learning approach that enables intelligent robots to learn the interactive functionalities of objects from human demonstrations in everyday environments. Instead of considering a single object, we model the interactive motions between paired objects in a human–object–object way. The innate interaction-affordance knowledge of the paired objects are learned from a labeled training dataset that contains a set of relative motions of the paired objects, human actions, and object labels. The learned knowledge is represented with a Bayesian Network, and the network can be used to improve the recognition reliability of both objects and human actions and to generate proper manipulation motion for a robot if a pair of objects is recognized. This paper also presents an image-based visual servoing approach that uses the learned motion features of the affordance in interaction as the control goals to control a robot to perform manipulation tasks.},
	number = {4},
	urldate = {2018-01-30TZ},
	journal = {Robotics and Autonomous Systems},
	author = {Sun, Yu and Ren, Shaogang and Lin, Yun},
	month = apr,
	year = {2014},
	keywords = {Action recognition, Graphical model, Learn from demonstration, Object classification, Robot learning},
	pages = {487--496}
}

@article{luddecke_learning_2017,
	title = {Learning to {Label} {Affordances} from {Simulated} and {Real} {Data}},
	url = {http://arxiv.org/abs/1709.08872},
	abstract = {An autonomous robot should be able to evaluate the affordances that are offered by a given situation. Here we address this problem by designing a system that can densely predict affordances given only a single 2D RGB image. This is achieved with a convolutional neural network (ResNet), which we combine with refinement modules recently proposed for addressing semantic image segmentation. We define a novel cost function, which is able to handle (potentially multiple) affordances of objects and their parts in a pixel-wise manner even in the case of incomplete data. We perform qualitative as well as quantitative evaluations with simulated and real data assessing 15 different affordances. In general, we find that affordances, which are well-enough represented in the training data, are correctly recognized with a substantial fraction of correctly assigned pixels. Furthermore, we show that our model outperforms several baselines. Hence, this method can give clear action guidelines for a robot.},
	urldate = {2018-01-30TZ},
	journal = {arXiv:1709.08872 [cs]},
	author = {Lüddecke, Timo and Wörgötter, Florentin},
	month = sep,
	year = {2017},
	note = {arXiv: 1709.08872},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics}
}

@article{koppula_learning_2012,
	title = {Learning {Human} {Activities} and {Object} {Affordances} from {RGB}-{D} {Videos}},
	url = {http://arxiv.org/abs/1210.1207},
	abstract = {Understanding human activities and object affordances are two very important skills, especially for personal robots which operate in human environments. In this work, we consider the problem of extracting a descriptive labeling of the sequence of sub-activities being performed by a human, and more importantly, of their interactions with the objects in the form of associated affordances. Given a RGB-D video, we jointly model the human activities and object affordances as a Markov random field where the nodes represent objects and sub-activities, and the edges represent the relationships between object affordances, their relations with sub-activities, and their evolution over time. We formulate the learning problem using a structural support vector machine (SSVM) approach, where labelings over various alternate temporal segmentations are considered as latent variables. We tested our method on a challenging dataset comprising 120 activity videos collected from 4 subjects, and obtained an accuracy of 79.4\% for affordance, 63.4\% for sub-activity and 75.0\% for high-level activity labeling. We then demonstrate the use of such descriptive labeling in performing assistive tasks by a PR2 robot.},
	urldate = {2018-01-30TZ},
	journal = {arXiv:1210.1207 [cs]},
	author = {Koppula, Hema Swetha and Gupta, Rudhir and Saxena, Ashutosh},
	month = oct,
	year = {2012},
	note = {arXiv: 1210.1207},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics}
}

@article{maiolino_flexible_2017,
	title = {Flexible robot sealant dispensing cell using {RGB}-{D} sensor and off-line programming},
	volume = {48},
	issn = {0736-5845},
	url = {http://www.sciencedirect.com/science/article/pii/S0736584516302253},
	doi = {10.1016/j.rcim.2017.04.004},
	abstract = {In aerospace manufacture the accurate and robust application of sealant is an integral and challenging part of the manufacturing process that is still performed by human operator. Automation of this process is difficult and not cost effective due to the high variability in the parts to operate and also the difficulty associated with programming industrial robotic systems. This work tries to overcome these problems by presenting an AOLP (Automatic Off-Line Programming) system for sealant dispensing through the integration of the ABB's proprietary OLP (Off-Line Programming) system RobotStudio with a relatively new RBG-D sensor technology based on structured light and the development of a RobotStudio add-on. The integration of the vision system in the generation of the robot program overcomes the current problems related to AOLP systems that rely on a known model of the work environment. This enables the ability to dynamically adapt the model according to sensor data, thus coping with environmental and parts variability during operation. Furthermore it exploits the advantages of an OLP system simplifying the robot programming allowing for faster automation of the process.},
	urldate = {2018-01-25TZ},
	journal = {Robotics and Computer-Integrated Manufacturing},
	author = {Maiolino, Perla and Woolley, Richard and Branson, David and Benardos, Panorios and Popov, Atanas and Ratchev, Svetan},
	month = dec,
	year = {2017},
	keywords = {AOLP, RGB-D sensor, Sealant dispensing},
	pages = {188--195}
}

@inproceedings{huh_adaptive_2017,
	title = {Adaptive motion planning with high-dimensional mixture models},
	doi = {10.1109/ICRA.2017.7989431},
	abstract = {This paper presents a novel adaptive approach to fast sampling-based motion planning by learning models of collision and collision-free regions in configuration spaces in an online manner. The proposed approach incrementally learns Gaussian Mixture Models (GMMs) for collision detection in high dimensional configuration spaces. In practical applications for robotic manipulation, the representation of collision and collision-free regions in configuration space can change due to relative motion between the robot base and workspace. We show how to rapidly adapt to such changes by using inverse kinematics to transform the parameters of the Gaussian mixture model to new configurations. The transformed model is initially used as a prior and then continually updated and refined as the RRT planning algorithm proceeds in real-time. This approach is extremely computationally efficient, and our proposed method is compared with traditional sampling-based planning methods on a number of experimental robot arm planning scenarios.},
	booktitle = {2017 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Huh, J. and Lee, B. and Lee, D. D.},
	month = may,
	year = {2017},
	keywords = {Adaptation models, Collision avoidance, Computational modeling, GMM, Gaussian mixture models, Gaussian processes, Manipulators, Planning, Predictive models, RRT planning algorithm, adaptive control, adaptive motion planning, collision avoidance, collision regions learning models, collision-free regions learning models, experimental robot arm planning scenarios, high-dimensional configuration spaces, high-dimensional mixture models, learning (artificial intelligence), manipulators, mixture models, path planning, robotic manipulation, sampling-based motion planning, sampling-based planning methods},
	pages = {3740--3747}
}

@inproceedings{mar_self-supervised_2017,
	title = {Self-supervised learning of tool affordances from 3D tool representation through parallel {SOM} mapping},
	doi = {10.1109/ICRA.2017.7989110},
	abstract = {Future humanoid robots will be expected to carry out a wide range of tasks for which they had not been originally equipped by learning new skills and adapting to their environment. A crucial requirement towards that goal is to be able to take advantage of external elements as tools to perform tasks for which their own manipulators are insufficient; the ability to autonomously learn how to use tools will render robots far more versatile and simpler to design. Motivated by this prospect, this paper proposes and evaluates an approach to allow robots to learn tool affordances based on their 3D geometry. To this end, we apply tool-pose descriptors to represent tools combined with the way in which they are grasped, and affordance vectors to represent the effect tool-poses achieve in function of the action performed. This way, tool affordance learning consists in determining the mapping between these 2 representations, which is achieved in 2 steps. First, the dimensionality of both representations is reduced by unsupervisedly mapping them onto respective Self-Organizing Maps (SOMs). Then, the mapping between the neurons in the tool-pose SOM and the neurons in the affordance SOM for pairs of tool-poses and their corresponding affordance vectors, respectively, is learned with a neural based regression model. This method enables the robot to accurately predict the effect of its actions using tools, and thus to select the best action for a given goal, even with tools not seen on the learning phase.},
	booktitle = {2017 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Mar, T. and Tikhanoff, V. and Metta, G. and Natale, L.},
	month = may,
	year = {2017},
	keywords = {3D geometry, 3D tool representation, Feature extraction, Geometry, Histograms, Mathematical model, Robots, Three-dimensional displays, Tools, affordance vectors, humanoid robots, intelligent robots, neural based regression model, neurocontrollers, neurons, parallel SOM mapping, regression analysis, self-organising feature maps, self-organizing maps, self-supervised learning, tool affordance learning, tool-pose SOM, tool-pose descriptors, unsupervised learning, unsupervisedly mapping},
	pages = {894--901}
}

@inproceedings{bose_fast_2016,
	title = {Fast depth edge detection and edge based {RGB}-{D} {SLAM}},
	doi = {10.1109/ICRA.2016.7487265},
	abstract = {This paper presents a method of occluding depth edge-detection targeted towards RGB-D video streams and explores the use of these and other edge features in RGB-D SLAM. The proposed depth edge-detection approach uses prior information obtained from the previous RGB-D video frame to determine which areas of the current depth image are likely to contain edges due to image similarity. By limiting the search for edges to these areas a significant amount of computation time is saved compared to searching the entire image. Pixels belonging to both the depth and colour edges of an RGB-D image can be back projected using the depth component to form 3D point clouds of edge points. Registration between such edge point clouds is achieved using ICP and we present a realtime RGB-D SLAM system utilizing such back projected edge features. Experimental results are presented demonstrating the performance of both the proposed depth edge-detection and SLAM system using publicly available datasets.},
	booktitle = {2016 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Bose, L. and Richards, A.},
	month = may,
	year = {2016},
	keywords = {3D point clouds, Cameras, ICP, Image edge detection, Iterative closest point algorithm, RGB-D video streams, SLAM (robots), Simultaneous localization and mapping, Streaming media, Three-dimensional displays, back projected edge features, computation time, depth component, edge based RGB-D SLAM, edge detection, edge features, fast depth edge detection, image colour analysis, image similarity, iterative methods, mobile robots, publicly available datasets, robot vision, video streaming},
	pages = {1323--1330}
}

@inproceedings{mahler_dex-net_2016,
	title = {Dex-{Net} 1.0: {A} cloud-based network of 3D objects for robust grasp planning using a {Multi}-{Armed} {Bandit} model with correlated rewards},
	shorttitle = {Dex-{Net} 1.0},
	doi = {10.1109/ICRA.2016.7487342},
	abstract = {This paper presents the Dexterity Network (Dex-Net) 1.0, a dataset of 3D object models and a sampling-based planning algorithm to explore how Cloud Robotics can be used for robust grasp planning. The algorithm uses a Multi- Armed Bandit model with correlated rewards to leverage prior grasps and 3D object models in a growing dataset that currently includes over 10,000 unique 3D object models and 2.5 million parallel-jaw grasps. Each grasp includes an estimate of the probability of force closure under uncertainty in object and gripper pose and friction. Dex-Net 1.0 uses Multi-View Convolutional Neural Networks (MV-CNNs), a new deep learning method for 3D object classification, to provide a similarity metric between objects, and the Google Cloud Platform to simultaneously run up to 1,500 virtual cores, reducing experiment runtime by up to three orders of magnitude. Experiments suggest that correlated bandit techniques can use a cloud-based network of object models to significantly reduce the number of samples required for robust grasp planning. We report on system sensitivity to variations in similarity metrics and in uncertainty in pose and friction. Code and updated information is available at http://berkeleyautomation.github.io/dex-net/.},
	booktitle = {2016 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Mahler, J. and Pokorny, F. T. and Hou, B. and Roderick, M. and Laskey, M. and Aubry, M. and Kohlhoff, K. and Kröger, T. and Kuffner, J. and Goldberg, K.},
	month = may,
	year = {2016},
	keywords = {3D object models, Dex-Net 1.0, Force, Friction, MV-CNN, Measurement, Planning, Robustness, Solid modeling, Three-dimensional displays, cloud computing, cloud robotics, cloud-based network, control engineering computing, convolution, correlated rewards, data analysis, dataset, deep learning method, dexterity network 1.0, force closure, image classification, learning systems, multi-armed bandit model, multiview convolutional neural networks, neural nets, object classification, parallel-jaw grasps, path planning, robot vision, robust grasp planning, similarity metrics},
	pages = {1957--1964}
}

@inproceedings{koo_focused_2016,
	title = {Focused online visual-motor coordination for a dual-arm robot manipulator},
	doi = {10.1109/ICRA.2016.7487297},
	abstract = {Coordination between visual sensors and robot manipulators is necessary for successful manipulation. This paper proposes a novel visual-motor coordination method that performs online parameter estimation of an RGB-D camera mounted in a robot head without any external markers. Through self-observation of a dual-arm robot manipulator, the method updates parameters to reduce the discrepancy between observed point cloud data and 3D mesh models of the current robot configuration. With the estimated parameters at each time step, visual data is adjusted to the focused workspace of the 14DOF dual-arm robot manipulator. The online and realtime algorithm was developed by using a GPU-based particle filtering method. Experimental results show that our method outperforms state-of-the-art offline registration methods in terms of accuracy and computation time. We also analyzed the dependence of the results on prior parameters to demonstrate the online capability of our method.},
	booktitle = {2016 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Koo, Seongyong and Behnke, S.},
	month = may,
	year = {2016},
	keywords = {3D mesh models, Calibration, Cameras, DOF dual-arm robot manipulator, GPU-based particle filtering method, RGB-D camera, Robot kinematics, Solid modeling, Three-dimensional displays, Visualization, computation time, computational complexity, focused online visual-motor coordination, graphics processing units, manipulators, online parameter estimation, parameter estimation, particle filtering (numerical methods), point cloud data, real-time algorithm, robot head, self-observation, sensors, visual sensors},
	pages = {1579--1586}
}

@inproceedings{polverini_sensorless_2016,
	title = {Sensorless and constraint based peg-in-hole task execution with a dual-arm robot},
	doi = {10.1109/ICRA.2016.7487161},
	abstract = {Fast and sensorless peg-in-hole insertion is a challenging task for a robotic manipulator. In order to deal with the peg-in-hole insertion problem without any need of an external force/torque sensor, this paper proposes to actively accomplish compliance in the insertion task relying on an admittance based control. This is combined with a real-time trajectory generator, by means of constraint based optimization, where a model-based sensorless observer of interaction forces is exploited. Experiments have been performed on an ABB dual-arm 7-DOF lightweight prototype robot to validate the proposed approach, with an insertion speed comparable to human manual execution and in presence of geometric uncertainty.},
	booktitle = {2016 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Polverini, M. P. and Zanchettin, A. M. and Castello, S. and Rocco, P.},
	month = may,
	year = {2016},
	keywords = {ABB dual-arm 7-DOF lightweight prototype robot, Admittance, Generators, Kinematics, Optimization, Robot sensing systems, Trajectory, admittance based control, constraint based optimization, contraint based peg-in-hole insertion, dual-arm robot, geometric uncertainty, grippers, interaction force, manipulators, model-based sensorless observer, observers, optimisation, real-time trajectory generator, robotic assembly, robotic manipulator, sensorless peg-in-hole insertion, trajectory control},
	pages = {415--420}
}

@article{li_design_2016,
	title = {Design of a {Multi}-{Arm} {Surgical} {Robotic} {System} for {Dexterous} {Manipulation}},
	volume = {8},
	issn = {1942-4302},
	url = {http://mechanismsrobotics.asmedigitalcollection.asme.org/article.aspx?articleid=2534618},
	doi = {10.1115/1.4034143},
	number = {6},
	urldate = {2018-01-25TZ},
	journal = {Journal of Mechanisms and Robotics},
	author = {Li, Zhi and Milutinović, Dejan and Rosen, Jacob},
	month = dec,
	year = {2016},
	pages = {061017}
}

@article{li_reaching_2017,
	title = {From reaching to reach-to-grasp: the arm posture difference and its implications on human motion control strategy},
	volume = {235},
	issn = {0014-4819, 1432-1106},
	shorttitle = {From reaching to reach-to-grasp},
	url = {https://link.springer.com/article/10.1007/s00221-017-4890-y},
	doi = {10.1007/s00221-017-4890-y},
	abstract = {Reach-to-grasp arm postures differ from those in pure reaching because they are affected by grasp position/orientation, rather than simple transport to a position during a reaching motion. This paper investigates this difference via an analysis of experimental data collected on reaching and reach-to-grasp motions. A seven-degree-of-freedom (DOFs) kinematic arm model with the swivel angle is used for the motion analysis. Compared to a widely used anatomical arm model, this model distinguishes clearly the four grasping-relevant DOFs (GR-DOFs) that are affected by positions and orientations of the objects to be grasped. These four GR-DOFs include the swivel angle that measures the elbow rotation about the shoulder–wrist axis, and three wrist joint angles. For each GR-DOF, we quantify position vs orientation task-relevance bias that measures how much the DOF is affected by the grasping position vs orientation. The swivel angle and forearm supination have similar bias, and the analysis of their motion suggests two hypotheses regarding the synergistic coordination of the macro- and micro-structures of the human arm (1) DOFs with similar task-relevance are synergistically coordinated; and (2) such synergy breaks when a task-relevant DOF is close to its joint limit without necessarily reaching the limit. This study provides a motion analysis method to reduce the control complexity for reach-to-grasp tasks, and suggests using dynamic coupling to coordinate the hand and arm of upper-limb exoskeletons.},
	language = {en},
	number = {5},
	urldate = {2018-01-25TZ},
	journal = {Experimental Brain Research},
	author = {Li, Zhi and Milutinović, Dejan and Rosen, Jacob},
	month = may,
	year = {2017},
	pages = {1627--1642}
}

@inproceedings{berenson_grasp_2007,
	title = {Grasp planning in complex scenes},
	doi = {10.1109/ICHR.2007.4813847},
	abstract = {This paper combines grasp analysis and manipulation planning techniques to perform fast grasp planning in complex scenes. In much previous work on grasping, the object being grasped is assumed to be the only object in the environment. Hence the grasp quality metrics and grasping strategies developed do not perform well when the object is close to obstacles and many good grasps are infeasible. We introduce a framework for finding valid grasps in cluttered environments that combines a grasp quality metric for the object with information about the local environment around the object and information about the robot's kinematics. We encode these factors in a grasp-scoring function which we use to rank a precomputed set of grasps in terms of their appropriateness for a given scene. We show that this ranking is essential for efficient grasp selection and present experiments in simulation and on the HRP2 robot.},
	booktitle = {2007 7th {IEEE}-{RAS} {International} {Conference} on {Humanoid} {Robots}},
	author = {Berenson, D. and Diankov, R. and Nishiwaki, Koichi and Kagami, Satoshi and Kuffner, J.},
	month = nov,
	year = {2007},
	keywords = {Grasping, HRP2 robot, Humanoid robots, Humans, Layout, Manipulators, Performance analysis, Robot kinematics, Robot sensing systems, Service robots, Technology planning, grasp analysis, grasp planning, grasp quality metrics, grasping strategies, humanoid robotics, humanoid robots, manipulation planning, manipulator kinematics, path planning, robot kinematics},
	pages = {42--48}
}

@phdthesis{lee_proximity_1978,
	address = {United States -- Illinois},
	type = {Ph.{D}.},
	title = {Proximity and {Reachability} in the {Plane}.},
	copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
	url = {https://search.proquest.com/docview/302879719/citation/2B1731A9C8E54652PQ/1},
	language = {English},
	urldate = {2018-01-23TZ},
	school = {University of Illinois at Urbana-Champaign},
	author = {LEE, DER-TSAI},
	year = {1978},
	keywords = {Applied sciences}
}

@phdthesis{lee_proximity_1978-1,
	address = {Champaign, IL, USA},
	type = {{PhD} {Thesis}},
	title = {Proximity and {Reachability} in the {Plane}.},
	school = {University of Illinois at Urbana-Champaign},
	author = {Lee, Der-Tsai},
	year = {1978}
}

@article{fedorov_image_2012,
	title = {Image {Registration} for {Targeted} {MRI}-guided {Transperineal} {Prostate} {Biopsy}},
	volume = {36},
	issn = {1053-1807},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3434292/},
	doi = {10.1002/jmri.23688},
	abstract = {Purpose
To develop and evaluate image registration methodology for automated re-identification of tumor-suspicious foci from pre-procedural MR exams during MR-guided transperineal prostate core biopsy.

Materials and Methods
A hierarchical approach for automated registration between planning and intra-procedural T2-weighted prostate MRI was developed and evaluated on the images acquired during 10 consecutive MR-guided biopsies. Registration accuracy was quantified at image-based landmarks and by evaluating spatial overlap for the manually segmented prostate and sub-structures. Registration reliability was evaluated by simulating initial mis-registration and analyzing the convergence behavior. Registration precision was characterized at the planned biopsy targets.

Results
The total computation time was compatible with a clinical setting, being at most 2 minutes. Deformable registration led to a significant improvement in spatial overlap of the prostate and peripheral zone contours compared to both rigid and affine registration. Average in-slice landmark registration error was 1.3±0.5 mm. Experiments simulating initial mis-registration resulted in an estimated average capture range of 6 mm and an average in-slice registration precision of ±0.3 mm.

Conclusion
Our registration approach requires minimum user interaction and is compatible with the time constraints of our interventional clinical workflow. The initial evaluation shows acceptable accuracy, reliability and consistency of the method.},
	number = {4},
	urldate = {2018-01-23TZ},
	journal = {Journal of magnetic resonance imaging : JMRI},
	author = {Fedorov, Andriy and Tuncali, Kemal and Fennessy, Fiona M. and Tokuda, Junichi and Hata, Nobuhiko and Wells, William M. and Kikinis, Ron and Tempany, Clare M.},
	month = oct,
	year = {2012},
	pmid = {22645031},
	pmcid = {PMC3434292},
	pages = {987--992}
}

@article{tokuda_-bore_2012,
	title = {In-bore setup and {Software} for 3T {MRI}-guided {Transperineal} {Prostate} {Biopsy}},
	volume = {57},
	issn = {0031-9155},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3517895/},
	doi = {10.1088/0031-9155/57/18/5823},
	abstract = {MRI-guided prostate biopsy in conventional closed-bore scanners requires transferring the patient outside the bore during needle insertion due to the constrained in-bore space, causing a safety hazard and limiting image feedback. To address this issue, we present our custom-made in-bore setup and software to support MRI-guided transperineal prostate biopsy in a wide-bore 3 Tesla (T) MRI scanner. The setup consists of a specially designed tabletop and a needle-guiding template with Z-frame that give a physician access to the perineum of the patient at the imaging position and allow performance of MRI-guided transperineal biopsy without moving the patient out of the scanner. The software and Z-frame allow registration of the template, target planning, and biopsy guidance. Initially, we performed phantom experiments to assess the accuracy of template registration and needle placement in a controlled environment. Subsequently, we embarked on our clinical trial (N = 10). The phantom experiments showed that the translational errors of the template registration along the right-left (RP) and anterior-posterior (AP) axes were 1.1 ± 0.8 mm and 1.4 ± 1.1 mm respectively, while the rotational errors around the RL, AP, and superior-inferior axes were 0.8 ± 1.0 degrees, 1.7 ± 1.6 degrees, and 0.0 ± 0.0 degrees respectively. The 2D root-mean-square (RMS) needle placement error was 3.0 mm. The clinical biopsy procedures were safely carried out in all ten clinical cases with a needle placement error of 5.4 mm (2D RMS). In conclusion, transperineal prostate biopsy in a wide-bore 3T scanner is feasible using our custom-made tabletop set up and software, which supports manual needle placement without moving the patient out of the magnet.},
	number = {18},
	urldate = {2018-01-23TZ},
	journal = {Physics in medicine and biology},
	author = {Tokuda, Junichi and Tuncali, Kemal and Iordachita, Iulian and Song, Sang-Eun and Fedorov, Andriy and Oguro, Sota and Lasso, Andras and Fennessy, Fiona M and Tempany, Clare M and Hata, Nobuhiko},
	month = sep,
	year = {2012},
	pmid = {22951350},
	pmcid = {PMC3517895},
	pages = {5823--5840}
}

@article{zijlstra_challenges_2017,
	title = {Challenges in {MR}-only seed localization for postimplant dosimetry in permanent prostate brachytherapy},
	volume = {44},
	issn = {2473-4209},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/mp.12505/abstract},
	doi = {10.1002/mp.12505},
	abstract = {Purpose

An MR-only postimplant dosimetry workflow for low dose rate (LDR) brachytherapy could reduce patient burden, improve accuracy, and improve cost efficiency. However, localization of brachytherapy seeds on MRI scans remains a major challenge for this type of workflow. In this study, we propose and validate an MR-only seed localization method and identify remaining challenges.


Methods and materials

The localization method was based on template matching of simulations of complex-valued imaging artifacts around metal brachytherapy seeds. The method was applied to MRI scans of 25 prostate cancer patients who underwent LDR brachytherapy and for whom postimplant dosimetry was performed after 4 weeks. The seed locations found with the MR-only method were validated against the seed locations found on CT. The circumstances in which detection errors were made were classified to gain an insight in the nature of the errors.


Results

A total of 1490 of 1557 (96\%) seeds were correctly detected, while 67 false-positive errors were made. The correctly detected seed locations had a high spatial accuracy with an average error of 0.8 mm compared with CT. A majority of the false positives occurred near other seeds. Most false negatives were found in either stranded configurations without spacers or near other seeds.


Conclusions

The low detection error rate and high localization accuracy obtained by the complex-valued template matching approach are promising for future clinical application of MR-only dosimetry. The most important remaining challenge is robustness with regard to configurations of multiple seeds in close vicinity, such as in strands of seeds without spacers. This issue could potentially be resolved by simulating specific configurations of multiple seeds or by constraining the treatment planning to avoid these configurations, which could make the proposed method competitive with CT-based seed localization.},
	language = {en},
	number = {10},
	urldate = {2018-01-23TZ},
	journal = {Medical Physics},
	author = {Zijlstra, Frank and Moerland, Marinus A. and van der Voort van Zyp, Jochem R.N. and Noteboom, Juus L. and Viergever, Max A. and Seevinck, Peter R.},
	month = oct,
	year = {2017},
	keywords = {MRI, brachytherapy, seed localization, simulation, susceptibility, template matching},
	pages = {5051--5060}
}

@article{zijlstra_challenges_2017-1,
	title = {Challenges in {MR}-only seed localization for postimplant dosimetry in permanent prostate brachytherapy},
	volume = {44},
	issn = {2473-4209},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/mp.12505/abstract},
	doi = {10.1002/mp.12505},
	abstract = {Purpose

An MR-only postimplant dosimetry workflow for low dose rate (LDR) brachytherapy could reduce patient burden, improve accuracy, and improve cost efficiency. However, localization of brachytherapy seeds on MRI scans remains a major challenge for this type of workflow. In this study, we propose and validate an MR-only seed localization method and identify remaining challenges.


Methods and materials

The localization method was based on template matching of simulations of complex-valued imaging artifacts around metal brachytherapy seeds. The method was applied to MRI scans of 25 prostate cancer patients who underwent LDR brachytherapy and for whom postimplant dosimetry was performed after 4 weeks. The seed locations found with the MR-only method were validated against the seed locations found on CT. The circumstances in which detection errors were made were classified to gain an insight in the nature of the errors.


Results

A total of 1490 of 1557 (96\%) seeds were correctly detected, while 67 false-positive errors were made. The correctly detected seed locations had a high spatial accuracy with an average error of 0.8 mm compared with CT. A majority of the false positives occurred near other seeds. Most false negatives were found in either stranded configurations without spacers or near other seeds.


Conclusions

The low detection error rate and high localization accuracy obtained by the complex-valued template matching approach are promising for future clinical application of MR-only dosimetry. The most important remaining challenge is robustness with regard to configurations of multiple seeds in close vicinity, such as in strands of seeds without spacers. This issue could potentially be resolved by simulating specific configurations of multiple seeds or by constraining the treatment planning to avoid these configurations, which could make the proposed method competitive with CT-based seed localization.},
	language = {en},
	number = {10},
	urldate = {2018-01-23TZ},
	journal = {Medical Physics},
	author = {Zijlstra, Frank and Moerland, Marinus A. and van der Voort van Zyp, Jochem R.N. and Noteboom, Juus L. and Viergever, Max A. and Seevinck, Peter R.},
	month = oct,
	year = {2017},
	keywords = {MRI, brachytherapy, seed localization, simulation, susceptibility, template matching},
	pages = {5051--5060}
}

@article{dai_bundlefusion:_2017,
	title = {{BundleFusion}: {Real}-{Time} {Globally} {Consistent} 3D {Reconstruction} {Using} {On}-the-{Fly} {Surface} {Reintegration}},
	volume = {36},
	issn = {0730-0301},
	shorttitle = {{BundleFusion}},
	url = {http://doi.acm.org/10.1145/3054739},
	doi = {10.1145/3054739},
	abstract = {Real-time, high-quality, 3D scanning of large-scale scenes is key to mixed reality and robotic applications. However, scalability brings challenges of drift in pose estimation, introducing significant errors in the accumulated model. Approaches often require hours of offline processing to globally correct model errors. Recent online methods demonstrate compelling results but suffer from (1) needing minutes to perform online correction, preventing true real-time use; (2) brittle frame-to-frame (or frame-to-model) pose estimation, resulting in many tracking failures; or (3) supporting only unstructured point-based representations, which limit scan quality and applicability. We systematically address these issues with a novel, real-time, end-to-end reconstruction framework. At its core is a robust pose estimation strategy, optimizing per frame for a global set of camera poses by considering the complete history of RGB-D input with an efficient hierarchical approach. We remove the heavy reliance on temporal tracking and continually localize to the globally optimized frames instead. We contribute a parallelizable optimization framework, which employs correspondences based on sparse features and dense geometric and photometric matching. Our approach estimates globally optimized (i.e., bundle adjusted) poses in real time, supports robust tracking with recovery from gross tracking failures (i.e., relocalization), and re-estimates the 3D model in real time to ensure global consistency, all within a single framework. Our approach outperforms state-of-the-art online systems with quality on par to offline methods, but with unprecedented speed and scan completeness. Our framework leads to a comprehensive online scanning solution for large indoor environments, enabling ease of use and high-quality results.1},
	number = {3},
	urldate = {2018-01-18TZ},
	journal = {ACM Trans. Graph.},
	author = {Dai, Angela and Nießner, Matthias and Zollhöfer, Michael and Izadi, Shahram and Theobalt, Christian},
	month = may,
	year = {2017},
	keywords = {RGB-D, global consistency, real-time, scalable, scan},
	pages = {24:1--24:18}
}

@incollection{huang_visual_2017,
	series = {Springer {Tracts} in {Advanced} {Robotics}},
	title = {Visual {Odometry} and {Mapping} for {Autonomous} {Flight} {Using} an {RGB}-{D} {Camera}},
	isbn = {978-3-319-29362-2 978-3-319-29363-9},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-29363-9_14},
	abstract = {RGB-D cameras provide both a color image and per-pixel depth estimates. The richness of their data and the recent development of low-cost sensors have combined to present an attractive opportunity for mobile robotics research. In this paper, we describe a system for visual odometry and mapping using an RGB-D camera, and its application to autonomous flight. By leveraging results from recent state-of-the-art algorithms and hardware, our system enables 3D flight in cluttered environments using only onboard sensor data. All computation and sensing required for local position control are performed onboard the vehicle, reducing the dependence on unreliable wireless links. We evaluate the effectiveness of our system for stabilizing and controlling a quadrotor micro air vehicle, demonstrate its use for constructing detailed 3D maps of an indoor environment, and discuss its limitations.},
	language = {en},
	urldate = {2018-01-18TZ},
	booktitle = {Robotics {Research}},
	publisher = {Springer, Cham},
	author = {Huang, Albert S. and Bachrach, Abraham and Henry, Peter and Krainin, Michael and Maturana, Daniel and Fox, Dieter and Roy, Nicholas},
	year = {2017},
	doi = {10.1007/978-3-319-29363-9_14},
	pages = {235--252}
}

@inproceedings{geiger_stereoscan:_2011,
	title = {{StereoScan}: {Dense} 3d reconstruction in real-time},
	shorttitle = {{StereoScan}},
	doi = {10.1109/IVS.2011.5940405},
	abstract = {Accurate 3d perception from video sequences is a core subject in computer vision and robotics, since it forms the basis of subsequent scene analysis. In practice however, online requirements often severely limit the utilizable camera resolution and hence also reconstruction accuracy. Furthermore, real-time systems often rely on heavy parallelism which can prevent applications in mobile devices or driver assistance systems, especially in cases where FPGAs cannot be employed. This paper proposes a novel approach to build 3d maps from high-resolution stereo sequences in real-time. Inspired by recent progress in stereo matching, we propose a sparse feature matcher in conjunction with an efficient and robust visual odometry algorithm. Our reconstruction pipeline combines both techniques with efficient stereo matching and a multi-view linking scheme for generating consistent 3d point clouds. In our experiments we show that the proposed odometry method achieves state-of-the-art accuracy. Including feature matching, the visual odometry part of our algorithm runs at 25 frames per second, while - at the same time - we obtain new depth maps at 3-4 fps, sufficient for online 3d reconstructions.},
	booktitle = {2011 {IEEE} {Intelligent} {Vehicles} {Symposium} ({IV})},
	author = {Geiger, A. and Ziegler, J. and Stiller, C.},
	month = jun,
	year = {2011},
	keywords = {3D maps, 3D point clouds, Cameras, Estimation, Image reconstruction, Real time systems, Stereo image processing, StereoScan, Three dimensional displays, Visualization, camera resolution, computer vision, dense 3D reconstruction, distance measurement, feature matcher, high resolution stereo sequences, image matching, image reconstruction, image sequences, multiview linking scheme, robot vision, robotics, robust visual odometry algorithm, scene analysis, stereo image processing, stereo matching, video sequences},
	pages = {963--968}
}

@inproceedings{heise_variational_2015,
	title = {Variational {PatchMatch} {MultiView} {Reconstruction} and {Refinement}},
	doi = {10.1109/ICCV.2015.107},
	abstract = {In this work we propose a novel approach to the problem of multi-view stereo reconstruction. Building upon the previously proposed PatchMatch stereo and PM-Huber algorithm we introduce an extension to the multi-view scenario that employs an iterative refinement scheme. Our proposed approach uses an extended and robustified volumetric truncated signed distance function representation, which is advantageous for the fusion of refined depth maps and also for raycasting the current reconstruction estimation together with estimated depth normals into arbitrary camera views. We formulate the combined multi-view stereo reconstruction and refinement as a variational optimization problem. The newly introduced plane based smoothing term in the energy formulation is guided by the current reconstruction confidence and the image contents. Further we propose an extension of the PatchMatch scheme with an additional KLT step to avoid unnecessary sampling iterations. Improper camera poses are corrected by a direct image aligment step that performs robust outlier compensation by means of a recently proposed kernel lifting framework. To speed up the optimization of the variational formulation an adapted scheme is used for faster convergence.},
	booktitle = {2015 {IEEE} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	author = {Heise, P. and Jensen, B. and Klose, S. and Knoll, A.},
	month = dec,
	year = {2015},
	keywords = {Cameras, Estimation, Image reconstruction, KLT step, Kernel, Optimization, PatchMatch stereo, Robustness, Visualization, convergence, depth map fusion, direct image alignment, energy formulation, image fusion, image reconstruction, iterative methods, iterative refinement scheme, kernel lifting framework, multiview stereo reconstruction, multiview stereo refinement, optimisation, outlier compensation, plane based smoothing term, ray tracing, raycasting, smoothing methods, stereo image processing, variational optimization problem, variational techniques, volumetric truncated signed distance function representation},
	pages = {882--890}
}

@article{mehrtash_deepinfer:_2017,
	title = {{DeepInfer}: {Open}-{Source} {Deep} {Learning} {Deployment} {Toolkit} for {Image}-{Guided} {Therapy}},
	volume = {10135},
	issn = {0277-786X},
	shorttitle = {{DeepInfer}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5467894/},
	doi = {10.1117/12.2256011},
	abstract = {Deep learning models have outperformed some of the previous state-of-the-art approaches in medical image analysis. Instead of using hand-engineered features, deep models attempt to automatically extract hierarchical representations at multiple levels of abstraction from the data. Therefore, deep models are usually considered to be more flexible and robust solutions for image analysis problems compared to conventional computer vision models. They have demonstrated significant improvements in computer-aided diagnosis and automatic medical image analysis applied to such tasks as image segmentation, classification and registration. However, deploying deep learning models often has a steep learning curve and requires detailed knowledge of various software packages. Thus, many deep models have not been integrated into the clinical research workflows causing a gap between the state-of-the-art machine learning in medical applications and evaluation in clinical research procedures. In this paper, we propose “DeepInfer” – an open-source toolkit for developing and deploying deep learning models within the 3D Slicer medical image analysis platform. Utilizing a repository of task-specific models, DeepInfer allows clinical researchers and biomedical engineers to deploy a trained model selected from the public registry, and apply it to new data without the need for software development or configuration. As two practical use cases, we demonstrate the application of DeepInfer in prostate segmentation for targeted MRI-guided biopsy and identification of the target plane in 3D ultrasound for spinal injections.},
	urldate = {2018-01-16TZ},
	journal = {Proceedings of SPIE--the International Society for Optical Engineering},
	author = {Mehrtash, Alireza and Pesteie, Mehran and Hetherington, Jorden and Behringer, Peter A. and Kapur, Tina and Wells, William M. and Rohling, Robert and Fedorov, Andriy and Abolmaesumi, Purang},
	month = feb,
	year = {2017},
	pmid = {28615794},
	pmcid = {PMC5467894}
}

@article{mehrtash_deepinfer:_2017-1,
	title = {{DeepInfer}: {Open}-{Source} {Deep} {Learning} {Deployment} {Toolkit} for {Image}-{Guided} {Therapy}},
	volume = {10135},
	issn = {0277-786X},
	shorttitle = {{DeepInfer}},
	doi = {10.1117/12.2256011},
	abstract = {Deep learning models have outperformed some of the previous state-of-the-art approaches in medical image analysis. Instead of using hand-engineered features, deep models attempt to automatically extract hierarchical representations at multiple levels of abstraction from the data. Therefore, deep models are usually considered to be more flexible and robust solutions for image analysis problems compared to conventional computer vision models. They have demonstrated significant improvements in computer-aided diagnosis and automatic medical image analysis applied to such tasks as image segmentation, classification and registration. However, deploying deep learning models often has a steep learning curve and requires detailed knowledge of various software packages. Thus, many deep models have not been integrated into the clinical research workflows causing a gap between the state-of-the-art machine learning in medical applications and evaluation in clinical research procedures. In this paper, we propose "DeepInfer" - an open-source toolkit for developing and deploying deep learning models within the 3D Slicer medical image analysis platform. Utilizing a repository of task-specific models, DeepInfer allows clinical researchers and biomedical engineers to deploy a trained model selected from the public registry, and apply it to new data without the need for software development or configuration. As two practical use cases, we demonstrate the application of DeepInfer in prostate segmentation for targeted MRI-guided biopsy and identification of the target plane in 3D ultrasound for spinal injections.},
	language = {eng},
	journal = {Proceedings of SPIE--the International Society for Optical Engineering},
	author = {Mehrtash, Alireza and Pesteie, Mehran and Hetherington, Jorden and Behringer, Peter A. and Kapur, Tina and Wells, William M. and Rohling, Robert and Fedorov, Andriy and Abolmaesumi, Purang},
	month = feb,
	year = {2017},
	pmid = {28615794},
	pmcid = {PMC5467894}
}

@article{ghafoorian_transfer_2017,
	title = {Transfer {Learning} for {Domain} {Adaptation} in {MRI}: {Application} in {Brain} {Lesion} {Segmentation}},
	shorttitle = {Transfer {Learning} for {Domain} {Adaptation} in {MRI}},
	url = {http://arxiv.org/abs/1702.07841},
	abstract = {Magnetic Resonance Imaging (MRI) is widely used in routine clinical diagnosis and treatment. However, variations in MRI acquisition protocols result in different appearances of normal and diseased tissue in the images. Convolutional neural networks (CNNs), which have shown to be successful in many medical image analysis tasks, are typically sensitive to the variations in imaging protocols. Therefore, in many cases, networks trained on data acquired with one MRI protocol, do not perform satisfactorily on data acquired with different protocols. This limits the use of models trained with large annotated legacy datasets on a new dataset with a different domain which is often a recurring situation in clinical settings. In this study, we aim to answer the following central questions regarding domain adaptation in medical image analysis: Given a fitted legacy model, 1) How much data from the new domain is required for a decent adaptation of the original network?; and, 2) What portion of the pre-trained model parameters should be retrained given a certain number of the new domain training samples? To address these questions, we conducted extensive experiments in white matter hyperintensity segmentation task. We trained a CNN on legacy MR images of brain and evaluated the performance of the domain-adapted network on the same task with images from a different domain. We then compared the performance of the model to the surrogate scenarios where either the same trained network is used or a new network is trained from scratch on the new dataset.The domain-adapted network tuned only by two training examples achieved a Dice score of 0.63 substantially outperforming a similar network trained on the same set of examples from scratch.},
	urldate = {2018-01-16TZ},
	journal = {arXiv:1702.07841 [cs]},
	author = {Ghafoorian, Mohsen and Mehrtash, Alireza and Kapur, Tina and Karssemeijer, Nico and Marchiori, Elena and Pesteie, Mehran and Guttmann, Charles R. G. and de Leeuw, Frank-Erik and Tempany, Clare M. and van Ginneken, Bram and Fedorov, Andriy and Abolmaesumi, Purang and Platel, Bram and Wells III, William M.},
	month = feb,
	year = {2017},
	note = {arXiv: 1702.07841},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{goksel_modeling_2009,
	title = {Modeling and simulation of flexible needles},
	volume = {31},
	issn = {1873-4030},
	doi = {10.1016/j.medengphy.2009.07.007},
	abstract = {Needle insertion is performed in many clinical and therapeutic procedures. Tissue displacement and needle bending which result from needle-tissue interaction make accurate targeting difficult. For performing physicians to gain essential needle targeting skills, needle insertion simulators can be used for training. An accurate needle bending model is essential for such simulators. These bending models are also needed for needle path planning. In this paper, three different models are presented to simulate the deformations of a needle. The first two models use the finite element method and take the geometric nonlinearity into account. The third model is a series of rigid bars connected by angular springs. The models were compared to recorded deformations during experiments of applying lateral tip forces on a brachytherapy needle. The model parameters were identified and the simulation results were compared to the experimental data. The results show that the angular spring model, which is computationally the most efficient model, is also the most accurate in modeling the bending of the brachytherapy needle.},
	language = {eng},
	number = {9},
	journal = {Medical Engineering \& Physics},
	author = {Goksel, Orcun and Dehghan, Ehsan and Salcudean, Septimiu E.},
	month = nov,
	year = {2009},
	pmid = {19674926},
	keywords = {Algorithms, Brachytherapy, Computer Simulation, Equipment Design, Finite Element Analysis, Models, Statistical, Models, Theoretical, Needles, Pattern Recognition, Automated, Robotics, Stress, Mechanical},
	pages = {1069--1078}
}

@article{goksel_modeling_2009-1,
	title = {Modeling and simulation of flexible needles},
	volume = {31},
	issn = {1350-4533},
	url = {http://www.sciencedirect.com/science/article/pii/S1350453309001477},
	doi = {10.1016/j.medengphy.2009.07.007},
	abstract = {Needle insertion is performed in many clinical and therapeutic procedures. Tissue displacement and needle bending which result from needle–tissue interaction make accurate targeting difficult. For performing physicians to gain essential needle targeting skills, needle insertion simulators can be used for training. An accurate needle bending model is essential for such simulators. These bending models are also needed for needle path planning. In this paper, three different models are presented to simulate the deformations of a needle. The first two models use the finite element method and take the geometric nonlinearity into account. The third model is a series of rigid bars connected by angular springs. The models were compared to recorded deformations during experiments of applying lateral tip forces on a brachytherapy needle. The model parameters were identified and the simulation results were compared to the experimental data. The results show that the angular spring model, which is computationally the most efficient model, is also the most accurate in modeling the bending of the brachytherapy needle.},
	number = {9},
	urldate = {2018-01-08TZ},
	journal = {Medical Engineering \& Physics},
	author = {Goksel, Orcun and Dehghan, Ehsan and Salcudean, Septimiu E.},
	month = nov,
	year = {2009},
	keywords = {Angular springs, Brachytherapy simulation, Flexible needles, Modeling bending, Twisting/torsion},
	pages = {1069--1078}
}

@article{mastmeyer_accurate_2017,
	title = {Accurate {Model}-based {Segmentation} of {Gynecologic} {Brachytherapy} {Catheter} {Collections} in {MRI}-images},
	volume = {42},
	issn = {1361-8415},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5654713/},
	doi = {10.1016/j.media.2017.06.011},
	abstract = {The gynecological cancer mortality rate, including cervical, ovarian, vaginal and vulvar cancers, is more than 20,000 annually in the US alone. In many countries, including the US, external-beam radiotherapy followed by high dose rate brachytherapy is the standard-of-care. The superior ability of MR to visualize soft tissue has led to an increase in its usage in planning and delivering brachytherapy treatment. A technical challenge associated with the use of MRI imaging for brachytherapy, in contrast to that of CT imaging, is the visualization of catheters that are used to place radiation sources into cancerous tissue. We describe here a precise, accurate method for achieving catheter segmentation and visualization. The algorithm, with the assistance of manually provided tip locations, performs segmentation using image-features, and is guided by a catheter-specific, estimated mechanical model. A final quality control step removes outliers or conflicting catheter trajectories. The mean Hausdorff error on a 54 patient, 760 catheter reference database was 1.49 mm; 51 of the outliers deviated more than two catheter widths (3.4 mm) from the gold standard, corresponding to catheter identification accuracy of 93\% in a Syed-Neblett template. In a multi-user simulation experiment for evaluating RMS precision by simulating varying manually-provided superior tip positions, 3σ maximum errors were 2.44 mm. The average segmentation time for a single catheter was 3 seconds on a standard PC. The segmentation time, accuracy and precision, are promising indicators of the value of this method for clinical translation of MR-guidance in gynecologic brachytherapy and other catheter-based interventional procedures.},
	urldate = {2018-01-01TZ},
	journal = {Medical image analysis},
	author = {Mastmeyer, Andre and Pernelle, Guillaume and Ma, Rubin and Barber, Lauren and Kapur, Tina},
	month = dec,
	year = {2017},
	pmid = {28803217},
	pmcid = {PMC5654713},
	keywords = {NA-MIC},
	pages = {173--188}
}

@inproceedings{pernelle_validation_2013,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Validation of {Catheter} {Segmentation} for {MR}-{Guided} {Gynecologic} {Cancer} {Brachytherapy}},
	isbn = {978-3-642-40759-8 978-3-642-40760-4},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-40760-4_48},
	doi = {10.1007/978-3-642-40760-4_48},
	abstract = {Segmentation of interstitial catheters from MRI needs to be addressed in order for MRI-based brachytherapy treatment planning to become part of the clinical practice of gynecologic cancer radiotherapy. This paper presents a validation study of a novel image-processing method for catheter segmentation. The method extends the distal catheter tip, interactively provided by the physician, to its proximal end, using knowledge of catheter geometry and appearance in MRI sequences. The validation study consisted of comparison of the algorithm results to expert manual segmentations, first on images of a phantom, and then on patient MRI images obtained during MRI-guided insertion of brachytherapy catheters for the treatment of gynecologic cancer. In the phantom experiment, the maximum disagreement between automatic and manual segmentation of the same MRI image, as computed using the Hausdorf distance, was 1.5 mm, which is of the same order as the MR image spatial resolution, while the disagreement between automatic segmentation of MR images and “ground truth”, manual segmentation of CT images, was 3.5mm. The segmentation method was applied to an IRB-approved retrospective database of 10 interstitial brachytherapy patients which included a total of 101 catheters. Compared with manual expert segmentations, the automatic method correctly segmented 93 out of 101 catheters, at an average rate of 0.3 seconds per catheter using a 3GHz Intel Core i7 computer with 16 GB RAM and running Mac OS X 10.7. These results suggest that the proposed catheter segmentation is both technically and clinically feasible.},
	language = {en},
	urldate = {2018-01-08TZ},
	booktitle = {Medical {Image} {Computing} and {Computer}-{Assisted} {Intervention} – {MICCAI} 2013},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Pernelle, Guillaume and Mehrtash, Alireza and Barber, Lauren and Damato, Antonio and Wang, Wei and Seethamraju, Ravi Teja and Schmidt, Ehud and Cormack, Robert A. and Wells, Williams and Viswanathan, Akila and Kapur, Tina},
	month = sep,
	year = {2013},
	keywords = {NA-MIC},
	pages = {380--387}
}

@article{mastmeyer_accurate_2017-1,
	title = {Accurate model-based segmentation of gynecologic brachytherapy catheter collections in {MRI}-images},
	volume = {42},
	issn = {1361-8423},
	doi = {10.1016/j.media.2017.06.011},
	abstract = {The gynecological cancer mortality rate, including cervical, ovarian, vaginal and vulvar cancers, is more than 20,000 annually in the US alone. In many countries, including the US, external-beam radiotherapy followed by high dose rate brachytherapy is the standard-of-care. The superior ability of MR to visualize soft tissue has led to an increase in its usage in planning and delivering brachytherapy treatment. A technical challenge associated with the use of MRI imaging for brachytherapy, in contrast to that of CT imaging, is the visualization of catheters that are used to place radiation sources into cancerous tissue. We describe here a precise, accurate method for achieving catheter segmentation and visualization. The algorithm, with the assistance of manually provided tip locations, performs segmentation using image-features, and is guided by a catheter-specific, estimated mechanical model. A final quality control step removes outliers or conflicting catheter trajectories. The mean Hausdorff error on a 54 patient, 760 catheter reference database was 1.49  mm; 51 of the outliers deviated more than two catheter widths (3.4  mm) from the gold standard, corresponding to catheter identification accuracy of 93\% in a Syed-Neblett template. In a multi-user simulation experiment for evaluating RMS precision by simulating varying manually-provided superior tip positions, 3σ maximum errors were 2.44  mm. The average segmentation time for a single catheter was 3 s on a standard PC. The segmentation time, accuracy and precision, are promising indicators of the value of this method for clinical translation of MR-guidance in gynecologic brachytherapy and other catheter-based interventional procedures.},
	language = {eng},
	journal = {Medical Image Analysis},
	author = {Mastmeyer, Andre and Pernelle, Guillaume and Ma, Ruibin and Barber, Lauren and Kapur, Tina},
	month = dec,
	year = {2017},
	pmid = {28803217},
	pmcid = {PMC5654713},
	keywords = {Accuracy, Catheter, MRI, Outlier reduction, Precision, Segmentation},
	pages = {173--188}
}

@article{fichera_through_2017,
	title = {Through the {Eustachian} {Tube} and {Beyond}: {A} {New} {Miniature} {Robotic} {Endoscope} to {See} {Into} the {Middle} {Ear}},
	volume = {2},
	issn = {2377-3766},
	shorttitle = {Through the {Eustachian} {Tube} and {Beyond}},
	doi = {10.1109/LRA.2017.2668468},
	abstract = {This letter presents a novel miniature robotic endoscope that is small enough to pass through the Eustachian tube and provides visualization of the middle ear (ME). The device features a miniature bending tip previously conceived of as a small-scale robotic wrist that has been adapted to carry and aim a small chip-tip camera and fiber-optic light sources. The motivation for trans-Eustachian tube ME inspection is to provide a natural-orifice-based route to the ME that does not require cutting or lifting the eardrum, as is currently required. In this letter, we first perform an analysis of the ME anatomy and use a computational design optimization platform to derive the kinematic requirements for endoscopic inspection of the ME through the Eustachian tube. Based on these requirements, we fabricate the proposed device and use it to demonstrate the feasibility of ME inspection in an anthropomorphic model, i.e., a 3-D printed ME phantom generated from patient image data. We show that our prototype provides {\textgreater} 74\% visibility coverage of the sinus tympani, a region of the ME crucial for diagnosis, compared to an average of only 6.9\% using a straight nonarticulated endoscope through the Eustachian tube.},
	number = {3},
	journal = {IEEE Robotics and Automation Letters},
	author = {Fichera, L. and Dillon, N. P. and Zhang, D. and Godage, I. S. and Siebold, M. A. and Hartley, B. I. and Noble, J. H. and Russell, P. T. and Labadie, R. F. and Webster, R. J.},
	month = jul,
	year = {2017},
	keywords = {3-D printed ME phantom, Computed tomography, Ear, Electron tubes, Endoscopes, Inspection, Medical robots and systems, Robots, Visualization, anthropomorphic model, computational design optimization platform, design engineering, ear, endoscopes, endoscopic inspection, fiber-optic light sources, kinematic requirements, medical robotics, middle ear, miniature bending tip, miniature robotic endoscope, nonarticulated endoscope, optimisation, orifice-based route, patient image data, robot kinematics, small chip-tip camera, small-scale robotic wrist, steerable catheters/needles, surgical robotics, three-dimensional printing, trans-Eustachian tube ME inspection},
	pages = {1488--1494}
}

@article{dinis_fernandes_prostate_2017,
	title = {Prostate fiducial marker detection with the use of multi-parametric magnetic resonance imaging},
	volume = {1},
	issn = {2405-6316},
	url = {http://www.sciencedirect.com/science/article/pii/S2405631616300227},
	doi = {10.1016/j.phro.2017.02.001},
	abstract = {The introduction of a magnetic resonance (MR)-only workflow in radiotherapy requires that fiducial markers, used for position verification, can be detected on MR images. Here we evaluate a model for marker detection in prostate cancer patients by combining information from our hospital standard multi-parametric (mp-) MRI protocol (T1-weighted – T1w, T2-weighted – T2w, B0) with dedicated sequences (balanced steady-state free precession sequence – bTFE, susceptibility weighted imaging – SWI). Thirty two patients scheduled for external-beam radiotherapy received a mp-MRI and computed-tomography; the latter was used as ground truth location of the markers. A logistic regression model was implemented for marker detection by combining features from all imaging sequences. The performance of the individual and combined sequences was assessed by determining true and false positive detections. The combination of different sequences (mp-MRI) resulted in a better performance than the best imaging sequence alone (bTFE). Combining mp-MRI+bTFE resulted in good accuracy and a true positive detection rate of 0.94. The standard mp-MRI provides valuable information to detect fiducial markers. The combination of different sequences outperforms the use of a single dedicated sequence. We recommend the addition of a bTFE to the standard mp-MRI protocol to improve fiducial marker detection.},
	number = {Supplement C},
	urldate = {2017-12-07TZ},
	journal = {Physics and Imaging in Radiation Oncology},
	author = {Dinis Fernandes, Catarina and Dinh, Cuong V. and Steggerda, Marcel J. and ter Beek, Leon C. and Smolic, Milena and van Buuren, Laurens D. and Pos, Floris J. and van der Heide, Uulke A.},
	month = jan,
	year = {2017},
	keywords = {External beam radiotherapy, Fiducial markers, Multi-parametric MRI, Prostate cancer},
	pages = {14--20}
}

@article{ghose_mri-alone_2016,
	title = {{MRI}-alone radiation therapy planning for prostate cancer: {Automatic} fiducial marker detection},
	volume = {43},
	issn = {2473-4209},
	shorttitle = {{MRI}-alone radiation therapy planning for prostate cancer},
	url = {http://onlinelibrary.wiley.com/doi/10.1118/1.4944871/abstract},
	doi = {10.1118/1.4944871},
	abstract = {Purpose:

The feasibility of radiation therapy treatment planning using substitute computed tomography (sCT) generated from magnetic resonance images (MRIs) has been demonstrated by a number of research groups. One challenge with an MRI-alone workflow is the accurate identification of intraprostatic gold fiducial markers, which are frequently used for prostate localization prior to each dose delivery fraction. This paper investigates a template-matching approach for the detection of these seeds in MRI.


Methods:

Two different gradient echo T1 and T2* weighted MRI sequences were acquired from fifteen prostate cancer patients and evaluated for seed detection. For training, seed templates from manual contours were selected in a spectral clustering manifold learning framework. This aids in clustering “similar” gold fiducial markers together. The marker with the minimum distance to a cluster centroid was selected as the representative template of that cluster during training. During testing, Gaussian mixture modeling followed by a Markovian model was used in automatic detection of the probable candidates. The probable candidates were rigidly registered to the templates identified from spectral clustering, and a similarity metric is computed for ranking and detection.


Results:

A fiducial detection accuracy of 95\% was obtained compared to manual observations. Expert radiation therapist observers were able to correctly identify all three implanted seeds on 11 of the 15 scans (the proposed method correctly identified all seeds on 10 of the 15).


Conclusions:

An novel automatic framework for gold fiducial marker detection in MRI is proposed and evaluated with detection accuracies comparable to manual detection. When radiation therapists are unable to determine the seed location in MRI, they refer back to the planning CT (only available in the existing clinical framework); similarly, an automatic quality control is built into the automatic software to ensure that all gold seeds are either correctly detected or a warning is raised for further manual intervention.},
	language = {en},
	number = {5},
	urldate = {2017-12-07TZ},
	journal = {Medical Physics},
	author = {Ghose, Soumya and Mitra, Jhimli and Rivest-Hénault, David and Fazlollahi, Amir and Stanwell, Peter and Pichler, Peter and Sun, Jidi and Fripp, Jurgen and Greer, Peter B. and Dowling, Jason A.},
	month = may,
	year = {2016},
	keywords = {Biological material, e.g. blood, urine, Cancer, Clinical applications, Cluster analysis, Cluster spectra, Computed tomography, Digital computing or data processing equipment or methods, specially adapted for specific applications, Gaussian processes, Gold, Haemocytometers, Image data processing or generation, in general, Involving electronic [emr] or nuclear [nmr] magnetic resonance, e.g. magnetic resonance imaging, Manifolds, Markov processes, Medical magnetic resonance imaging, Radiation therapy, Registration, Therapeutic applications, including brachytherapy, Treatment planning, biomedical MRI, cancer, geometric registration, image registration, medical image processing, prostate cancer, radiation therapy, spectral clustering, template matching},
	pages = {2218--2228}
}
@article{maspero_evaluation_2017,
	title = {Evaluation of an automatic {MR}-based gold fiducial marker localisation method for {MR}-only prostate radiotherapy},
	volume = {62},
	issn = {0031-9155},
	url = {http://stacks.iop.org/0031-9155/62/i=20/a=7981},
	doi = {10.1088/1361-6560/aa875f},
	abstract = {An MR-only radiotherapy planning (RTP) workflow would reduce the cost, radiation exposure and uncertainties introduced by CT-MRI registrations. In the case of prostate treatment, one of the remaining challenges currently holding back the implementation of an RTP workflow is the MR-based localisation of intraprostatic gold fiducial markers (FMs), which is crucial for accurate patient positioning. Currently, MR-based FM localisation is clinically performed manually. This is sub-optimal, as manual interaction increases the workload. Attempts to perform automatic FM detection often rely on being able to detect signal voids induced by the FMs in magnitude images. However, signal voids may not always be sufficiently specific, hampering accurate and robust automatic FM localisation. Here, we present an approach that aims at automatic MR-based FM localisation. This method is based on template matching using a library of simulated complex-valued templates, and exploiting the behaviour of the complex MR signal in the vicinity of the FM. Clinical evaluation was performed on seventeen prostate cancer patients undergoing external beam radiotherapy treatment. Automatic MR-based FM localisation was compared to manual MR-based and semi-automatic CT-based localisation (the current gold standard) in terms of detection rate and the spatial accuracy and precision of localisation. The proposed method correctly detected all three FMs in 15/17 patients. The spatial accuracy (mean) and precision (STD) were 0.9 mm and 0.5 mm respectively, which is below the voxel size of \#\#IMG\#\# [http://ej.iop.org/images/0031-9155/62/20/7981/pmbaa875fieqn001.gif] \$1.1 {\textbackslash}times 1.1 {\textbackslash}times 1.2\$ mm 3 and comparable to MR-based manual localisation. FM localisation failed (3/51 FMs) in the presence of bleeding or calcifications in the direct vicinity of the FM. The method was found to be spatially accurate and precise, which is essential for clinical use. To overcome any missed detection, we envision the use of the proposed method along with verification by an observer. This will result in a semi-automatic workflow facilitating the introduction of an MR-only workflow.},
	language = {en},
	number = {20},
	urldate = {2017-12-07TZ},
	journal = {Physics in Medicine \& Biology},
	author = {Maspero, Matteo and Berg, Cornelis A. T. van den and Zijlstra, Frank and Sikkes, Gonda G. and Boer, Hans C. J. de and Meijer, Gert J. and Kerkmeijer, Linda G. W. and Viergever, Max A. and Lagendijk, Jan J. W. and Seevinck, Peter R.},
	year = {2017},
	pages = {7981}
}

@article{zijlstra_fast_2017,
	title = {Fast {Fourier}-based simulation of off-resonance artifacts in steady-state gradient echo {MRI} applied to metal object localization},
	volume = {78},
	issn = {1522-2594},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/mrm.26556/abstract},
	doi = {10.1002/mrm.26556},
	abstract = {Purpose

To accelerate simulation of off-resonance artifacts in steady-state gradient echo MRI by using fast Fourier transforms and demonstrate its applicability to metal object localization.


Theory and Methods

By exploiting the repetitive nature of steady-state pulse sequences it is possible to use fast Fourier transforms to calculate the MR signal. Based on this principle, a method for fast simulation of off-resonance artifacts was designed. The method was validated against Bloch simulations and MRI scans. Its clinical relevance was demonstrated by employing it for template matching-based metal object localization, as applied to a titanium cylinder, an oxidized zirconium knee implant, and gold fiducials.


Results

The fast simulations were accurate compared with actual MRI scans of the objects. The differences between the fast simulations and Bloch simulations were minor, while the acceleration scaled linearly with the number of phase-encoding lines. The object localization method accurately localized the various metal objects.


Conclusion

The proposed simulation methodology provided accurate 3D simulations of off-resonance artifacts with a lower computational complexity than Bloch simulations. The speed of the simulations opens up possibilities in image reconstructions involving off-resonance phenomena that were previously infeasible due to computational limitations, as demonstrated for metal object localization. Magn Reson Med 78:2035–2041, 2017. © 2016 The Authors Magnetic Resonance in Medicine published by Wiley Periodicals, Inc. on behalf of International Society for Magnetic Resonance in Medicine. This is an open access article under the terms of the Creative Commons Attribution NonCommercial License, which permits use, distribution and reproduction in any medium, provided the original work is properly cited and is not used for commercial purposes.},
	language = {en},
	number = {5},
	urldate = {2017-12-07TZ},
	journal = {Magnetic Resonance in Medicine},
	author = {Zijlstra, Frank and Bouwman, Job G. and Braškutė, Ieva and Viergever, Max A. and Seevinck, Peter R.},
	month = nov,
	year = {2017},
	keywords = {Bloch simulations, FORECAST, MRI simulation, magnetic susceptibility, off-resonance artifacts},
	pages = {2035--2041}
}

@article{zijlstra_fast_2017-1,
	title = {Fast {Fourier}‐based simulation of off‐resonance artifacts in steady‐state gradient echo {MRI} applied to metal object localization},
	volume = {78},
	issn = {1522-2594},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/mrm.26556/full},
	doi = {10.1002/mrm.26556},
	abstract = {To accelerate simulation of off‐resonance artifacts in steady‐state gradient echo MRI by using fast Fourier transforms and demonstrate its applicability to metal object localization.By exploiting the repetitive...},
	language = {en},
	number = {5},
	urldate = {2017-12-07TZ},
	journal = {Magnetic Resonance in Medicine},
	author = {Zijlstra, Frank and Bouwman, Job G. and Braškutė, Ieva and Viergever, Max A. and Seevinck, Peter R.},
	month = nov,
	year = {2017},
	pages = {2035--2041}
}

@article{bakker_susceptibility_1993,
	title = {Susceptibility artifacts in 2DFT spin-echo and gradient-echo imaging: {The} cylinder model revisited},
	volume = {11},
	issn = {0730-725X},
	shorttitle = {Susceptibility artifacts in 2DFT spin-echo and gradient-echo imaging},
	url = {http://www.sciencedirect.com/science/article/pii/0730725X9390473Q},
	doi = {10.1016/0730-725X(93)90473-Q},
	abstract = {Susceptibility-induced geometry and intensity distortions are a familiar observation in MR imaging. In the past few years several attempts have been made to aid in the understanding of susceptibility artifacts by means of simulation studies. Although these studies, which were mostly carried out with simple test objects, have produced some qualitative insight into χ-artifacts, the results lacked precision in describing finer details. In this paper we show the discrepancy between theory and experiment in previous work to be the result of an inadequate theoretical approach. In most studies so far, ΔB0 effects are taken into account in the frequency domain, that is, after Fourier transformation of the data. In our view the simulation should follow the actual sequence of events in an imaging experiment and deal with the effect of error fields in the time domain (k-space) already. The correctness of this view is demonstrated here by comparing the results of time and frequency domain simulation against experimental observation for a coaxial cylinder phantom, a widely used model in this type of work. Having established the superiority of the time domain simulation, we demonstrate its use in predicting χ-artifacts under various experimental conditions, for example, in spin-echo and gradient-echo imaging with a reduced number of phaseencoding steps.},
	number = {4},
	urldate = {2017-12-06TZ},
	journal = {Magnetic Resonance Imaging},
	author = {Bakker, C. J. G. and Bhagwandien, R. and Moerland, M. A. and Fuderer, M.},
	month = jan,
	year = {1993},
	keywords = {Geometric distortion, Intensity distortion, Magnetic resonance imaging, Susceptibility artifacts},
	pages = {539--548}
}

@article{ludeke_susceptibility_1985,
	title = {Susceptibility artefacts in {NMR} imaging},
	volume = {3},
	issn = {0730-725X},
	url = {http://www.sciencedirect.com/science/article/pii/0730725X85903972},
	doi = {10.1016/0730-725X(85)90397-2},
	number = {4},
	urldate = {2017-12-06TZ},
	journal = {Magnetic Resonance Imaging},
	author = {Lüdeke, K. M. and Röschmann, P. and Tischler, R.},
	month = jan,
	year = {1985},
	pages = {329--343}
}

@article{balac_integral_2001,
	title = {Integral method for numerical simulation of {MRI} artifacts induced by metallic implants},
	volume = {45},
	issn = {1522-2594},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/mrm.1098/abstract},
	doi = {10.1002/mrm.1098},
	abstract = {Numerical simulation is a valuable tool for the study of magnetic susceptibility artifacts from metallic implants. A major difficulty in the simulation lies in the computation of the magnetic field induced by the metallic implant. A new method has been designed and implemented to compute the magnetic field induced by metallic objects of arbitrary shape. The magnetic field is expressed pointwise in terms of a surface integral. Efficient quadrature schemes are proposed to evaluate this integral. Finally, the method is linked to an artifact reconstruction model to simulate the images. Magn Reson Med 45:724–727, 2001. © 2001 Wiley-Liss, Inc.},
	language = {en},
	number = {4},
	urldate = {2017-12-06TZ},
	journal = {Magnetic Resonance in Medicine},
	author = {Balac, S. and Caloz, G. and Cathelineau, G. and Chauvel, B. and de Certaines, J.d.},
	month = apr,
	year = {2001},
	keywords = {integral representation, magnetic field computation, magnetostatics, numerical simulation, susceptibility artifacts},
	pages = {724--727}
}

@article{balac_integral_2001-1,
	title = {Integral method for numerical simulation of {MRI} artifacts induced by metallic implants},
	volume = {45},
	issn = {1522-2594},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/mrm.1098/abstract},
	doi = {10.1002/mrm.1098},
	abstract = {Numerical simulation is a valuable tool for the study of magnetic susceptibility artifacts from metallic implants. A major difficulty in the simulation lies in the computation of the magnetic field induced by the metallic implant. A new method has been designed and implemented to compute the magnetic field induced by metallic objects of arbitrary shape. The magnetic field is expressed pointwise in terms of a surface integral. Efficient quadrature schemes are proposed to evaluate this integral. Finally, the method is linked to an artifact reconstruction model to simulate the images. Magn Reson Med 45:724–727, 2001. © 2001 Wiley-Liss, Inc.},
	language = {en},
	number = {4},
	urldate = {2017-12-06TZ},
	journal = {Magnetic Resonance in Medicine},
	author = {Balac, S. and Caloz, G. and Cathelineau, G. and Chauvel, B. and de Certaines, J.d.},
	month = apr,
	year = {2001},
	keywords = {integral representation, magnetic field computation, magnetostatics, numerical simulation, susceptibility artifacts},
	pages = {724--727}
}

@article{bhagwandien_numerical_1992,
	title = {Numerical analysis of the magnetic field for arbitrary magnetic susceptibility distributions in 2D},
	volume = {10},
	issn = {0730-725X},
	url = {http://www.sciencedirect.com/science/article/pii/0730725X9290489M},
	doi = {10.1016/0730-725X(92)90489-M},
	abstract = {We describe a numerical technique for calculating the 2D magnetic field in arbitrary magnetic susceptibility distribution. The technique we used is the explicit finite difference method with an addition of the Du Fort-Frankle algorithm. The proposed algorithm is unconditionally stable and has excellent convergence properties. For simple geometries, numerical results were compared against analytical solutions and appeared to be in excellent agreement.},
	number = {2},
	urldate = {2017-12-06TZ},
	journal = {Magnetic Resonance Imaging},
	author = {Bhagwandien, R. and van Ee, R. and Beersma, R. and Bakker, C. J. G. and Moerland, M. A. and Lagendijk, J. J. W.},
	month = jan,
	year = {1992},
	keywords = {Distortions, Magnetic field analysis, Magnetic field simulations, Magnetic resonance imaging, Susceptibility artifacts},
	pages = {299--313}
}

@article{balac_integral_2001-2,
	title = {Integral method for numerical simulation of {MRI} artifacts induced by metallic implants},
	volume = {45},
	issn = {0740-3194},
	abstract = {Numerical simulation is a valuable tool for the study of magnetic susceptibility artifacts from metallic implants. A major difficulty in the simulation lies in the computation of the magnetic field induced by the metallic implant. A new method has been designed and implemented to compute the magnetic field induced by metallic objects of arbitrary shape. The magnetic field is expressed pointwise in terms of a surface integral. Efficient quadrature schemes are proposed to evaluate this integral. Finally, the method is linked to an artifact reconstruction model to simulate the images. Magn Reson Med 45:724-727, 2001.},
	language = {eng},
	number = {4},
	journal = {Magnetic Resonance in Medicine},
	author = {Balac, S. and Caloz, G. and Cathelineau, G. and Chauvel, B. and de Certaines, J. D.},
	month = apr,
	year = {2001},
	pmid = {11284004},
	keywords = {Artifacts, Magnetic Resonance Imaging, Magnetics, Mathematics, Metals, Models, Theoretical, Prostheses and Implants},
	pages = {724--727}
}

@article{lewin_needle_1996,
	title = {Needle localization in {MR}-guided biopsy and aspiration: effects of field strength, sequence design, and magnetic field orientation.},
	volume = {166},
	issn = {0361-803X},
	shorttitle = {Needle localization in {MR}-guided biopsy and aspiration},
	url = {http://www.ajronline.org/doi/abs/10.2214/ajr.166.6.8633445},
	doi = {10.2214/ajr.166.6.8633445},
	abstract = {: The purpose of this investigation was to evaluate the accuracy of MR Imaging for needle depiction at 0.2 and 1.5 T with multiple pulse sequences and needle orientations. The goal was to provide a framework for biopsy approach and imaging technique parameter selection that will ensure the safety and accuracy of MR-guided procedures.Eight titanium and stainless steel alloy MR-compatible biopsy devices were immersed in fluid phantoms and placed into 1.5- and 0.2-T MR systems used for clinical imaging. Spin-echo, turbo spin-echo, and gradient-echo images were obtained with the needle shafts of the biopsy devices placed parallel to, perpendicular to, and at angles of 30 degrees and 60 degrees relative to the static magnetic field of the scanner. All images were obtained with the frequency-encoding direction parallel to and perpendicular to the needle shaft. Needle width and tip position were measured from images on a freestanding workstation, and the apparent tip position was compared with that obtained by direct measurement. The difference between these values was calculated for each needle type, imaging sequence, frequency-encoding direction, and needle orientation.Artifactual widening was much more apparent at 1.5 T than at 0.2 T, as was error in determining needle tip position. Artifacts at both field strengths were most pronounced with gradient-echo sequences, less so with turbo spin-echo sequences, and least of all with spin-echo sequences. For spin-echo and turbo spin-echo sequences, when the frequency-encoding axis was perpendicular to the needle shaft, the apparent width of the needle was larger, but error in needle tip position was smaller. Artifacts were much less apparent, but error in tip position increased, as the orientation of the needle shaft became more parallel to the direction of the magnetic field.Specific measurements differed with field strength, but needle tip localization within 1 mm was obtained at both 0.2 and 1.5 T with the appropriate frequency-encoding direction, pulse sequence, and imaging parameters. Orientation of the needle parallel to the magnetic field significantly reduced the apparent width of the needle at both field strengths but also decreased the accuracy of needle tip position localization.},
	number = {6},
	urldate = {2017-12-06TZ},
	journal = {American Journal of Roentgenology},
	author = {Lewin, J S and Duerk, J L and Jain, V R and Petersilge, C A and Chao, C P and Haaga, J R},
	month = jun,
	year = {1996},
	pages = {1337--1345}
}

@article{lewin_needle_1996-1,
	title = {Needle localization in {MR}-guided biopsy and aspiration: effects of field strength, sequence design, and magnetic field orientation},
	volume = {166},
	issn = {0361-803X},
	shorttitle = {Needle localization in {MR}-guided biopsy and aspiration},
	doi = {10.2214/ajr.166.6.8633445},
	abstract = {OBJECTIVE: The purpose of this investigation was to evaluate the accuracy of MR Imaging for needle depiction at 0.2 and 1.5 T with multiple pulse sequences and needle orientations. The goal was to provide a framework for biopsy approach and imaging technique parameter selection that will ensure the safety and accuracy of MR-guided procedures.
MATERIALS AND METHODS: Eight titanium and stainless steel alloy MR-compatible biopsy devices were immersed in fluid phantoms and placed into 1.5- and 0.2-T MR systems used for clinical imaging. Spin-echo, turbo spin-echo, and gradient-echo images were obtained with the needle shafts of the biopsy devices placed parallel to, perpendicular to, and at angles of 30 degrees and 60 degrees relative to the static magnetic field of the scanner. All images were obtained with the frequency-encoding direction parallel to and perpendicular to the needle shaft. Needle width and tip position were measured from images on a freestanding workstation, and the apparent tip position was compared with that obtained by direct measurement. The difference between these values was calculated for each needle type, imaging sequence, frequency-encoding direction, and needle orientation.
RESULTS: Artifactual widening was much more apparent at 1.5 T than at 0.2 T, as was error in determining needle tip position. Artifacts at both field strengths were most pronounced with gradient-echo sequences, less so with turbo spin-echo sequences, and least of all with spin-echo sequences. For spin-echo and turbo spin-echo sequences, when the frequency-encoding axis was perpendicular to the needle shaft, the apparent width of the needle was larger, but error in needle tip position was smaller. Artifacts were much less apparent, but error in tip position increased, as the orientation of the needle shaft became more parallel to the direction of the magnetic field.
CONCLUSION: Specific measurements differed with field strength, but needle tip localization within 1 mm was obtained at both 0.2 and 1.5 T with the appropriate frequency-encoding direction, pulse sequence, and imaging parameters. Orientation of the needle parallel to the magnetic field significantly reduced the apparent width of the needle at both field strengths but also decreased the accuracy of needle tip position localization.},
	language = {eng},
	number = {6},
	journal = {AJR. American journal of roentgenology},
	author = {Lewin, J. S. and Duerk, J. L. and Jain, V. R. and Petersilge, C. A. and Chao, C. P. and Haaga, J. R.},
	month = jun,
	year = {1996},
	pmid = {8633445},
	keywords = {Biopsy, Needle, Magnetic Resonance Imaging, Needles, Phantoms, Imaging},
	pages = {1337--1345}
}

@article{radzi_metal_2014,
	title = {Metal artifacts from titanium and steel screws in {CT}, 1.5T and 3T {MR} images of the tibial {Pilon}: a quantitative assessment in 3D},
	volume = {4},
	issn = {2223-4292},
	shorttitle = {Metal artifacts from titanium and steel screws in {CT}, 1.5T and 3T {MR} images of the tibial {Pilon}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4032923/},
	doi = {10.3978/j.issn.2223-4292.2014.03.06},
	abstract = {Radiographs are commonly used to assess articular reduction of the distal tibia (pilon) fractures postoperatively, but may reveal malreductions inaccurately. While magnetic resonance imaging (MRI) and computed tomography (CT) are potential three-dimensional (3D) alternatives they generate metal-related artifacts. This study aims to quantify the artifact size from orthopaedic screws using CT, 1.5T and 3T MRI data. Three screws were inserted into one intact human cadaver ankle specimen proximal to and along the distal articular surface, then CT, 1.5T and 3T MRI scanned. Four types of screws were investigated: titanium alloy (TA), stainless steel (SS) (Ø =3.5 mm), cannulated TA (CTA) and cannulated SS (CSS) (Ø =4.0 mm, Ø empty core =2.6 mm). 3D artifact models were reconstructed using adaptive thresholding. The artifact size was measured by calculating the perpendicular distance from the central screw axis to the boundary of the artifact in four anatomical directions with respect to the distal tibia. The artifact sizes (in the order of TA, SS, CTA and CSS) from CT were 2.0, 2.6, 1.6 and 2.0 mm; from 1.5T MRI they were 3.7, 10.9, 2.9, and 9 mm; and 3T MRI they were 4.4, 15.3, 3.8, and 11.6 mm respectively. Therefore, CT can be used as long as the screws are at a safe distance of about 2 mm from the articular surface. MRI can be used if the screws are at least 3 mm away from the articular surface except for SS and CSS. Artifacts from steel screws were too large thus obstructed the pilon from being visualised in MRI. Significant differences (P{\textless}0.05) were found in the size of artifacts between all imaging modalities, screw types and material types, except 1.5T versus 3T MRI for the SS screws (P=0.063). CTA screws near the joint surface can improve postoperative assessment in CT and MRI. MRI presents a favourable non-ionising alternative when using titanium hardware. Since these factors may influence the quality of postoperative assessment, potential improvements in operative techniques should be considered.},
	number = {3},
	urldate = {2017-12-05TZ},
	journal = {Quantitative Imaging in Medicine and Surgery},
	author = {Radzi, Shairah and Cowin, Gary and Robinson, Mark and Pratap, Jit and Volp, Andrew and Schuetz, Michael A. and Schmutz, Beat},
	month = jun,
	year = {2014},
	pmid = {24914417},
	pmcid = {PMC4032923},
	pages = {163--172}
}

@article{radzi_metal_2014-1,
	title = {Metal artifacts from titanium and steel screws in {CT}, 1.5T and 3T {MR} images of the tibial {Pilon}: a quantitative assessment in 3D},
	volume = {4},
	issn = {2223-4292},
	shorttitle = {Metal artifacts from titanium and steel screws in {CT}, 1.5T and 3T {MR} images of the tibial {Pilon}},
	doi = {10.3978/j.issn.2223-4292.2014.03.06},
	abstract = {Radiographs are commonly used to assess articular reduction of the distal tibia (pilon) fractures postoperatively, but may reveal malreductions inaccurately. While magnetic resonance imaging (MRI) and computed tomography (CT) are potential three-dimensional (3D) alternatives they generate metal-related artifacts. This study aims to quantify the artifact size from orthopaedic screws using CT, 1.5T and 3T MRI data. Three screws were inserted into one intact human cadaver ankle specimen proximal to and along the distal articular surface, then CT, 1.5T and 3T MRI scanned. Four types of screws were investigated: titanium alloy (TA), stainless steel (SS) (Ø =3.5 mm), cannulated TA (CTA) and cannulated SS (CSS) (Ø =4.0 mm, Ø empty core =2.6 mm). 3D artifact models were reconstructed using adaptive thresholding. The artifact size was measured by calculating the perpendicular distance from the central screw axis to the boundary of the artifact in four anatomical directions with respect to the distal tibia. The artifact sizes (in the order of TA, SS, CTA and CSS) from CT were 2.0, 2.6, 1.6 and 2.0 mm; from 1.5T MRI they were 3.7, 10.9, 2.9, and 9 mm; and 3T MRI they were 4.4, 15.3, 3.8, and 11.6 mm respectively. Therefore, CT can be used as long as the screws are at a safe distance of about 2 mm from the articular surface. MRI can be used if the screws are at least 3 mm away from the articular surface except for SS and CSS. Artifacts from steel screws were too large thus obstructed the pilon from being visualised in MRI. Significant differences (P{\textless}0.05) were found in the size of artifacts between all imaging modalities, screw types and material types, except 1.5T versus 3T MRI for the SS screws (P=0.063). CTA screws near the joint surface can improve postoperative assessment in CT and MRI. MRI presents a favourable non-ionising alternative when using titanium hardware. Since these factors may influence the quality of postoperative assessment, potential improvements in operative techniques should be considered.},
	language = {eng},
	number = {3},
	journal = {Quantitative Imaging in Medicine and Surgery},
	author = {Radzi, Shairah and Cowin, Gary and Robinson, Mark and Pratap, Jit and Volp, Andrew and Schuetz, Michael A. and Schmutz, Beat},
	month = jun,
	year = {2014},
	pmid = {24914417},
	pmcid = {PMC4032923},
	keywords = {Computed tomography (CT), magnetic resonance imaging (MRI), metal artifacts, pilon, tibial plafond},
	pages = {163--172}
}

@article{lee_overcoming_2007,
	title = {Overcoming {Artifacts} from {Metallic} {Orthopedic} {Implants} at {High}-{Field}-{Strength} {MR} {Imaging} and {Multi}-detector {CT}},
	volume = {27},
	issn = {0271-5333},
	url = {http://pubs.rsna.org/doi/full/10.1148/rg.273065087},
	doi = {10.1148/rg.273065087},
	number = {3},
	urldate = {2017-12-05TZ},
	journal = {RadioGraphics},
	author = {Lee, Mi-Jung and Kim, Sungjun and Lee, Sung-Ah and Song, Ho-Taek and Huh, Yong-Min and Kim, Dae-Hong and Han, Seung Hwan and Suh, Jin-Suck},
	month = may,
	year = {2007},
	pages = {791--803}
}

@article{liu_fast_2017,
	title = {Fast {Realistic} {MRI} {Simulations} {Based} on {Generalized} {Multi}-{Pool} {Exchange} {Tissue} {Model}},
	volume = {36},
	issn = {0278-0062},
	doi = {10.1109/TMI.2016.2620961},
	abstract = {We present MRiLab, a new comprehensive simulator for large-scale realistic MRI simulations on a regular PC equipped with a modern graphical processing unit (GPU). MRiLab combines realistic tissue modeling with numerical virtualization of an MRI system and scanning experiment to enable assessment of a broad range of MRI approaches including advanced quantitative MRI methods inferring microstructure on a sub-voxel level. A flexible representation of tissue microstructure is achieved in MRiLab by employing the generalized tissue model with multiple exchanging water and macromolecular proton pools rather than a system of independent proton isochromats typically used in previous simulators. The computational power needed for simulation of the biologically relevant tissue models in large 3D objects is gained using parallelized execution on GPU. Three simulated and one actual MRI experiments were performed to demonstrate the ability of the new simulator to accommodate a wide variety of voxel composition scenarios and demonstrate detrimental effects of simplified treatment of tissue micro-organization adapted in previous simulators. GPU execution allowed 200× improvement in computational speed over standard CPU. As a cross-platform, open-source, extensible environment for customizing virtual MRI experiments, MRiLab streamlines the development of new MRI methods, especially those aiming to infer quantitatively tissue composition and microstructure.},
	number = {2},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Liu, F. and Velikina, J. V. and Block, W. F. and Kijowski, R. and Samsonov, A. A.},
	month = feb,
	year = {2017},
	keywords = {3D objects, Biological system modeling, Brain modeling, CEST, Computational modeling, GPU, MRiLab, Magnetic resonance imaging, Magnetization, Protons, biological tissues, biologically relevant tissue models, biomedical MRI, computational power, generalized multipool exchange tissue model, graphical processing unit, graphical processing unit (GPU), graphics processing units, large-scale realistic MRI simulations, macromolecular proton pools, magnetization transfer, medical computing, numerical virtualization, open-source extensible environment, relaxometry, simulation, subvoxel level, tissue composition, tissue microorganization, tissue microstructure, voxel composition scenarios},
	pages = {527--537}
}

@article{hrinivich_accuracy_2017,
	title = {Accuracy and variability of high-dose-rate prostate brachytherapy needle tip localization using live two-dimensional and sagittally reconstructed three-dimensional ultrasound},
	volume = {16},
	issn = {1538-4721},
	url = {http://www.sciencedirect.com/science/article/pii/S153847211730394X},
	doi = {10.1016/j.brachy.2017.06.008},
	abstract = {To measure the accuracy and variability of manual high-dose-rate (HDR) prostate brachytherapy (BT) needle tip localization using sagittally reconstructed three-dimensional (3D) transrectal ultrasound (TRUS) augmented with live two-dimensional (2D) sagittal TRUS. Ten prostate cancer patients underwent HDR-BT during which the sagittally assisted sagittally reconstructed (SASR) segmentation technique was completed in parallel with commercially available sagittally assisted axially reconstructed (SAAR) TRUS for comparison. The SASR technique makes use of live 2D ultrasound intraoperatively and allows needle tip updates using the final 3D image in the absence of image artifacts. These updates were repeated offline twice by two separate users. Needle end-length measurements were used to calculate insertion depth errors (IDEs) for each technique. Images of 147 needles were analyzed. For the SASR technique, both users were confident in tip positions on the final 3D image within 3 mm for 52\% of needles, so these tip positions were updated. For the remaining 48\% of needles, the tip positions from the live 2D images were used. This SASR technique enabled the localization of all needles with IDEs within ±3 mm for 84\% of needles and IDE range of [−6.2 mm, 5.9 mm], compared with 57\% and [−8.1 mm, 7.7 mm] when using the commercially available SAAR technique. The SASR technique mitigates the impact of 3D TRUS image artifacts on HDR-BT needle tip localization by incorporating live 2D sagittal TRUS intraoperatively and provides a statistically significant reduction in IDE variance compared with the routine SAAR technique.},
	number = {5},
	urldate = {2017-12-04TZ},
	journal = {Brachytherapy},
	author = {Hrinivich, William Thomas and Hoover, Douglas A. and Surry, Kathleen and Edirisinghe, Chandima and Velker, Vikram and Bauman, Glenn and D'Souza, David and Fenster, Aaron and Wong, Eugene},
	month = sep,
	year = {2017},
	keywords = {3D ultrasound, High-dose-rate brachytherapy, Needle localization, Prostate cancer, Transrectal ultrasound},
	pages = {1035--1043}
}

@article{muller-bierl_numerical_2004,
	title = {Numerical modeling of needle tip artifacts in {MR} gradient echo imaging},
	volume = {31},
	issn = {2473-4209},
	url = {http://onlinelibrary.wiley.com/doi/10.1118/1.1640971/abstract},
	doi = {10.1118/1.1640971},
	abstract = {Exact determination of needle tip position is obsolete for interventional procedures under control of magnetic resonance imaging (MRI). Exact needle tip navigation is complicated by the paramagnetism of microsurgical instruments: Local magnetic field inhomogeneities are induced resulting in position encoding artifacts and in signal voids in the surrounding of instruments and especially near their tips. The artifacts generated by the susceptibility of the material are not only dependent on the material properties themselves and on the applied MRI sequences and parameters, but also on the geometric shape of the instruments and on the orientation to the static magnetic field in the MR unit. A numerical model based on superposition of induced elementary dipole fields was developed for studying the field distortions near paramagnetic needle tips. The model was validated by comparison with experimental data using field mapping MRI techniques. Comparison between experimental data and numerical simulations revealed good correspondence for the induced field inhomogeneities. Further systematic numerical studies of the field distribution were performed for variable types of concentric and asymmetric tip shapes, for different ratios between tip length and needle diameter, and for different orientations of the needle axis in the external static magnetic field. Based on the computed local inhomogeneities of the magnetic field in the surroundings of the needle tips, signal voids in usual gradient echo images were simulated for a prediction of the artifacts. The practically relevant spatial relation between those artifacts and the hidden tip of the needle was calculated for the different tip shapes and orientations in the external field. As needle tip determination is crucial in interventional procedures, e.g., in taking biopsies, the present model can help to instruct the physician prior to surgical interventions in better estimating the needle tip position for different orientations and needle tip shapes as they appear in interventional procedures. As manufacturing prototypes with subsequent measurements of artifacts in MRI are a costly procedure the presented model may also help to optimize shapes of needle tips and of other parts of MR-compatible instruments and implants with low expense prior to production if some shape parameters can be chosen freely.},
	language = {en},
	number = {3},
	urldate = {2017-12-04TZ},
	journal = {Medical Physics},
	author = {Müller-Bierl, Bernd and Graf, Hansjörg and Lauer, Ulrike and Steidle, Günter and Schick, Fritz},
	month = mar,
	year = {2004},
	keywords = {Encoding, General theory and mathematical aspects, Instrumentation, MR artifacts, Magnetic fields, Magnetic resonance, Magnetic resonance imaging, Materials properties, Medical magnetic resonance imaging, Numerical modeling, Paramagnetism, Static magnetic fields, Static magnetic susceptibility, biomedical MRI, instruments, magnetic fields, magnetic susceptibility, modelling, navigation, needle localization, needle tip artifact, needle visualization, paramagnetism},
	pages = {579--587}
}

@article{muller-bierl_numerical_2004-1,
	title = {Numerical modeling of needle tip artifacts in {MR} gradient echo imaging},
	volume = {31},
	issn = {0094-2405},
	doi = {10.1118/1.1640971},
	abstract = {Exact determination of needle tip position is obsolete for interventional procedures under control of magnetic resonance imaging (MRI). Exact needle tip navigation is complicated by the paramagnetism of microsurgical instruments: Local magnetic field inhomogeneities are induced resulting in position encoding artifacts and in signal voids in the surrounding of instruments and especially near their tips. The artifacts generated by the susceptibility of the material are not only dependent on the material properties themselves and on the applied MRI sequences and parameters, but also on the geometric shape of the instruments and on the orientation to the static magnetic field in the MR unit. A numerical model based on superposition of induced elementary dipole fields was developed for studying the field distortions near paramagnetic needle tips. The model was validated by comparison with experimental data using field mapping MRI techniques. Comparison between experimental data and numerical simulations revealed good correspondence for the induced field inhomogeneities. Further systematic numerical studies of the field distribution were performed for variable types of concentric and asymmetric tip shapes, for different ratios between tip length and needle diameter, and for different orientations of the needle axis in the external static magnetic field. Based on the computed local inhomogeneities of the magnetic field in the surroundings of the needle tips, signal voids in usual gradient echo images were simulated for a prediction of the artifacts. The practically relevant spatial relation between those artifacts and the hidden tip of the needle was calculated for the different tip shapes and orientations in the external field. As needle tip determination is crucial in interventional procedures, e.g., in taking biopsies, the present model can help to instruct the physician prior to surgical interventions in better estimating the needle tip position for different orientations and needle tip shapes as they appear in interventional procedures. As manufacturing prototypes with subsequent measurements of artifacts in MRI are a costly procedure the presented model may also help to optimize shapes of needle tips and of other parts of MR-compatible instruments and implants with low expense prior to production if some shape parameters can be chosen freely.},
	language = {eng},
	number = {3},
	journal = {Medical Physics},
	author = {Müller-Bierl, Bernd and Graf, Hansjörg and Lauer, Ulrike and Steidle, Günter and Schick, Fritz},
	month = mar,
	year = {2004},
	pmid = {15070257},
	keywords = {Artifacts, Biopsy, Echo-Planar Imaging, Image Processing, Computer-Assisted, Magnetics, Models, Theoretical, Needles, Phantoms, Imaging, Software},
	pages = {579--587}
}

@inproceedings{moreira_towards_2017,
	title = {Towards {MRI}-guided flexible needle steering using fiber {Bragg} grating-based tip tracking},
	doi = {10.1109/ICRA.2017.7989564},
	abstract = {The use of magnetic resonance (MR) images for needle-based interventions offers several advantages over other types of imaging modalities (e.g., high tissue contrast and no radiation). However, MR-guided interventions face challenges related to electromagnetic compatibility of medical devices and real-time tracking of surgical instruments. This work presents a flexible needle steering system that combines an MR-compatible robot and a Fiber Bragg Grating (FBG)-based needle tip tracker. The MR images are used to localize obstacles and targets, while the FBG sensors provide strain measurements for online estimation of the needle tip position. A pre-operative planner defines the needle entry point and desired path, while a model predictive controller calculates the needle rotation during the insertion. To the best of the authors knowledge, this is the first work that fuses MR images and FBG-based tracking to steer a flexible needle in closed-loop inside the MR bore. The system is validated by steering a bevel-tipped flexible needle towards a physical target in gelatin phantoms and biological tissues. The needle reaches the target in all trials with an average targeting error of 2.76 mm. Disregarding the target displacement during the insertion, the average targeting error drops to 1.74 mm. The preliminary results demonstrate the feasibility of combining MR images and FBG-based needle tip tracking to steer a flexible needle in clinical procedures. In order to move towards to a clinically-relevant application, the design of a flexible Nitinol biopsy needle is also presented and evaluated by experiments in a prostate of a bull. The flexible needle presented a curvature 2.5 times larger than a conventional biopsy needle while maintaining the ability to collect tissue samples.},
	booktitle = {2017 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Moreira, P. and Boskma, K. J. and Misra, S.},
	month = may,
	year = {2017},
	keywords = {Biopsy, Bragg gratings, FBG sensors, FBG-based needle tip tracker, Fiber gratings, MR-compatible robot, MRI-guided flexible needle steering, Needles, Robots, Sensors, Target tracking, bevel-tipped flexible needle, biological tissues, biomedical MRI, fiber Bragg grating-based tip tracking, flexible Nitinol biopsy needle, gelatin phantoms, image fusion, magnetic resonance images, medical device electromagnetic compatibility, medical image processing, medical robotics, model predictive controller, needle tip position online estimation, needles, object tracking, optical fibres, predictive control, preoperative planner, robot vision, strain measurement, strain measurements, surgical instrument real-time tracking},
	pages = {4849--4854}
}

@article{garrido-jurado_automatic_2014,
	title = {Automatic generation and detection of highly reliable fiducial markers under occlusion},
	volume = {47},
	issn = {0031-3203},
	url = {http://www.sciencedirect.com/science/article/pii/S0031320314000235},
	doi = {10.1016/j.patcog.2014.01.005},
	abstract = {This paper presents a fiducial marker system specially appropriated for camera pose estimation in applications such as augmented reality and robot localization. Three main contributions are presented. First, we propose an algorithm for generating configurable marker dictionaries (in size and number of bits) following a criterion to maximize the inter-marker distance and the number of bit transitions. In the process, we derive the maximum theoretical inter-marker distance that dictionaries of square binary markers can have. Second, a method for automatically detecting the markers and correcting possible errors is proposed. Third, a solution to the occlusion problem in augmented reality applications is shown. To that aim, multiple markers are combined with an occlusion mask calculated by color segmentation. The experiments conducted show that our proposal obtains dictionaries with higher inter-marker distances and lower false negative rates than state-of-the-art systems, and provides an effective solution to the occlusion problem.},
	number = {6},
	urldate = {2017-11-26TZ},
	journal = {Pattern Recognition},
	author = {Garrido-Jurado, S. and Muñoz-Salinas, R. and Madrid-Cuevas, F. J. and Marín-Jiménez, M. J.},
	month = jun,
	year = {2014},
	keywords = {Augmented reality, Computer vision, Fiducial marker},
	pages = {2280--2292}
}

@inproceedings{langguth_shading-aware_2016,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Shading-{Aware} {Multi}-view {Stereo}},
	isbn = {978-3-319-46486-2 978-3-319-46487-9},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-46487-9_29},
	doi = {10.1007/978-3-319-46487-9_29},
	abstract = {We present a novel multi-view reconstruction approach that effectively combines stereo and shape-from-shading energies into a single optimization scheme. Our method uses image gradients to transition between stereo-matching (which is more accurate at large gradients) and Lambertian shape-from-shading (which is more robust in flat regions). In addition, we show that our formulation is invariant to spatially varying albedo without explicitly modeling it. We show that the resulting energy function can be optimized efficiently using a smooth surface representation based on bicubic patches, and demonstrate that this algorithm outperforms both previous multi-view stereo algorithms and shading based refinement approaches on a number of datasets.},
	language = {en},
	urldate = {2017-11-14TZ},
	booktitle = {Computer {Vision} – {ECCV} 2016},
	publisher = {Springer, Cham},
	author = {Langguth, Fabian and Sunkavalli, Kalyan and Hadap, Sunil and Goesele, Michael},
	month = oct,
	year = {2016},
	pages = {469--485}
}

@misc{langguth_smvs:_2017,
	title = {smvs: {Shading}-aware {Multi}-view {Stereo}},
	copyright = {BSD-3-Clause},
	shorttitle = {smvs},
	url = {https://github.com/flanggut/smvs},
	urldate = {2017-11-14TZ},
	author = {Langguth, Fabian},
	month = nov,
	year = {2017},
	note = {original-date: 2016-07-12T13:11:02Z}
}

@misc{pfalkingham_trying_2016,
	title = {Trying all the free {Photogrammetry}!},
	url = {https://pfalkingham.wordpress.com/2016/09/14/trying-all-the-free-photogrammetry/},
	abstract = {In which I tried – and failed – to document pros and cons for about a million different combinations of software.},
	urldate = {2017-11-14TZ},
	journal = {Dr Peter L. Falkingham},
	author = {{pfalkingham}},
	month = sep,
	year = {2016}
}

@inproceedings{muller_calibration_2014,
	title = {Calibration and 3D ground truth data generation with orthogonal camera-setup and refraction compensation for aquaria in real-time},
	volume = {3},
	abstract = {In this paper we present a novel approach to generate precise 3D ground-truth data considering the refraction of the fish tank. We used an accurate and easy-to-handle calibration method to calibrate two orthogonally aligned high-resolution cameras in real-time. For precise fish shape segmentation we combined two different background subtraction algorithms, which can also be trained while fish are swimming inside the aquarium. The presented approach takes also shadow segmentation removal and mirroring into account. For refraction compensation at the air-water border we developed an algorithm which calculates the ray-deflection of every shape-pixel and compute the 3D-model in real-time.},
	booktitle = {2014 {International} {Conference} on {Computer} {Vision} {Theory} and {Applications} ({VISAPP})},
	author = {Müller, K. and Schlemper, J. and Kuhnert, L. and Kuhnert, K. D.},
	month = jan,
	year = {2014},
	keywords = {3D-model, Calibration, Cameras, Computational modeling, Computer vision, Fish Tank, Real-time systems, Refraction, Segmentation, Three-dimensional displays, Tracking, Vision},
	pages = {626--634}
}

@article{shah_keypoints-based_2017,
	title = {Keypoints-based surface representation for 3D modeling and 3D object recognition},
	volume = {64},
	issn = {0031-3203},
	url = {http://www.sciencedirect.com/science/article/pii/S0031320316303429},
	doi = {10.1016/j.patcog.2016.10.028},
	abstract = {The three-dimensional (3D) modeling and recognition of 3D objects have been traditionally performed using local features to represent the underlying 3D surface. Extraction of features requires cropping of several local surface patches around detected keypoints. Although an important step, the extraction and representation of such local patches adds to the computational complexity of the algorithms. This paper proposes a novel Keypoints-based Surface Representation (KSR) technique. The proposed technique has the following two characteristics: (1) It does not rely on the computation of features on a small surface patch cropped around a detected keypoint. Rather, it exploits the geometrical relationship between the detected 3D keypoints for local surface representation. (2) KSR is computationally efficient, requiring only seconds to process 3D models with over 50,000 points with a MATLAB implementation. Experimental results on the UWA and Stanford 3D models dataset suggest that it can accurately perform pairwise and multiview range image registration (3D modeling). KSR was also tested for 3D object recognition with occluded scenes. Recognition results on the UWA dataset show that the proposed technique outperforms existing methods including 3D-Tensor, VD-LSD, keypoint-depth based feature, spherical harmonics and spin image with a recognition rate of 95.9\%. The proposed approach also achieves a recognition rate of 93.5\% on the challenging Ca'Fascori dataset compared to 92.5\% achieved by game-theoretic. The proposed method is computationally efficient compared to state-of-the-art local feature methods.},
	number = {Supplement C},
	urldate = {2017-10-26TZ},
	journal = {Pattern Recognition},
	author = {Shah, Syed Afaq Ali and Bennamoun, Mohammed and Boussaid, Farid},
	month = apr,
	year = {2017},
	keywords = {3D Object recognition, 3D modeling, Keypoints, Range images},
	pages = {29--38}
}

@inproceedings{farneback_two-frame_2003,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Two-{Frame} {Motion} {Estimation} {Based} on {Polynomial} {Expansion}},
	isbn = {978-3-540-40601-3 978-3-540-45103-7},
	url = {https://link.springer.com/chapter/10.1007/3-540-45103-X_50},
	doi = {10.1007/3-540-45103-X_50},
	abstract = {This paper presents a novel two-frame motion estimation algorithm. The first step is to approximate each neighborhood of both frames by quadratic polynomials, which can be done efficiently using the polynomial expansion transform. From observing how an exact polynomial transforms under translation a method to estimate displacement fields from the polynomial expansion coefficients is derived and after a series of refinements leads to a robust algorithm. Evaluation on the Yosemite sequence shows good results.},
	language = {en},
	urldate = {2017-10-26TZ},
	booktitle = {Image {Analysis}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Farnebäck, Gunnar},
	month = jun,
	year = {2003},
	keywords = {OpenCV, dense optical flow},
	pages = {363--370}
}

@article{presti_prostate_2000,
	title = {Prostate cancer: assessment of risk using digital rectal examination, tumor grade, prostate-specific antigen, and systematic biopsy},
	volume = {38},
	issn = {0033-8389},
	shorttitle = {Prostate cancer},
	abstract = {Refinement in the local staging and risk assessment for prostate cancer patients utilizing clinical parameters is ongoing. DRE, tumor grade, and PSA provide some useful information for risk assessment in individual patients. More recent studies using percent free PSA levels and systematic biopsy results have added additional staging information and may play a more significant role in the future in risk assessment. This information should supplement additional imaging tests in the management of these patients.},
	language = {eng},
	number = {1},
	journal = {Radiologic Clinics of North America},
	author = {Presti, J. C.},
	month = jan,
	year = {2000},
	pmid = {10664666},
	keywords = {Biopsy, Needle, Diagnostic Imaging, Humans, Male, Neoplasm Staging, Physical Examination, Prostate-Specific Antigen, Prostatic Neoplasms, Risk Assessment},
	pages = {49--58}
}

@incollection{haug_sensor_2012,
	title = {Sensor {Fusion} {Using} {Photogrammetric} and {Inertial} {Measurements}},
	copyright = {Copyright © 2012 John Wiley \& Sons, Inc.},
	isbn = {978-1-118-28779-8},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/9781118287798.ch20/summary},
	abstract = {This chapter contains sections titled:

* Introduction
* The Process (Dynamic) Model for Rigid Body Motion
* The Sensor Fusion Observational Model
* The Generation of Synthetic Data
* Estimation Methods
* Performance Comparison Analysis
* Conclusions
* Future Work
* References},
	language = {en},
	urldate = {2017-10-25TZ},
	booktitle = {Bayesian {Estimation} and {Tracking}},
	publisher = {John Wiley \& Sons, Inc.},
	author = {Haug, Anton J.},
	year = {2012},
	doi = {10.1002/9781118287798.ch20},
	keywords = {IMU, linear accelerations, process model for rigid body motion, sensor fusion observational, accuracy over photogrammetry/IMU-based, sensor fusion to photogrammetry and IMU analysis, and fault tolerance, sensor fusion, photogrammetric and IMU, images from multiple cameras},
	pages = {346--365}
}

@article{guidi_fusion_2003,
	title = {Fusion of range camera and photogrammetry: a systematic procedure for improving 3-{D} models metric accuracy},
	volume = {33},
	issn = {1083-4419},
	shorttitle = {Fusion of range camera and photogrammetry},
	doi = {10.1109/TSMCB.2003.814282},
	abstract = {The generation of three-dimensional (3-D) digital models produced by optical technologies in some cases involves metric errors. This happens when small high-resolution 3-D images are assembled together in order to model a large object. In some applications, as for example 3-D modeling of Cultural Heritage, the problem of metric accuracy is a major issue and no methods are currently available for enhancing it. The authors present a procedure by which the metric reliability of the 3-D model, obtained through iterative alignments of many range maps, can be guaranteed to a known acceptable level. The goal is the integration of the 3-D range camera system with a close range digital photogrammetry technique. The basic idea is to generate a global coordinate system determined by the digital photogrammetric procedure, measuring the spatial coordinates of optical targets placed around the object to be modeled. Such coordinates, set as reference points, allow the proper rigid motion of few key range maps, including a portion of the targets, in the global reference system defined by photogrammetry. The other 3-D images are normally aligned around these locked images with usual iterative algorithms. Experimental results on an anthropomorphic test object, comparing the conventional and the proposed alignment method, are finally reported.},
	number = {4},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
	author = {Guidi, G. and Beraldin, J. A. and Ciofi, S. and Atzeni, C.},
	month = aug,
	year = {2003},
	keywords = {3D image alignment, 3D model metric accuracy, 3D modeling, 3D range camera system, Assembly, Coordinate measuring machines, Councils, Cultural Heritage, Cultural differences, Digital cameras, Fusion power generation, Laser modes, Optical sensors, Shape measurement, Three dimensional displays, anthropomorphic test object, cameras, close range digital photogrammetry, computer vision, error analysis, experimental results, global coordinate system, high-resolution 3D images, image matching, image resolution, iterative algorithms, iterative alignments, photogrammetry, range camera, range maps, sensor fusion, solid modelling, three-dimensional digital model generation},
	pages = {667--676}
}

@article{guidi_fusion_2003-1,
	title = {Fusion of range camera and photogrammetry: a systematic procedure for improving 3-{D} models metric accuracy},
	volume = {33},
	issn = {1083-4419},
	shorttitle = {Fusion of range camera and photogrammetry},
	doi = {10.1109/TSMCB.2003.814282},
	abstract = {The generation of three-dimensional (3-D) digital models produced by optical technologies in some cases involves metric errors. This happens when small high-resolution 3-D images are assembled together in order to model a large object. In some applications, as for example 3-D modeling of Cultural Heritage, the problem of metric accuracy is a major issue and no methods are currently available for enhancing it. The authors present a procedure by which the metric reliability of the 3-D model, obtained through iterative alignments of many range maps, can be guaranteed to a known acceptable level. The goal is the integration of the 3-D range camera system with a close range digital photogrammetry technique. The basic idea is to generate a global coordinate system determined by the digital photogrammetric procedure, measuring the spatial coordinates of optical targets placed around the object to be modeled. Such coordinates, set as reference points, allow the proper rigid motion of few key range maps, including a portion of the targets, in the global reference system defined by photogrammetry. The other 3-D images are normally aligned around these locked images with usual iterative algorithms. Experimental results on an anthropomorphic test object, comparing the conventional and the proposed alignment method, are finally reported.},
	number = {4},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
	author = {Guidi, G. and Beraldin, J. A. and Ciofi, S. and Atzeni, C.},
	month = aug,
	year = {2003},
	keywords = {3D image alignment, 3D model metric accuracy, 3D modeling, 3D range camera system, Assembly, Coordinate measuring machines, Councils, Cultural Heritage, Cultural differences, Digital cameras, Fusion power generation, Laser modes, Optical sensors, Shape measurement, Three dimensional displays, anthropomorphic test object, cameras, close range digital photogrammetry, computer vision, error analysis, experimental results, global coordinate system, high-resolution 3D images, image matching, image resolution, iterative algorithms, iterative alignments, photogrammetry, range camera, range maps, sensor fusion, solid modelling, three-dimensional digital model generation},
	pages = {667--676}
}

@article{wartenberg_closed-loop_2017,
	title = {Closed-loop {Autonomous} {Needle} {Steering} during {Cooperatively} {Controlled} {Needle} {Insertions} for {MRI}-guided {Pelvic} {Interventions}},
	abstract = {We introduce a robotic system configured for autonomous closed-loop needle steering during hands-on cooperatively controlled robotic needle insertion. Needle placement is performed using a 6-DOF robotic system suitable for the MR environment.},
	author = {Wartenberg, Marek and Schornak, Joseph and Carvalho, Paulo and Patel, Niravkumar and Iorachita, Iulian and Tempany, Clare and Hata, Nobuhiko and Tokuda, Junichi and Fischer, Gregory},
	year = {2017}
}

@article{wartenberg_development_2017,
	title = {Development and {Evaluation} of a {Cooperatively} {Controlled} {Robotic} {Needle} {Driver} for {MRI}-guided {Pelvic} {Interventions}},
	abstract = {Needle-based percutaneous pelvic interventions often require multiple insertion attempts to reach sufficient targeting accuracy. Repeated needle insertions lead to lengthened
procedure time, increased cost and unnecessary discomfort to
the patient. An actuated needle driver suitable for the MR
environment was developed and evaluated herein. It is config-
ured for hands-on cooperative control of needle insertion under
real-time MR imaging, also capable of active compensation
of deflections from the intended insertion path through au-
tonomous bevel tipped needle rotation. Cooperatively controlled
needle insertions were performed into multi-layered phantoms
under real-time MR imaging. User input and needle forces
were captured to evaluate the cooperative insertion architecture,
where needle insertion velocity was shown to be a function of
the two. Additionally, transitions between phantom layers can
be easily detected. Furthermore, needle rotation was performed
under real-time MR imaging showing active compensation can
be performed during continuous cooperative insertions. Finally,
the robot’s effect on signal-to-noise ratio (SNR) was performed
with maximum signal loss less than 16\% in a single worst case,
and less than 3\% in all others.},
	author = {Wartenberg, Marek and Carvalho, Paulo and Patel, Niravkumar and Nycz, Chris and Iordachita, Iulian and Tempany, Clare and Hata, Nobuhiko and Tokuda, Junichi and Fischer, Gregory S.},
	year = {2017},
	keywords = {AIM Lab, needle insertion robot}
}

@article{dietrich_measurement_2007,
	title = {Measurement of signal-to-noise ratios in {MR} images: {Influence} of multichannel coils, parallel imaging, and reconstruction filters},
	volume = {26},
	issn = {1522-2586},
	shorttitle = {Measurement of signal-to-noise ratios in {MR} images},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/jmri.20969/abstract},
	doi = {10.1002/jmri.20969},
	abstract = {Purpose
To evaluate the validity of different approaches to determine the signal-to-noise ratio (SNR) in MRI experiments with multi-element surface coils, parallel imaging, and different reconstruction filters.
Materials and Methods
Four different approaches of SNR calculation were compared in phantom measurements and in vivo based on: 1) the pixel-by-pixel standard deviation (SD) in multiple repeated acquisitions; 2) the signal statistics in a difference image; and 3) and 4) the statistics in two separate regions of a single image employing either the mean value or the SD of background noise. Different receiver coil systems (with one and eight channels), acquisitions with and without parallel imaging, and five different reconstruction filters were compared.
Results
Averaged over all phantom measurements, the deviations from the reference value provided by the multiple-acquisitions method are 2.7\% (SD 1.6\%) for the difference method, 37.7\% (25.9\%) for the evaluation of the mean value of background noise, and 34.0\% (38.1\%) for the evaluation of the SD of background noise.
Conclusion
The conventionally determined SNR based on separate signal and noise regions in a single image will in general not agree with the true SNR measured in images after the application of certain reconstruction filters, multichannel reconstruction, or parallel imaging. J. Magn. Reson. Imaging 2007. © 2007 Wiley-Liss, Inc.},
	language = {en},
	number = {2},
	urldate = {2017-10-24TZ},
	journal = {Journal of Magnetic Resonance Imaging},
	author = {Dietrich, Olaf and Raya, José G. and Reeder, Scott B. and Reiser, Maximilian F. and Schoenberg, Stefan O.},
	month = aug,
	year = {2007},
	keywords = {MR imaging, image analysis, parallel imaging, postprocessing filters, signal-to-noise ratio},
	pages = {375--385}
}

@article{abayazid_integrating_2013,
	title = {Integrating {Deflection} {Models} and {Image} {Feedback} for {Real}-{Time} {Flexible} {Needle} {Steering}},
	volume = {29},
	issn = {1552-3098},
	doi = {10.1109/TRO.2012.2230991},
	abstract = {Needle insertion procedures are commonly used for diagnostic and therapeutic purposes. In this paper, an image-guided control system is developed to robotically steer flexible needles with an asymmetric tip. Knowledge about needle deflection is required for accurate steering. Two different models to predict needle deflection are presented. The first is a kinematics-based model, and the second model predicts needle deflection that is based on the mechanics of needle-tissue interaction. Both models predict deflection of needles that undergo multiple bends. The maximum targeting errors of the kinematics-based and the mechanics-based models for 110-mm insertion distance using a φ 0.5-mm needle are 0.8 and 1.7 mm, respectively. The kinematics-based model is used in the proposed image-guided control system. The control system accounts for target motion during the insertion procedure by detecting the target position in each image frame. Five experimental cases are presented to validate the real-time control system using both camera and ultrasound images as feedback. The experimental results show that the targeting errors of camera and ultrasound image-guided steering toward a moving target are 0.35 and 0.42 mm, respectively. The targeting accuracy of the algorithm is sufficient to reach the smallest lesions (φ 2 mm) that can be detected using the state-of-the-art ultrasound imaging systems.},
	number = {2},
	journal = {IEEE Transactions on Robotics},
	author = {Abayazid, M. and Roesthuis, R. J. and Reilink, R. and Misra, S.},
	month = apr,
	year = {2013},
	keywords = {Computer-assisted surgery, Force, Needles, Predictive models, Real-time systems, Shape, Target tracking, Ultrasonic imaging, asymmetric tip, biological tissues, biomedical ultrasonics, camera, cameras, deflection model integration, distance 110 mm, feedback, image feedback, image guided control system, image-guided control, kinematics-based model, lesions, mechanics-based model, medical image processing, medical robotics, minimally invasive surgery, needle deflection, needle insertion procedure, needle-tissue interaction mechanics, needles, needle–tissue interactions, object detection, patient diagnosis, patient therapy, robotically steer flexible needle, size 0.35 mm, size 0.42 mm, size 0.8 mm, size 1.7 mm, steering systems, target position detection, ultrasonic imaging, ultrasound, ultrasound image guided steering, ultrasound imaging system},
	pages = {542--553}
}

@article{futterer_mri_2010,
	title = {{MRI} of the prostate: potential role of robots},
	volume = {2},
	issn = {1755-5191},
	shorttitle = {{MRI} of the prostate},
	url = {https://research.utwente.nl/en/publications/mri-of-the-prostate-potential-role-of-robots},
	doi = {10.2217/iim.10.46},
	language = {Undefined},
	number = {5},
	urldate = {2017-10-24TZ},
	journal = {Imaging in medicine},
	author = {Fütterer, Jurgen J. and Misra, Sarthak and Macura, Katarzyna J.},
	month = oct,
	year = {2010},
	pages = {583--592}
}
@article{troccaz_guiding_1998,
	title = {Guiding systems for computer-assisted surgery: introducing synergistic devices and discussing the different approaches},
	volume = {2},
	issn = {1361-8415},
	shorttitle = {Guiding systems for computer-assisted surgery},
	url = {http://www.sciencedirect.com/science/article/pii/S1361841598800066},
	doi = {10.1016/S1361-8415(98)80006-6},
	abstract = {Computer-assisted surgery (CAS) or computer-assisted therapy (CAT) attempt primarily to optimize the performance of medical tasks. CAS systems include a guiding system to connect the information world of data and plans to the physical world of surgeons, patients and instruments, and to supplement the surgeon's perception and dexterity. Passive, semi-active and active systems have been proposed and implemented in various clinical applications. In this paper we introduce synergistic devices which are an extension of semi-active systems. We also discuss the advantages of the different categories of guiding systems on the basis of a list of task-oriented and user-oriented qualitative factors.},
	number = {2},
	urldate = {2017-10-24TZ},
	journal = {Medical Image Analysis},
	author = {Troccaz, Jocelyne and Peshkin, Michael and Davies, Brian},
	month = jun,
	year = {1998},
	keywords = {computer-assisted surgery, guiding systems, medical robotics, synergistic devices},
	pages = {101--119}
}

@inproceedings{roesthuis_modeling_2015,
	title = {Modeling and steering of a novel actuated-tip needle through a soft-tissue simulant using {Fiber} {Bragg} {Grating} sensors},
	doi = {10.1109/ICRA.2015.7139502},
	abstract = {Needle insertions are common during surgical procedures. Accurately delivering the needle at a specific location in the human body is of importance for the clinical outcome of the procedure. Studies have already shown that robotically inserting traditional needles with a bevel tip can improve targeting accuracy. However, steering of such needles requires spinning the needle, which may lead to additional tissue damage. Therefore, we propose a novel design consisting of a flexible needle with a tendon-driven actuated-tip. Changing the orientation of the actuated-tip allows to control the steering direction of the needle and the amount of deflection. We derive the kinematic model which describes the needle path given the actuated-tip orientation based on nonholonomic kinematics. We present a method for steering the needle towards a target location in soft tissue. This method incorporates online parameter estimation in order to adapt for changes in tissue stiffness. Needle insertion experiments are performed in soft-tissue simulants, made from porcine gelatin. Needle tip pose is measured during insertion using Fiber Bragg Grating (FBG) based shape reconstruction. Results show that the needle can be steered towards targets located at 20 mm from the initial insertion axis, at a depth of 100 mm with a mean targeting error of 2.02 mm.},
	booktitle = {2015 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Roesthuis, R. J. and Berg, N. J. van de and Dobbelsteen, J. J. van den and Misra, S.},
	month = may,
	year = {2015},
	keywords = {Biological tissues, Bragg gratings, Fiber gratings, Needles, Parameter estimation, Sensors, Shape, actuated-tip needle, fiber Bragg grating sensors, flexible needle, medical robotics, mobile robots, needle insertions, needle tip pose, nonholonomic kinematics, online parameter estimation, optical fibres, parameter estimation, porcine gelatin, robot kinematics, shape reconstruction, soft-tissue simulant, steering direction, surgical procedures, tendon-driven actuated-tip},
	pages = {2283--2289}
}

@article{patil_needle_2014,
	title = {Needle {Steering} in 3-{D} {Via} {Rapid} {Replanning}},
	volume = {30},
	issn = {1552-3098},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4244660/},
	doi = {10.1109/TRO.2014.2307633},
	abstract = {Steerable needles have the potential to improve the effectiveness of needle-based clinical procedures such as biopsy and drug delivery by improving targeting accuracy and reaching previously inaccessible targets that are behind sensitive or impenetrable anatomical regions. We present a new needle steering system capable of automatically reaching targets in 3-D environments while avoiding obstacles and compensating for real-world uncertainties. Given a specification of anatomical obstacles and a clinical target (e.g., from preoperative medical images), our system plans and controls needle motion in a closed-loop fashion under sensory feedback to optimize a clinical metric. We unify planning and control using a new fast algorithm that continuously replans the needle motion. Our rapid replanning approach is enabled by an efficient sampling-based rapidly exploring random tree (RRT) planner that achieves orders-of-magnitude reduction in computation time compared with prior 3-D approaches by incorporating variable curvature kinematics and a novel distance metric for planning. Our system uses an electromagnetic tracking system to sense the state of the needle tip during the procedure. We experimentally evaluate our needle steering system using tissue phantoms and animal tissue ex vivo. We demonstrate that our rapid replanning strategy successfully guides the needle around obstacles to desired 3-D targets with an average error of less than 3 mm.},
	number = {4},
	urldate = {2017-10-24TZ},
	journal = {IEEE transactions on robotics : a publication of the IEEE Robotics and Automation Society},
	author = {Patil, Sachin and Burgner, Jessica and Webster, Robert J. and Alterovitz, Ron},
	month = aug,
	year = {2014},
	pmid = {25435829},
	pmcid = {PMC4244660},
	pages = {853--864}
}

@inproceedings{ayvali_accurate_2014,
	title = {Accurate in-plane and out-of-plane ultrasound-based tracking of the discretely actuated steerable cannula},
	doi = {10.1109/ICRA.2014.6907727},
	abstract = {Discretely actuated steerable cannula is a multi-degree-of-freedom hollow needle (cannula) that could potentially be used in needle-based procedures to deliver therapeutic and diagnostic tools to a target region through its hollow inner core. Needle-based procedures are commonly performed using intra-operative image guidance. 2D ultrasound is one of the most commonly used imaging modalities in clinics. It is portable, inexpensive and free of ionizing radiation. The success of the needle-based procedures depends on accurate detection of the needle. The accuracy of the out-of-plane detection, where the ultrasound transducer is placed at a right angle to the long-axis of the needle, depends on the ultrasound beam width. Finite width of the ultrasound beam and uniform cross-section of the needle introduce errors in tracking. The accuracy of in-plane tracking depends on the tracking algorithm used and the spatial resolution of the ultrasound transducer. This work presents a method to quantify the finite ultrasound beam width and the spatial accuracy of the transducer. An out-of-plane detection method was implemented to locate the tip of the discretely actuated steerable cannula. An in-plane tracking algorithm based on optical flow was also developed to obtain the shape of a planar cannula. The algorithms and the methods developed in this work are general and they can be extended to needles having straight, curved and arbitrary shapes.},
	booktitle = {2014 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Ayvali, E. and Desai, J. P.},
	month = may,
	year = {2014},
	keywords = {2D ultrasound, Accuracy, Brightness, Imaging, Needles, Rails, Transducers, Ultrasonic imaging, biomedical equipment, biomedical ultrasonics, diagnostic tool, discretely actuated steerable cannula, finite ultrasound beam width, finite width, imaging modality, in-plane tracking algorithm, in-plane ultrasound-based tracking, intra-operative image guidance, ionizing radiation, medical signal detection, multidegree-of-freedom hollow needle, needle detection, needle-based procedures, needles, optical flow, out-of-plane detection method, out-of-plane ultrasound-based tracking, planar cannula, spatial accuracy, spatial resolution, therapeutic tool, ultrasonic transducers, ultrasound transducer},
	pages = {5896--5901}
}

@article{engh_percutaneous_2010,
	title = {Percutaneous {Intracerebral} {Navigation} by {Duty}-{Cycled} {Spinning} of {Flexible} {Bevel}-{Tipped} {Needles}},
	volume = {67},
	issn = {0148-396X},
	url = {https://academic.oup.com/neurosurgery/article/67/4/1117/2556761/Percutaneous-Intracerebral-Navigation-by-Duty},
	doi = {10.1227/NEU.0b013e3181ec1551},
	abstract = {BACKGROUND:Intracerebral drug delivery using surgically placed microcatheters is a growing area of interest for potential treatment of a wide variety of neurological diseases, including tumors, neurodegenerative disorders, trauma, epilepsy, and stroke. Current catheter placement techniques are limited to straight trajectories. The development of an inexpensive system for flexible percutaneous intracranial navigation may be of significant clinical benefit.OBJECTIVE:Utilizing duty-cycled spinning of a flexible bevel-tipped needle, the authors devised and tested a means of achieving nonlinear trajectories for the navigation of catheters in the brain, which may be applicable to a wide variety of neurological diseases.METHODS:Exploiting the bending tendency of bevel-tipped needles due to their asymmetry, the authors devised and tested a means of generating curvilinear trajectories by spinning a needle with a variable duty cycle (ie, in on-off fashion). The technique can be performed using image guidance, and trajectories can be adjusted intraoperatively via joystick. Fifty-eight navigation trials were performed during cadaver testing to demonstrate the efficacy of the needle-steering system and to test its precision.RESULTS:The needle-steering system achieved a target acquisition error of 2 ± 1 mm, while demonstrating the ability to reach multiple targets from one burr hole using trajectories of varying curvature.CONCLUSION:The accuracy of the needle-steering system was demonstrated in a cadaveric model. Future studies will determine the safety of the device in vivo.},
	number = {4},
	urldate = {2017-10-24TZ},
	journal = {Neurosurgery},
	author = {Engh, Johnathan A. and Minhas, Davneet S. and Kondziolka, Douglas and Riviere, Cameron N.},
	month = oct,
	year = {2010},
	pages = {1117--1123}
}

@article{vrooijink_needle_2014,
	title = {Needle path planning and steering in a three-dimensional non-static environment using two-dimensional ultrasound images},
	volume = {33},
	issn = {0278-3649},
	url = {https://doi.org/10.1177/0278364914526627},
	doi = {10.1177/0278364914526627},
	abstract = {Needle insertion is commonly performed in minimally invasive medical procedures such as biopsy and radiation cancer treatment. During such procedures, accurate needle tip placement is critical for correct diagnosis or successful treatment. Accurate placement of the needle tip inside tissue is challenging, especially when the target moves and anatomical obstacles must be avoided. We develop a needle steering system capable of autonomously and accurately guiding a steerable needle using two-dimensional (2D) ultrasound images. The needle is steered to a moving target while avoiding moving obstacles in a three-dimensional (3D) non-static environment. Using a 2D ultrasound imaging device, our system accurately tracks the needle tip motion in 3D space in order to estimate the tip pose. The needle tip pose is used by a rapidly exploring random tree-based motion planner to compute a feasible needle path to the target. The motion planner is sufficiently fast such that replanning can be performed repeatedly in a closed-loop manner. This enables the system to correct for perturbations in needle motion, and movement in obstacle and target locations. Our needle steering experiments in a soft-tissue phantom achieves maximum targeting errors of 0.86 ± 0.35 mm (without obstacles) and 2.16 ± 0.88 mm (with a moving obstacle).},
	language = {en},
	number = {10},
	urldate = {2017-10-24TZ},
	journal = {The International Journal of Robotics Research},
	author = {Vrooijink, Gustaaf J. and Abayazid, Momen and Patil, Sachin and Alterovitz, Ron and Misra, Sarthak},
	month = sep,
	year = {2014},
	pages = {1361--1374}
}

@article{reed_robot-assisted_2011,
	title = {Robot-{Assisted} {Needle} {Steering}},
	volume = {18},
	issn = {1070-9932},
	doi = {10.1109/MRA.2011.942997},
	abstract = {Needle insertion is a critical aspect of many medical treatments, diagnostic methods, and scientific studies, and is considered to be one of the simplest and most minimally invasive medical procedures. Robot-assisted needle steering has the potential to improve the effectiveness of existing medical procedures and enable new ones by allowing increased accuracy through more dexterous control of the needle-tip path and acquisition of targets not accessible by straight-line trajectories. In this article, we describe a robot-assisted needle-steering system that uses three integrated controllers: a motion planner concerned with guiding the needle around obstacles to a target in a desired plane, a planar controller that maintains the needle in the desired plane, and a torsion compensator that controls the needle-tip orientation about the axis of the needle shaft.},
	number = {4},
	journal = {IEEE Robotics Automation Magazine},
	author = {Reed, K. B. and Majewicz, A. and Kallem, V. and Alterovitz, R. and Goldberg, K. and Cowan, N. J. and Okamura, A. M.},
	month = dec,
	year = {2011},
	keywords = {Biomedical imaging, Cameras, Force, Needles, Planning, Robots, Shafts, collision avoidance, compensation, medical diagnosis, medical robotics, medical treatment, minimally invasive medical procedure, motion control, motion planner, needle insertion, needle shaft, needle-tip orientation control, needle-tip path dexterous control, patient diagnosis, patient treatment, planar controller, robot-assisted needle steering, straight-line trajectory, torsion compensator},
	pages = {35--46}
}

@article{stoianovici_mri-safe_2013,
	title = {{MRI}-{Safe} {Robot} for {Endorectal} {Prostate} {Biopsy}},
	volume = {19},
	issn = {1083-4435},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4219418/},
	doi = {10.1109/TMECH.2013.2279775},
	abstract = {This paper reports the development of an MRI-Safe robot for direct (interventional) MRI-guided endorectal prostate biopsy. The robot is constructed of nonmagnetic and electrically nonconductive materials, and is electricity free, using pneumatic actuation and optical sensors. Targeting biopsy lesions of MRI abnormality presents substantial clinical potential for the management of prostate cancer., The paper describes MRI-Safe requirements, presents the kinematic architecture, design and construction of the robot, and a comprehensive set of preclinical tests for MRI compatibility and needle targeting accuracy. The robot has a compact and simple 3 degree-of-freedom (DoF) structure, two for orienting a needle-guide and one to preset the depth of needle insertion. The actual insertion is performed manually through the guide and up to the preset depth. To reduce the complexity and size of the robot next to the patient, the depth setting DoF is remote., Experimental results show that the robot is safe to use in any MRI environment (MRI-Safe). Comprehensive MRI tests show that the presence and motion of the robot in the MRI scanner cause virtually no image deterioration or signal to noise ratio (SNR) change. Robot’s accuracy in bench test, CT-guided in-vitro, MRI-guided in-vitro and animal tests are 0.37mm, 1.10mm, 2.09mm, and 2.58mm respectively. These values are acceptable for clinical use.},
	number = {4},
	urldate = {2017-10-24TZ},
	journal = {IEEE/ASME transactions on mechatronics : a joint publication of the IEEE Industrial Electronics Society and the ASME Dynamic Systems and Control Division},
	author = {Stoianovici, Dan and Kim, Chunwoo and Srimathveeravalli, Govindarajan and Sebrecht, Peter and Petrisor, Doru and Coleman, Jonathan and Solomon, Stephen B. and Hricak, Hedvig},
	month = sep,
	year = {2013},
	pmid = {25378897},
	pmcid = {PMC4219418},
	pages = {1289--1299}
}

@article{damico_transperineal_2000,
	title = {{TRANSPERINEAL} {MAGNETIC} {RESONANCE} {IMAGE} {GUIDED} {PROSTATE} {BIOPSY}},
	volume = {164},
	issn = {0022-5347},
	url = {http://www.sciencedirect.com/science/article/pii/S0022534705673661},
	doi = {10.1016/S0022-5347(05)67366-1},
	abstract = {We report the findings of a transperineal magnetic resonance image (MRI) guided biopsy of the prostate in a man with increasing prostate specific antigen who was not a candidate for a transrectal ultrasound guided biopsy. Using an open configuration 0.5 Tesla MRI scanner and pelvic coil, a random sextant sample was obtained under real time MRI guidance from the peripheral zone of the prostate gland as well as a single core from each MRI defined lesion. The patient had previously undergone proctocolectomy for ulcerative colitis and, therefore, was not a candidate for transrectal ultrasound guided biopsy. Prior attempts to make the diagnosis of prostate cancer using a transurethral approach were unsuccessful. The random sextant samples contained benign prostatic hyperplasia, whereas Gleason grade 3 + 3 = 6 adenocarcinoma was confirmed in 15\% and 25\% of the 2 cores obtained from the MRI targeted specimens of 2 defined lesions. The procedure was well tolerated by the patient. Transperineal MRI guided biopsy is a new technique that may be useful in detecting prostate cancer in men with increasing prostate specific antigen who are not candidates for transrectal ultrasound guided biopsy.},
	number = {2},
	urldate = {2017-10-24TZ},
	journal = {The Journal of Urology},
	author = {D’amico, A. V. and Tempany, C. M. and Cormack, R. and Hata, N. and Jinzaki, M. and Tuncali, K. and Weinstein, M. and Richie, J. P.},
	month = aug,
	year = {2000},
	keywords = {biopsy, magnetic resonance imaging, prostate, prostate-specific antigen, prostatic neoplasms},
	pages = {385--387}
}

@inproceedings{fazal_needle_2009,
	title = {Needle insertion forces for haptic feedback device},
	volume = {1},
	doi = {10.1109/ISIEA.2009.5356495},
	abstract = {This paper presents needle insertion forces for haptic feedback device in soft tissue. The force information from needle insertions is being measured by the sensor. The force feedback produced by the device can be used in robot-assisted percutaneous therapies. The objective of the work reported here is to design a device for reality-based data. Insertion force data was collected on chicken skin and meat. The needle insertion force is modeled in three parts; force due to capsule stiffness, friction and cutting. The data from model is compared with real time force data. From the simulation and experimental results, it is found out that the error between measured and modeled force converges.},
	booktitle = {2009 {IEEE} {Symposium} on {Industrial} {Electronics} {Applications}},
	author = {Fazal, I. and Karsiti, M. N.},
	month = oct,
	year = {2009},
	keywords = {Biological tissues, Force feedback, Force measurement, Force sensors, Friction, Haptic feedback, Haptic interfaces, Medical treatment, Needle insertion forces, Needles, Robot sensing systems, Skin, Tele-robotic surgery, biological tissues, biomechanics, biomedical equipment, capsule stiffness, chicken meat, chicken skin, cutting, cutting force, force feedback, force measurement, friction, friction force, haptic feedback device, haptic interfaces, medical robotics, medical supplies, needle insertion forces, needles, robot assisted percutaneous therapy, soft tissue, surgery, telerobotic surgery},
	pages = {20--22}
}

@article{okamura_force_2004,
	title = {Force modeling for needle insertion into soft tissue},
	volume = {51},
	issn = {0018-9294},
	doi = {10.1109/TBME.2004.831542},
	abstract = {The modeling of forces during needle insertion into soft tissue is important for accurate surgical simulation, preoperative planning, and intelligent robotic assistance for percutaneous therapies. We present a force model for needle insertion and experimental procedures for acquiring data from ex vivo tissue to populate that model. Data were collected from bovine livers using a one-degree-of-freedom robot equipped with a load cell and needle attachment. computed tomography imaging was used to segment the needle insertion process into phases identifying different relative velocities between the needle and tissue. The data were measured and modeled in three parts: 1) capsule stiffness, a nonlinear spring model; 2) friction, a modified Karnopp model; and 3) cutting, a constant for a given tissue. In addition, we characterized the effects of needle diameter and tip type on insertion force using a silicone rubber phantom. In comparison to triangular and diamond tips, a bevel tip causes more needle bending and is more easily affected by tissue density variations. Forces for larger diameter needles are higher due to increased cutting and friction forces.},
	number = {10},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Okamura, A. M. and Simone, C. and O'Leary, M. D.},
	month = oct,
	year = {2004},
	keywords = {Animals, Biological tissues, Biopsy, Needle, Bovine, Cattle, Computational modeling, Computed tomography, Computer Simulation, Connective Tissue, Elasticity, Friction, Hardness, Hardness Tests, Intelligent robots, Liver, Medical treatment, Models, Biological, Needles, Robotics, Stress, Mechanical, Surgery, Surgery, Computer-Assisted, Telemedicine, Transducers, Weight-Bearing, accurate surgical simulation, bevel needle tip, biological tissues, biomechanics, bovine livers, capsule stiffness, computed tomography imaging, computerised tomography, force modeling, friction, intelligent robotic assistance, intelligent robots, liver, medical robotics, modified Karnopp model, needle bending, needle insertion, needle model, nonlinear spring model, one-degree-of-freedom robot, percutaneous therapies, phantoms, physiological models, preoperative planning, silicone rubber phantom, soft tissue, surgery, tissue density variations},
	pages = {1707--1716}
}

@article{kallem_image_2009,
	title = {Image {Guidance} of {Flexible} {Tip}-{Steerable} {Needles}},
	volume = {25},
	issn = {1552-3098},
	doi = {10.1109/TRO.2008.2010357},
	abstract = {Image guidance promises to improve targeting accuracy and broaden the scope of medical procedures performed with needles. This paper takes a step toward automating the guidance of a flexible tip-steerable needle as it is inserted into the human tissue. We build upon a previously proposed nonholonomic model of needles that derive steering from asymmetric bevel forces at the tip. The bevel-tip needle is inserted and rotated at its base in order to steer it in 6 DOF. As a first step for control, we show that the needle tip can be automatically guided to a planar slice of the tissue as it is inserted. Our approach keeps the physician in the loop to control insertion speed. The distance of the needle tip position from the plane of interest is used to drive an observer-based feedback controller that we prove is locally asymptotically stable. Numerical simulations demonstrate a large domain of attraction and robustness of the controller in the face of parametric uncertainty and measurement noise. Physical experiments with tip-steerable nitinol needles inserted into a transparent plastisol tissue phantom under stereo image guidance validate the effectiveness of our approach.},
	number = {1},
	journal = {IEEE Transactions on Robotics},
	author = {Kallem, V. and Cowan, N. J.},
	month = feb,
	year = {2009},
	keywords = {Feedback control, asymptotic stability, feedback, flexible tip-steerable needles, locally asymptotically stable, medical procedures, medical robotics, needle model, needle steering, nonholonomic model, nonholonomic system, numerical simulations, observer-based feedback controller, observers, position control, robot vision, stereo image guidance, transparent plastisol tissue phantom},
	pages = {191--196}
}

@article{webster_nonholonomic_2006,
	title = {Nonholonomic {Modeling} of {Needle} {Steering}},
	volume = {25},
	issn = {0278-3649},
	url = {https://doi.org/10.1177/0278364906065388},
	doi = {10.1177/0278364906065388},
	abstract = {As a flexible needle with a bevel tip is pushed through soft tissue, the                     asymmetry of the tip causes the needle to bend. We propose that, by using                     nonholonomic kinematics, control, and path planning, an appropriately designed                     needle can be steered through tissue to reach a specified 3D target. Such                     steering capability could enhance targeting accuracy and may improve outcomes                     for percutaneous therapies, facilitate research on therapy effectiveness, and                     eventually enable new minimally invasive techniques. In this paper, we consider                     a first step toward active needle steering: design and experimental validation                     of a nonholonomic model for steering flexible needles with bevel tips. The model                     generalizes the standard three degree-of-freedom (DOF) nonholonomic unicycle and                     bicycle models to 6 DOF using Lie group theory. Model parameters are fit using                     experimental data, acquired via a robotic device designed for the specific                     purpose of inserting and steering a flexible needle. The experiments                     quantitatively validate the bevel-tip needle steering model, enabling future                     research in flexible needle path planning, control, and simulation.},
	language = {en},
	number = {5-6},
	urldate = {2017-10-24TZ},
	journal = {The International Journal of Robotics Research},
	author = {Webster, Robert J. and Kim, Jin Seob and Cowan, Noah J. and Chirikjian, Gregory S. and Okamura, Allison M.},
	month = may,
	year = {2006},
	keywords = {needle model},
	pages = {509--525}
}

@incollection{cowan_robotic_2011,
	title = {Robotic {Needle} {Steering}: {Design}, {Modeling}, {Planning}, and {Image} {Guidance}},
	isbn = {978-1-4419-1125-4 978-1-4419-1126-1},
	shorttitle = {Robotic {Needle} {Steering}},
	url = {https://link.springer.com/chapter/10.1007/978-1-4419-1126-1_23},
	abstract = {This chapter describes how advances in needle design, modeling, planning, and image guidance make it possible to steer flexible needles from outside the body to reach specified anatomical targets not accessible using traditional needle insertion methods. Steering can be achieved using a variety of mechanisms, including tip-based steering, lateral manipulation, and applying forces to the tissue as the needle is inserted. Models of these steering mechanisms can predict needle trajectory based on steering commands, motivating new preoperative path planning algorithms. These planning algorithms can be integrated with emerging needle imaging technology to achieve intraoperative closed-loop guidance and control of steerable needles.},
	language = {en},
	urldate = {2017-10-24TZ},
	booktitle = {Surgical {Robotics}},
	publisher = {Springer, Boston, MA},
	author = {Cowan, Noah J. and Goldberg, Ken and Chirikjian, Gregory S. and Fichtinger, Gabor and Alterovitz, Ron and Reed, Kyle B. and Kallem, Vinutha and Park, Wooram and Misra, Sarthak and Okamura, Allison M.},
	year = {2011},
	doi = {10.1007/978-1-4419-1126-1_23},
	keywords = {needle model},
	pages = {557--582}
}

@article{tokuda_openigtlink:_2009,
	title = {{OpenIGTLink}: an open network protocol for image-guided therapy environment},
	volume = {5},
	issn = {1478-5951},
	shorttitle = {{OpenIGTLink}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2811069/},
	doi = {10.1002/rcs.274},
	abstract = {Background
With increasing research on system integration for image-guided therapy (IGT), there has been a strong demand for standardized communication among devices and software to share data such as target positions, images and device status.

Method
We propose a new, open, simple and extensible network communication protocol for IGT, named OpenIGTLink, to transfer transform, image and status messages. We conducted performance tests and use-case evaluations in five clinical and engineering scenarios.

Results
The protocol was able to transfer position data with submillisecond latency up to 1024 fps and images with latency of {\textless}10 ms at 32 fps. The use-case tests demonstrated that the protocol is feasible for integrating devices and software.

Conclusion
The protocol proved capable of handling data required in the IGT setting with sufficient time resolution and latency. The protocol not only improves the interoperability of devices and software but also promotes transitions of research prototypes to clinical applications..},
	number = {4},
	urldate = {2017-10-24TZ},
	journal = {The international journal of medical robotics + computer assisted surgery : MRCAS},
	author = {Tokuda, Junichi and Fischer, Gregory S. and Papademetris, Xenophon and Yaniv, Ziv and Ibanez, Luis and Cheng, Patrick and Liu, Haiying and Blevins, Jack and Arata, Jumpei and Golby, Alexandra J. and Kapur, Tina and Pieper, Steve and Burdette, Everette C. and Fichtinger, Gabor and Tempany, Clare M. and Hata, Nobuhiko},
	month = dec,
	year = {2009},
	pmid = {19621334},
	pmcid = {PMC2811069},
	pages = {423--434}
}

@article{tokuda_integrated_2009,
	title = {Integrated navigation and control software system for {MRI}-guided robotic prostate interventions},
	issn = {0895-6111},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2815337/},
	doi = {10.1016/j.compmedimag.2009.07.004},
	abstract = {A software system to provide intuitive navigation for MRI-guided robotic transperineal prostate therapy is presented. In the system, the robot control unit, the MRI scanner, and the open-source navigation software are connected together via Ethernet to exchange commands, coordinates, and images using an open network communication protocol, OpenIGTLink. The system has six states called “workphases” that provide the necessary synchronization of all components during each stage of the clinical workflow, and the user interface guides the operator linearly through these workphases. On top of this framework, the software provides the following features for needle guidance: interactive target planning; 3D image visualization with current needle position; treatment monitoring through real-time MR images of needle trajectories in the prostate. These features are supported by calibration of robot and image coordinates by fiducial-based registration. Performance tests show that the registration error of the system was 2.6 mm within the prostate volume. Registered real-time 2D images were displayed 1.97 s after the image location is specified.},
	urldate = {2017-10-24TZ},
	journal = {Computerized medical imaging and graphics : the official journal of the Computerized Medical Imaging Society},
	author = {Tokuda, Junichi and Fischer, Gregory S. and DiMaio, Simon P. and Gobbi, David G. and Csoma, Csaba and Mewes, Philip W. and Fichtinger, Gabor and Tempany, Clare M. and Hata, Nobuhiko},
	month = aug,
	year = {2009},
	pmid = {19699057},
	pmcid = {PMC2815337}
}

@article{song_biopsy_2012,
	title = {Biopsy {Needle} {Artifact} {Localization} in {MRI}-guided {Robotic} {Transrectal} {Prostate} {Intervention}},
	volume = {59},
	issn = {0018-9294},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3675798/},
	doi = {10.1109/TBME.2012.2192118},
	abstract = {Recently a number of robotic intervention systems for magnetic resonance image (MRI) guided needle placement in the prostate have been reported. In MRI-guided needle interventions, after a needle is inserted, the needle position is often confirmed with a volumetric MRI scan. Commonly used titanium needles are not directly visible in an MR image, but they generate a susceptibility artifact in the immediate neighborhood of the needle. This paper reports the results of a quantitative study of the relationship between the true position of titanium biopsy needle and the corresponding needle artifact position in MR images, thereby providing a better understanding of the influence of needle artifact on targeting errors. The titanium needle tip artifact extended 9 mm beyond the actual needle tip location with tendency to bend towards the scanner’s B0 magnetic field direction, and axially displaced 0.38 mm and 0.32 mm (mean) in scanner’s frequency and phase encoding direction, respectively.},
	number = {7},
	urldate = {2017-10-24TZ},
	journal = {IEEE transactions on bio-medical engineering},
	author = {Song, Sang-Eun and Cho, Nathan B. and Iordachita, Iulian and Guion, Peter and Fichtinger, Gabor and Kaushal, Aradhana and Camphausen, Kevin and Whitcomb, Louis L.},
	month = jul,
	year = {2012},
	pmid = {22481805},
	pmcid = {PMC3675798},
	pages = {1902--1911}
}

@article{weiss_mr-guided_2008,
	title = {{MR}-guided biopsy: {A} review of current techniques and applications},
	volume = {27},
	issn = {1522-2586},
	shorttitle = {{MR}-guided biopsy},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/jmri.21270/abstract},
	doi = {10.1002/jmri.21270},
	abstract = {Biopsy has become a cornerstone of modern medicine and most modern biopsies are performed percutaneously using image guidance, typically computed tomography or ultrasound. MR-guided biopsy offers many advantages over these more traditional modalities, and the recent development of interventional MR imaging techniques has made MR-guided percutaneous biopsies and aspirations a clinical reality. As the field of MR-guided procedures continues to expand and to attract more attention from radiologists, it is important to understand the concepts, techniques, applications, advantages, and limitations of MR-guided biopsy/percutaneous procedures. Radiologists should also recognize the need for their significant involvement in the technical aspects of MR-guided procedures, since several user-defined parameters can alter device visualization in the MR imaging environment and affect procedure safety. This article reviews the prerequisites, systems, and applications of MR-guided biopsy. J. Magn. Reson. Imaging 2008;27:311–325. © 2008 Wiley-Liss, Inc.},
	language = {en},
	number = {2},
	urldate = {2017-10-24TZ},
	journal = {Journal of Magnetic Resonance Imaging},
	author = {Weiss, Clifford R. and Nour, Sherif Gamal and Lewin, Jonathan S.},
	month = feb,
	year = {2008},
	keywords = {MR guidance, MRI, abdomen, augmented reality, biopsy, breast, frameless stereotaxy, head and neck, image fusion, imaging system development, interventional magnetic resonance, liver, multiplanar imaging, musculoskeletal, percutaneous therapy, prostate, real-time imaging, sclerotherapy},
	pages = {311--325}
}

@article{kochavi_method_2004,
	title = {Method for rapid {MRI} needle tracking},
	volume = {51},
	issn = {1522-2594},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/mrm.20065/abstract},
	doi = {10.1002/mrm.20065},
	abstract = {A new method for MRI needle tracking within a given two-dimensional (2D) image slice is presented. The method is based on k-space investigation of the difference image between the current dynamic frame and a reference frame. Using only a few central k-lines of the difference image and a nonlinear optimization procedure, one can resolve the parameters that define the 2D sinc function that best characterizes the needle in k-space. The spatial location and orientation of the needle are determined from these parameters. Rapid needle tracking is obtained by repeated acquisitions of the same set of several central k-lines (as in a “keyhole” protocol) and repeated computation of these parameters. The calculated needle tip is depicted on the reference image by means of a graphic overlay. The procedure was tested in computer simulations and in actual MRI scans (the computations were done offline). It was demonstrated that six k-lines out of 128 usually suffice to locate the needle. The refresh rate of the needle location depends on the time required to sample the subset of k-lines, calculate the current needle location, and refresh the reference image. Magn Reson Med 51:1083–1087, 2004. © 2004 Wiley-Liss, Inc.},
	language = {en},
	number = {5},
	urldate = {2017-10-24TZ},
	journal = {Magnetic Resonance in Medicine},
	author = {Kochavi, Eyal and Goldsher, Dorith and Azhari, Haim},
	month = may,
	year = {2004},
	keywords = {iMRI, interventional MRI, invasive MRI, needle tracking, rapid imaging},
	pages = {1083--1087}
}

@article{eslami_-bore_2016,
	title = {In-{Bore} {Prostate} {Transperineal} {Interventions} with an {MRI}-guided {Parallel} {Manipulator}: {System} {Development} and {Preliminary} {Evaluation}},
	volume = {12},
	issn = {1478-5951},
	shorttitle = {In-{Bore} {Prostate} {Transperineal} {Interventions} with an {MRI}-guided {Parallel} {Manipulator}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4691445/},
	doi = {10.1002/rcs.1671},
	abstract = {Background
The robot-assisted minimally-invasive surgery is well recognized as a feasible solution for diagnosis and treatment of the prostate cancer in human.

Methods
In this paper the kinematics of a parallel 4 Degrees-of-Freedom (DOF) surgical manipulator designed for minimally invasive in-bore prostate percutaneous interventions through the patient's perineum. The proposed manipulator takes advantage of 4 sliders actuated by MRI-compatible piezoelectric motors and incremental rotary encoders. Errors, mostly originating from the design and manufacturing process, need to be identified and reduced before the robot is deployed in the clinical trials.

Results
The manipulator has undergone several experiments to evaluate the repeatability and accuracy of the needle placement which is an essential concern in percutaneous prostate interventions.

Conclusion
The acquired results endorse the sustainability, precision (about 1 mm in air (in x or y direction) at the needle's reference point) and reliability of the manipulator.},
	number = {2},
	urldate = {2017-10-24TZ},
	journal = {The international journal of medical robotics + computer assisted surgery : MRCAS},
	author = {Eslami, Sohrab and Shang, Weijian and Li, Gang and Patel, Nirav and Fischer, Gregory S. and Tokuda, Junichi and Hata, Nobuhiko and Tempany, Clare M. and Iordachita, Iulian},
	month = jun,
	year = {2016},
	pmid = {26111458},
	pmcid = {PMC4691445},
	pages = {199--213}
}

@misc{noauthor_transperineal_nodate,
	title = {Transperineal prostate biopsy under magnetic resonance image guidance: {A} needle placement accuracy study - {Blumenfeld} - 2007 - {Journal} of {Magnetic} {Resonance} {Imaging} - {Wiley} {Online} {Library}},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/jmri.21067/abstract;jsessionid=3DCC9DEE8D88A9385489F01D9597DF3F.f03t04},
	urldate = {2017-10-24TZ}
}

@article{blumenfeld_transperineal_2007,
	title = {Transperineal prostate biopsy under magnetic resonance image guidance: a needle placement accuracy study},
	volume = {26},
	issn = {1053-1807},
	shorttitle = {Transperineal prostate biopsy under magnetic resonance image guidance},
	doi = {10.1002/jmri.21067},
	abstract = {PURPOSE: To quantify needle placement accuracy of magnetic resonance image (MRI)-guided core needle biopsy of the prostate.
MATERIALS AND METHODS: A total of 10 biopsies were performed with 18-gauge (G) core biopsy needle via a percutaneous transperineal approach. Needle placement error was assessed by comparing the coordinates of preplanned targets with the needle tip measured from the intraprocedural coherent gradient echo images. The source of these errors was subsequently investigated by measuring displacement caused by needle deflection and needle susceptibility artifact shift in controlled phantom studies. Needle placement error due to misalignment of the needle template guide was also evaluated.
RESULTS: The mean and standard deviation (SD) of errors in targeted biopsies was 6.5 +/- 3.5 mm. Phantom experiments showed significant placement error due to needle deflection with a needle with an asymmetrically beveled tip (3.2-8.7 mm depending on tissue type) but significantly smaller error with a symmetrical bevel (0.6-1.1 mm). Needle susceptibility artifacts observed a shift of 1.6 +/- 0.4 mm from the true needle axis. Misalignment of the needle template guide contributed an error of 1.5 +/- 0.3 mm.
CONCLUSION: Needle placement error was clinically significant in MRI-guided biopsy for diagnosis of prostate cancer. Needle placement error due to needle deflection was the most significant cause of error, especially for needles with an asymmetrical bevel.},
	language = {eng},
	number = {3},
	journal = {Journal of magnetic resonance imaging: JMRI},
	author = {Blumenfeld, Philip and Hata, Nobuhiko and DiMaio, Simon and Zou, Kelly and Haker, Steven and Fichtinger, Gabor and Tempany, Clare M. C.},
	month = sep,
	year = {2007},
	pmid = {17729363},
	keywords = {Aged, Artifacts, Biopsy, Needle, Contrast Media, Humans, Magnetic Resonance Imaging, Magnetic Resonance Spectroscopy, Male, Middle Aged, Needles, Phantoms, Imaging, Prostatectomy, Prostatic Neoplasms, Reproducibility of Results, Retrospective Studies},
	pages = {688--694}
}

@article{logan_current_2014,
	title = {Current {Status} of {MRI} and {Ultrasound} {Fusion} {Software} {Platforms} for {Guidance} of {Prostate} {Biopsies}},
	volume = {114},
	issn = {1464-4096},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4568118/},
	doi = {10.1111/bju.12593},
	abstract = {• Prostate MRI is currently the best diagnostic imaging method for
detecting prostate cancer, • Magnetic Resonance Imaging-Ultrasound (MRI/US) fusion allows the
sensitivity and specificity of MRI to be combined with real time capabilities of
transrectal ultrasound (TRUS)., • Multiple approaches and techniques exist for MRI/US fusion and
include (1) direct “in bore” MR biopsies, (2) cognitive fusion,
and (3) MRI/US fusion via software-based image co-registration platforms.},
	number = {5},
	urldate = {2017-10-24TZ},
	journal = {BJU international},
	author = {Logan, Jennifer K and Rais-Bahrami, Soroush and Turkbey, Baris and Gomella, Andrew and Amalou, Hayet and Choyke, Peter L and Wood, Bradford J and Pinto, Peter A},
	month = nov,
	year = {2014},
	pmid = {24298917},
	pmcid = {PMC4568118},
	pages = {641--652}
}

@article{bomers_mri-guided_2012,
	title = {{MRI}-{Guided} {Interventions} for the {Treatment} of {Prostate} {Cancer}},
	volume = {199},
	issn = {0361-803X},
	url = {http://www.ajronline.org/doi/full/10.2214/AJR.12.8725},
	doi = {10.2214/AJR.12.8725},
	abstract = {Choose
                    Top of pageABSTRACT {\textless}{\textless}Materials and MethodsResultsDiscussionConclusionReferencesCITING ARTICLES OBJECTIVE. The purpose of this article is to evaluate MRI-guided therapies and to investigate their feasibility for focal therapy in prostate cancer patients. Relevant articles were retrieved using the PubMed online search engine. CONCLUSION. Currently, MRI-guided laser ablation and MRI-guided focused ultrasound are the most promising options for focal treatment of the prostate in patients with prostate cancer. Other techniques—that is, cryosurgery, microwave ablation, and radiofrequency ablation—are, for several and different reasons, less suitable for MRI-guided focal therapy of the prostate.},
	number = {4},
	urldate = {2017-10-24TZ},
	journal = {American Journal of Roentgenology},
	author = {Bomers, Joyce G. R. and Sedelaar, J. P. Michiel and Barentsz, Jelle O. and Fütterer, Jurgen J.},
	month = oct,
	year = {2012},
	keywords = {MRI-guided interventions, oncology, prostate cancer},
	pages = {714--720}
}

@incollection{park_path_2009,
	series = {Springer {Tracts} in {Advanced} {Robotics}},
	title = {Path {Planning} for {Flexible} {Needles} {Using} {Second} {Order} {Error} {Propagation}},
	isbn = {978-3-642-00311-0 978-3-642-00312-7},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-00312-7_36},
	abstract = {In this paper we propose a computationally efficient method for the steering of flexible needles with a bevel tip in the presence of uncertainties for the case when there are no obstacles in the environment. Based on the stochastic model for the needles, we develop a new framework for path planning of a flexible needle with a bevel tip. This consists of three parts: (a) approximation of probability density functions for the needle tip pose; (b) application of a second order error propagation algorithm on the Euclidean motion group; and (c) application of the path-of-probability (POP) algorithm. The probability density functions are approximated as Gaussians under the assumption that the uncertainty in the needle insertion is fairly small. The means and the covariances for the probability density functions are estimated using the error propagation algorithm that has second order accuracy. The POP algorithm is adapted to the path planning for the flexible needles so as to give the appropriate steering plan. Combining these components and considering 5 degree-of-freedom targets, the new method gives the path of the flexible needle that hits the target point with the desired hitting direction.},
	language = {en},
	urldate = {2017-10-24TZ},
	booktitle = {Algorithmic {Foundation} of {Robotics} {VIII}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Park, Wooram and Wang, Yunfeng and Chirikjian, Gregory S.},
	year = {2009},
	doi = {10.1007/978-3-642-00312-7_36},
	pages = {583--595}
}

@article{park_estimation_2010,
	title = {Estimation of {Model} {Parameters} for {Steerable} {Needles}},
	issn = {2152-4092},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3107577/},
	doi = {10.1109/ROBOT.2010.5509380},
	abstract = {Flexible needles with bevel tips are being developed as useful tools for minimally invasive surgery and percutaneous therapy. When such a needle is inserted into soft tissue, it bends due to the asymmetric geometry of the bevel tip. This insertion with bending is not completely repeatable. We characterize the deviations in needle tip pose (position and orientation) by performing repeated needle insertions into artificial tissue. The base of the needle is pushed at a constant speed without rotating, and the covariance of the distribution of the needle tip pose is computed from experimental data. We develop the closed-form equations to describe how the covariance varies with different model parameters. We estimate the model parameters by matching the closed-form covariance and the experimentally obtained covariance. In this work, we use a needle model modified from a previously developed model with two noise parameters. The modified needle model uses three noise parameters to better capture the stochastic behavior of the needle insertion. The modified needle model provides an improvement of the covariance error from 26.1\% to 6.55\%.},
	urldate = {2017-10-24TZ},
	journal = {IEEE International Conference on Robotics and Automation : ICRA : [proceedings] IEEE International Conference on Robotics and Automation},
	author = {Park, Wooram and Reed, Kyle B. and Okamura, Allison M. and Chirikjian, Gregory S.},
	year = {2010},
	pmid = {21643451},
	pmcid = {PMC3107577},
	pages = {3703--3708}
}

@inproceedings{wartenberg_towards_2016,
	title = {Towards synergistic control of hands-on needle insertion with automated needle steering for {MRI}-guided prostate interventions},
	doi = {10.1109/EMBC.2016.7591878},
	abstract = {A significant hurdle of accurate needle tip placement in percutaneous needle-based prostate interventions is unmodeled needle deflection and tissue deformation during insertion. This paper introduces a robotic platform for developing synergistic, cooperatively controlled needle insertion algorithms decoupled from closed-loop image-guided needle steering. Shared control of the surgical workspace through human-robot synergy creates a balance between the accuracy of robotic autonomy while still providing ultimate control of the procedure to the physician. Validation tests were performed using camera-based image-guided feedback control of needle steering with cooperative hands-on needle insertion. Locations were targeted inside a transparent gelatin phantom with an average total error of 2.68 ± 0.34mm and in-plane error of 2.59 ± 0.30mm.},
	booktitle = {2016 38th {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society} ({EMBC})},
	author = {Wartenberg, M. and Patel, N. and Li, G. and Fischer, G. S.},
	month = aug,
	year = {2016},
	keywords = {Force, MRI-guided prostate intervention, Medical services, Needles, Phantoms, Robot sensing systems, Trajectory, automated needle steering, biomedical MRI, camera-based image-guided feedback control, closed-loop image-guided needle steering, gelatin phantom, hands-on needle insertion, human-robot synergy, medical image processing, medical robotics, needle deflection, needle insertion algorithm, needle-based prostate intervention, needles, phantoms, robotic autonomy, robotic platform, tissue deformation},
	pages = {5116--5119}
}

@article{swensen_torsional_2014,
	title = {Torsional {Dynamics} of {Steerable} {Needles}: {Modeling} and {Fluoroscopic} {Guidance}},
	volume = {61},
	issn = {0018-9294},
	shorttitle = {Torsional {Dynamics} of {Steerable} {Needles}},
	doi = {10.1109/TBME.2014.2326161},
	abstract = {Needle insertions underlie a diversity of medical interventions. Steerable needles provide a means by which to enhance existing needle-based interventions and facilitate new ones. Tip-steerable needles follow a curved path and can be steered by twisting the needle base during insertion, but this twisting excites torsional dynamics that introduce a discrepancy between the base and tip twist angles. Here, we model the torsional dynamics of a flexible rod-such as a tip-steerable needle-during subsurface insertion and develop a new controller based on the model. The torsional model incorporates time-varying mode shapes to capture the changing boundary conditions inherent during insertion. Numerical simulations and physical experiments using two distinct setups-stereo camera feedback in semitransparent artificial tissue and feedback control with real-time X-ray imaging in optically opaque artificial tissue-demonstrate the need to account for torsional dynamics in control of the needle tip.},
	number = {11},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Swensen, J. P. and Lin, M. and Okamura, A. M. and Cowan, N. J.},
	month = nov,
	year = {2014},
	keywords = {Biomechanical Phenomena, Computer Simulation, Continuum robot, Dynamics, Fluoroscopy, Kinematics, Mathematical model, Models, Biological, Needles, Robotic Surgical Procedures, Robots, Springs, Torque, Torsion, Mechanical, biological tissues, biomedical optical imaging, boundary conditions, cameras, diagnostic radiography, feedback control, flexible rod, fluoroscopic guidance, medical interventions, medical robot, needle insertions, numerical simulation, optically opaque artificial tissue, real-time X-ray imaging, robot dynamics, semitransparent artificial tissue, setup-stereo camera feedback, steerable needles, subsurface insertion, time-varying systems, tip twist angles, tip-steerable needles, torsional dynamics model},
	pages = {2707--2717}
}

@article{dimaio_needle_2003,
	title = {Needle insertion modeling and simulation},
	volume = {19},
	issn = {1042-296X},
	doi = {10.1109/TRA.2003.817044},
	abstract = {A methodology for estimating the force distribution that occurs along a needle shaft during insertion is described. An experimental system for measuring planar tissue phantom deformation during needle insertions has been developed and is presented. A two-dimensional linear elastostatic material model, discretised using the finite element method, is used to derive contact force information that is not directly measurable. This approach provides a method for quantifying the needle forces and soft tissue deformations that occur during general needle trajectories in multiple dimensions. The needle force distribution is used for graphical and haptic real-time simulations of needle insertion. Since the force displacement relationship is required only along the needle, a condensation technique is shown to achieve very fast interactive simulations. Stiffness matrix changes corresponding to changes in boundary conditions and material coordinate frames are performed using low-rank matrix updates.},
	number = {5},
	journal = {IEEE Transactions on Robotics and Automation},
	author = {DiMaio, S. P. and Salcudean, S. E.},
	month = oct,
	year = {2003},
	keywords = {Biological materials, Biological tissues, Boundary conditions, Finite element methods, Force measurement, Haptic interfaces, Imaging phantoms, Needles, Shafts, Transmission line matrix methods, Young's modulus, biological tissues, biomechanics, boundary conditions, condensation technique, contact force information, elasticity, end-effector, finite element analysis, finite element method, force displacement relationship, force distribution, general needle trajectories, graphical simulations, haptic real-time simulations, low-rank matrix updates, manipulators, material coordinate frames, medical image processing, medical robotics, multiple dimensions, needle forces, needle insertion modeling, needle insertion simulation, needle shaft, phantoms, physiological models, planar robotic manipulator, planar tissue phantom deformation, real-time systems, soft tissue deformations, stiffness matrix changes, surgery, two-dimensional linear elastostatic material model, very fast interactive simulations},
	pages = {864--875}
}

@article{fischer_mri-compatible_2008,
	title = {{MRI}-{Compatible} {Pneumatic} {Robot} for {Transperineal} {Prostate} {Needle} {Placement}},
	volume = {13},
	issn = {1083-4435},
	doi = {10.1109/TMECH.2008.924044},
	abstract = {Magnetic resonance imaging (MRI) can provide high-quality 3-D visualization of prostate and surrounding tissue, thus granting potential to be a superior medical imaging modality for guiding and monitoring prostatic interventions. However, the benefits cannot be readily harnessed for interventional procedures due to difficulties that surround the use of high-field (1.5T or greater) MRI. The inability to use conventional mechatronics and the confined physical space makes it extremely challenging to access the patient. We have designed a robotic assistant system that overcomes these difficulties and promises safe and reliable intraprostatic needle placement inside closed high-field MRI scanners. MRI compatibility of the robot has been evaluated under 3T MRI using standard prostate imaging sequences and average SNR loss is limited to 5\%. Needle alignment accuracy of the robot under servo pneumatic control is better than 0.94 mm rms per axis. The complete system workflow has been evaluated in phantom studies with accurate visualization and targeting of five out of five 1 cm targets. The paper explains the robot mechanism and controller design, the system integration, and presents results of preliminary evaluation of the system.},
	number = {3},
	journal = {IEEE/ASME Transactions on Mechatronics},
	author = {Fischer, G. S. and Iordachita, I. and Csoma, C. and Tokuda, J. and DiMaio, S. P. and Tempany, C. M. and Hata, N. and Fichtinger, G.},
	month = jun,
	year = {2008},
	keywords = {Biomedical imaging, Biomedical monitoring, MRI-compatible pneumatic robot, Magnetic resonance imaging, Magnetic resonance imaging (MRI) compatible robotics, Mechatronics, Medical robotics, Needles, Orbital robotics, Patient monitoring, Robots, Visualization, biomedical MRI, controller design, high-quality 3D visualization, image sequences, magnetic resonance imaging, medical imaging modality, medical robotics, pneumatic control, prostate brachytherapy and biopsy, prostate imaging sequences, prostatic interventions monitoring, robot mechanism, robot vision, robotic assistant system, servo pneumatic control, transperineal prostate needle placement},
	pages = {295--305}
}

@inproceedings{simone_modeling_2002,
	title = {Modeling of needle insertion forces for robot-assisted percutaneous therapy},
	volume = {2},
	doi = {10.1109/ROBOT.2002.1014848},
	abstract = {Force information from needle insertions was measured and modeled for use in robot-assisted percutaneous therapies. Data was collected on bovine livers using the Johns Hopkins University Steady Hand Robot, and modeled in three parts: force due to capsule stiffness, friction, and cutting. Capsule stiffness is modeled by a nonlinear spring model, friction by a modified Karnopp model, and cutting by the remaining forces, which appear to be constant for a given tissue sample. During robot-assisted procedures, real-time force data can be compared to these models to control puncture of interior structures.},
	booktitle = {Proceedings 2002 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({Cat}. {No}.02CH37292)},
	author = {Simone, C. and Okamura, A. M.},
	year = {2002},
	keywords = {Feedback, Force measurement, Haptic interfaces, Humans, Instruments, Johns Hopkins University Steady Hand Robot, Medical treatment, Minimally invasive surgery, Needles, Robotics and automation, Robots, biological tissues, bovine livers, capsule stiffness, cutting, friction, haptic interfaces, liver ablation, medical robotics, modified Karnopp model, needle insertion forces, nonlinear spring model, patient diagnosis, patient treatment, prostate brachytherapy, puncture, real-time force data, robot-assisted percutaneous therapy, tissue layers},
	pages = {2085--2091 vol.2}
}

@article{tse_haptic_2012,
	title = {Haptic {Needle} {Unit} for {MR}-{Guided} {Biopsy} and {Its} {Control}},
	volume = {17},
	issn = {1083-4435},
	doi = {10.1109/TMECH.2011.2113187},
	abstract = {MRI provides high-resolution anatomical images and is ideal for certain image-guided interventions. Due to the physical separation between the patient region of interest and the workspace accessible by the clinician, direct force feedback from the target anatomy is missing during the interventions. This paper demonstrates the use of a master-slave haptic device for magnetic resonance-guided biopsy, using a novel haptic control scheme based upon a neural network speed model. Results have shown the feasibility of the proposed hardware design and control scheme.},
	number = {1},
	journal = {IEEE/ASME Transactions on Mechatronics},
	author = {Tse, Z. T. H. and Elhawary, H. and Rea, M. and Davies, B. and Young, I. and Lamperth, M.},
	month = feb,
	year = {2012},
	keywords = {Biological system modeling, Computational modeling, Force, Force control, Haptic interfaces, Load modeling, MR-guided biopsy, MRI intervention, Magnetic resonance imaging, Needles, biomedical MRI, control engineering computing, direct force feedback, force feedback, haptic control scheme, haptic interfaces, haptic needle unit, high-resolution anatomical images, image-guided interventions, master-slave haptic device, medical image processing, medical robotics, neural network speed model, neurocontrollers, patient region-of-interest, piezo-electric ceramic actuators, piezoceramic electric motor, piezoceramics, piezoelectric actuators},
	pages = {183--187}
}
@inproceedings{turkseven_design_2011,
	title = {Design of an {MRI} compatible haptic interface},
	doi = {10.1109/IROS.2011.6095170},
	abstract = {This paper proposes an MRI-compatible, 1-axis force sensing unit which is designed to be used as a haptic interface on an MRI compatible robot. Recently, it became a popular research direction to enable MRI in surgical operations and brain studies with the help of robotic devices. However, due to high magnetic field in MRI environment, conventional sensors and robots cannot be used in MRI rooms. Existing MRI-compatible force sensors have limited number of degrees of freedom or they do not offer compact solutions for multiple-axis sensing. In this paper, a compact 1-axis force sensing unit which employs a compliant displacement amplification mechanism is introduced and then analyzed for better sensitivity and accuracy. A combination of multiple proposed sensing units can be assembled to have a force sensor with desired number of degrees of freedom. Prototypes made of delrin and ABS-plastic are tested. Experiments indicated that the proposed sensor is suitable for force sensing and fully compatible to MRI. Also, the sensor made of delrin is superior in mechanical performance and MRI compatibility to ABS-plastic sample.},
	booktitle = {2011 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Turkseven, M. and Ueda, J.},
	month = sep,
	year = {2011},
	keywords = {Force, Force sensors, Loading, Magnetic resonance imaging, Robot sensing systems},
	pages = {2139--2144}
}

@inproceedings{su_real-time_2011,
	title = {Real-time {MRI}-guided needle placement robot with integrated fiber optic force sensing},
	doi = {10.1109/ICRA.2011.5979539},
	abstract = {This paper presents the first prototype of a magnetic resonance imaging (MRI) compatible piezoelectric actuated robot integrated with a high-resolution fiber optic sensor for prostate brachytherapy with real-time in situ needle steering capability in 3T MRI. The 6-degrees-of-freedom (DOF) robot consists of a modular 3-DOF needle driver with fiducial tracking frame and a 3-DOF actuated Cartesian stage. The needle driver provides needle cannula rotation and translation (2-DOF) and stylet translation (1-DOF). The driver mimics the manual physician gesture by two point grasping. To render proprioception associated with prostate interventions, a Fabry Perot interferometer based fiber optic strain sensor is designed to provide high-resolution axial needle insertion force measurement and is robust to large range of temperature variation. The paper explains the robot mechanism, controller design, optical modeling and opto-mechanical design of the force sensor. MRI compatibility of the robot is evaluated under 3T MRI using standard prostate imaging sequences and average signal noise ratio (SNR) loss is limited to 2\% during actuator motion. A dynamic needle insertion is performed and bevel tip needle steering capability is demonstrated under continuous real-time MRI guidance, both with no visually identifiable interference during robot motion. Fiber optic sensor calibration validates the theoretical modeling with satisfactory sensing range and resolution for prostate intervention.},
	booktitle = {2011 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Su, H. and Zervas, M. and Cole, G. A. and Furlong, C. and Fischer, G. S.},
	month = may,
	year = {2011},
	keywords = {3-DOF actuated Cartesian stage, 3T MRI, Brachytherapy, Fabry-Perot Interferometer, Fabry-Perot interferometer, Fabry-Perot interferometers, MRI Compatibility, MRI compatibility, Magnetic resonance imaging, Needle Driver, Needles, Optical Force Sensor, Optical fiber sensors, Optical fibers, Robot sensing systems, actuator motion, bevel tip needle steering capability, brachytherapy, control system synthesis, controller design, fiber optic sensor calibration, fiber optic strain sensor, fibre optic sensors, fiducial tracking frame, force measurement, force sensor, force sensors, high-resolution axial needle insertion force measurement, high-resolution fiber optic sensor, identifiable interference, integrated fiber optic force sensing, integrated optics, magnetic resonance imaging, manual physician gesture, medical robotics, modular 3DOF needle driver, needle cannula rotation, needles, optical modeling, opto-mechanical design, piezoelectric actuated robot, piezoelectric actuators, prostate brachytherapy, prostate imaging sequence, real-time MRI-guided needle placement robot, real-time in situ needle steering capability, real-time systems, robot mechanism, signal noise ratio loss, steering systems, stylet translation},
	pages = {1583--1588}
}

@inproceedings{patel_closed-loop_2015,
	title = {Closed-loop asymmetric-tip needle steering under continuous intraoperative {MRI} guidance},
	doi = {10.1109/EMBC.2015.7319484},
	abstract = {Magnetic resonance imaging (MRI) provides excellent image contrast for various types of tissues, making it a suitable choice over other imaging modalities for various image-guided needle interventions. Furthermore, robot-assistance is maturing for surgical procedures such as percutaneous prostate and brain interventions. Although MRI-guided, robot-assisted needle interventions are approaching clinical usage, they are still typically open-loop in nature due to the lack of continuous intraoperative needle tracking. Closed-loop needle-based procedures can improve the accuracy of needle tip placement by correcting the needle trajectory during insertion. This paper proposes a system for robot-assisted, flexible asymmetric-tipped needle interventions under continuous intraoperative MRI guidance. A flexible needle's insertion depth and rotation angle are manipulated by an MRI-compatible robot in the bore of the MRI scanner during continuous multi-planar image acquisition to reach a desired target location. Experiments are performed on gelatin phantoms to assess the accuracy of needle placement into the target location. The system was able to successfully utilize live MR imaging to guide the path of the needle, and results show an average total targeting error of 2.5±0.47mm, with an average in-plane error of 2.09±0.33mm.},
	booktitle = {2015 37th {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society} ({EMBC})},
	author = {Patel, N. A. and Katwijk, T. van and Li, G. and Moreira, P. and Shang, W. and Misra, S. and Fischer, G. S.},
	month = aug,
	year = {2015},
	keywords = {Geometry, MRI scanner, MRI-compatible robot, Magnetic resonance imaging, Needles, Robot kinematics, Target tracking, Trajectory, biomedical MRI, brain intervention, closed loop systems, closed-loop asymmetric-tip needle steering, continuous intraoperative MRI guidance, continuous intraoperative needle tracking, continuous multiplanar image acquisition, flexible asymmetric-tipped needle intervention, flexible needle insertion depth, flexible needle rotation angle, gelatin phantom, image contrast, image-guided needle intervention, imaging modality, magnetic resonance imaging, medical robotics, needle tip placement, needle trajectory, needles, percutaneous prostate intervention, phantoms, robot-assistance, robot-assisted needle intervention, surgery, surgical procedure, tissue type},
	pages = {4869--4874}
}